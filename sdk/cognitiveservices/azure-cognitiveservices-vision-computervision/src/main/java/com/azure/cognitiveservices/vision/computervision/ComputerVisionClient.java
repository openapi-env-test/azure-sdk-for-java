// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT License.
// Code generated by Microsoft (R) AutoRest Code Generator.

package com.azure.cognitiveservices.vision.computervision;

import com.azure.core.annotation.Generated;
import com.azure.core.annotation.ReturnType;
import com.azure.core.annotation.ServiceClient;
import com.azure.core.annotation.ServiceMethod;
import com.azure.core.exception.ClientAuthenticationException;
import com.azure.core.exception.HttpResponseException;
import com.azure.core.exception.ResourceModifiedException;
import com.azure.core.exception.ResourceNotFoundException;
import com.azure.core.http.rest.RequestOptions;
import com.azure.core.http.rest.Response;
import com.azure.core.util.BinaryData;

/** Initializes a new instance of the synchronous ComputerVisionClient type. */
@ServiceClient(builder = ComputerVisionClientBuilder.class)
public final class ComputerVisionClient {
    @Generated private final ComputerVisionAsyncClient client;

    /**
     * Initializes an instance of ComputerVisionClient class.
     *
     * @param client the async client.
     */
    @Generated
    ComputerVisionClient(ComputerVisionAsyncClient client) {
        this.client = client;
    }

    /**
     * This operation extracts a rich set of visual features based on the image content. Two input methods are supported
     * -- (1) Uploading an image or (2) specifying an image URL. Within your request, there is an optional parameter to
     * allow you to choose which features to return. By default, image categories are returned in the response. A
     * successful response will be returned in JSON. If the request failed, the response will contain an error code and
     * a message to help understand what went wrong.
     *
     * <p><strong>Query Parameters</strong>
     *
     * <table border="1">
     *     <caption>Query Parameters</caption>
     *     <tr><th>Name</th><th>Type</th><th>Required</th><th>Description</th></tr>
     *     <tr><td>visualFeatures</td><td>List&lt;String&gt;</td><td>No</td><td>A string indicating what visual feature types to return. Multiple values should be comma-separated. Valid visual feature types include: Categories - categorizes image content according to a taxonomy defined in documentation. Tags - tags the image with a detailed list of words related to the image content. Description - describes the image content with a complete English sentence. Faces - detects if faces are present. If present, generate coordinates, gender and age. ImageType - detects if image is clipart or a line drawing. Color - determines the accent color, dominant color, and whether an image is black&amp;white. Adult - detects if the image is pornographic in nature (depicts nudity or a sex act), or is gory (depicts extreme violence or blood). Sexually suggestive content (aka racy content) is also detected. Objects - detects various objects within an image, including the approximate location. The Objects argument is only available in English. Brands - detects various brands within an image, including the approximate location. The Brands argument is only available in English. In the form of "," separated string.</td></tr>
     *     <tr><td>details</td><td>List&lt;String&gt;</td><td>No</td><td>A string indicating which domain-specific details to return. Multiple values should be comma-separated. Valid visual feature types include: Celebrities - identifies celebrities if detected in the image, Landmarks - identifies notable landmarks in the image. In the form of "," separated string.</td></tr>
     *     <tr><td>language</td><td>String</td><td>No</td><td>The desired language for output generation. If this parameter is not specified, the default value is "en". See https://aka.ms/cv-languages for list of supported languages.</td></tr>
     *     <tr><td>descriptionExclude</td><td>List&lt;String&gt;</td><td>No</td><td>Turn off specified domain models when generating the description. In the form of "," separated string.</td></tr>
     *     <tr><td>model-version</td><td>String</td><td>No</td><td>Optional parameter to specify the version of the AI model. Accepted values are: "latest", "2021-04-01", "2021-05-01". Defaults to "latest".</td></tr>
     * </table>
     *
     * <p><strong>Request Body Schema</strong>
     *
     * <pre>{@code
     * {
     *     url: String
     * }
     * }</pre>
     *
     * <p><strong>Response Body Schema</strong>
     *
     * <pre>{@code
     * {
     *     categories: [
     *         {
     *             name: String
     *             score: Double
     *             detail: {
     *                 celebrities: [
     *                     {
     *                         name: String
     *                         confidence: Double
     *                         faceRectangle: {
     *                             left: Integer
     *                             top: Integer
     *                             width: Integer
     *                             height: Integer
     *                         }
     *                     }
     *                 ]
     *                 landmarks: [
     *                     {
     *                         name: String
     *                         confidence: Double
     *                     }
     *                 ]
     *             }
     *         }
     *     ]
     *     adult: {
     *         isAdultContent: Boolean
     *         isRacyContent: Boolean
     *         isGoryContent: Boolean
     *         adultScore: Double
     *         racyScore: Double
     *         goreScore: Double
     *     }
     *     color: {
     *         dominantColorForeground: String
     *         dominantColorBackground: String
     *         dominantColors: [
     *             String
     *         ]
     *         accentColor: String
     *         isBWImg: Boolean
     *     }
     *     imageType: {
     *         clipArtType: Integer
     *         lineDrawingType: Integer
     *     }
     *     tags: [
     *         {
     *             name: String
     *             confidence: Double
     *             hint: String
     *         }
     *     ]
     *     description: {
     *         tags: [
     *             String
     *         ]
     *         captions: [
     *             {
     *                 text: String
     *                 confidence: Double
     *             }
     *         ]
     *     }
     *     faces: [
     *         {
     *             age: Integer
     *             gender: String(Male/Female)
     *             faceRectangle: (recursive schema, see faceRectangle above)
     *         }
     *     ]
     *     objects: [
     *         {
     *             rectangle: {
     *                 x: Integer
     *                 y: Integer
     *                 w: Integer
     *                 h: Integer
     *             }
     *             object: String
     *             confidence: Double
     *             parent: {
     *                 object: String
     *                 confidence: Double
     *                 parent: (recursive schema, see parent above)
     *             }
     *         }
     *     ]
     *     brands: [
     *         {
     *             name: String
     *             confidence: Double
     *             rectangle: (recursive schema, see rectangle above)
     *         }
     *     ]
     *     requestId: String
     *     metadata: {
     *         width: Integer
     *         height: Integer
     *         format: String
     *     }
     *     modelVersion: String
     * }
     * }</pre>
     *
     * @param imageUrl A JSON document with a URL pointing to the image that is to be analyzed.
     * @param requestOptions The options to configure the HTTP request before HTTP client sends it.
     * @throws HttpResponseException thrown if the request is rejected by server.
     * @throws ClientAuthenticationException thrown if the request is rejected by server on status code 401.
     * @throws ResourceNotFoundException thrown if the request is rejected by server on status code 404.
     * @throws ResourceModifiedException thrown if the request is rejected by server on status code 409.
     * @return result of AnalyzeImage operation along with {@link Response}.
     */
    @Generated
    @ServiceMethod(returns = ReturnType.SINGLE)
    public Response<BinaryData> analyzeImageWithResponse(BinaryData imageUrl, RequestOptions requestOptions) {
        return this.client.analyzeImageWithResponse(imageUrl, requestOptions).block();
    }

    /**
     * This operation generates a description of an image in human readable language with complete sentences. The
     * description is based on a collection of content tags, which are also returned by the operation. More than one
     * description can be generated for each image. Descriptions are ordered by their confidence score. Descriptions may
     * include results from celebrity and landmark domain models, if applicable. Two input methods are supported -- (1)
     * Uploading an image or (2) specifying an image URL. A successful response will be returned in JSON. If the request
     * failed, the response will contain an error code and a message to help understand what went wrong.
     *
     * <p><strong>Query Parameters</strong>
     *
     * <table border="1">
     *     <caption>Query Parameters</caption>
     *     <tr><th>Name</th><th>Type</th><th>Required</th><th>Description</th></tr>
     *     <tr><td>maxCandidates</td><td>Integer</td><td>No</td><td>Maximum number of candidate descriptions to be returned.  The default is 1.</td></tr>
     *     <tr><td>language</td><td>String</td><td>No</td><td>The desired language for output generation. If this parameter is not specified, the default value is "en". See https://aka.ms/cv-languages for list of supported languages.</td></tr>
     *     <tr><td>descriptionExclude</td><td>List&lt;String&gt;</td><td>No</td><td>Turn off specified domain models when generating the description. In the form of "," separated string.</td></tr>
     *     <tr><td>model-version</td><td>String</td><td>No</td><td>Optional parameter to specify the version of the AI model. Accepted values are: "latest", "2021-04-01", "2021-05-01". Defaults to "latest".</td></tr>
     * </table>
     *
     * <p><strong>Request Body Schema</strong>
     *
     * <pre>{@code
     * {
     *     url: String
     * }
     * }</pre>
     *
     * <p><strong>Response Body Schema</strong>
     *
     * <pre>{@code
     * {
     *     description: {
     *         tags: [
     *             String
     *         ]
     *         captions: [
     *             {
     *                 text: String
     *                 confidence: Double
     *             }
     *         ]
     *     }
     *     requestId: String
     *     metadata: {
     *         width: Integer
     *         height: Integer
     *         format: String
     *     }
     *     modelVersion: String
     * }
     * }</pre>
     *
     * @param imageUrl A JSON document with a URL pointing to the image that is to be analyzed.
     * @param requestOptions The options to configure the HTTP request before HTTP client sends it.
     * @throws HttpResponseException thrown if the request is rejected by server.
     * @throws ClientAuthenticationException thrown if the request is rejected by server on status code 401.
     * @throws ResourceNotFoundException thrown if the request is rejected by server on status code 404.
     * @throws ResourceModifiedException thrown if the request is rejected by server on status code 409.
     * @return a collection of content tags, along with a list of captions sorted by confidence level, and image
     *     metadata along with {@link Response}.
     */
    @Generated
    @ServiceMethod(returns = ReturnType.SINGLE)
    public Response<BinaryData> describeImageWithResponse(BinaryData imageUrl, RequestOptions requestOptions) {
        return this.client.describeImageWithResponse(imageUrl, requestOptions).block();
    }

    /**
     * Performs object detection on the specified image. Two input methods are supported -- (1) Uploading an image or
     * (2) specifying an image URL. A successful response will be returned in JSON. If the request failed, the response
     * will contain an error code and a message to help understand what went wrong.
     *
     * <p><strong>Query Parameters</strong>
     *
     * <table border="1">
     *     <caption>Query Parameters</caption>
     *     <tr><th>Name</th><th>Type</th><th>Required</th><th>Description</th></tr>
     *     <tr><td>model-version</td><td>String</td><td>No</td><td>Optional parameter to specify the version of the AI model. Accepted values are: "latest", "2021-04-01", "2021-05-01". Defaults to "latest".</td></tr>
     * </table>
     *
     * <p><strong>Request Body Schema</strong>
     *
     * <pre>{@code
     * {
     *     url: String
     * }
     * }</pre>
     *
     * <p><strong>Response Body Schema</strong>
     *
     * <pre>{@code
     * {
     *     objects: [
     *         {
     *             rectangle: {
     *                 x: Integer
     *                 y: Integer
     *                 w: Integer
     *                 h: Integer
     *             }
     *             object: String
     *             confidence: Double
     *             parent: {
     *                 object: String
     *                 confidence: Double
     *                 parent: (recursive schema, see parent above)
     *             }
     *         }
     *     ]
     *     requestId: String
     *     metadata: {
     *         width: Integer
     *         height: Integer
     *         format: String
     *     }
     *     modelVersion: String
     * }
     * }</pre>
     *
     * @param imageUrl A JSON document with a URL pointing to the image that is to be analyzed.
     * @param requestOptions The options to configure the HTTP request before HTTP client sends it.
     * @throws HttpResponseException thrown if the request is rejected by server.
     * @throws ClientAuthenticationException thrown if the request is rejected by server on status code 401.
     * @throws ResourceNotFoundException thrown if the request is rejected by server on status code 404.
     * @throws ResourceModifiedException thrown if the request is rejected by server on status code 409.
     * @return result of a DetectImage call along with {@link Response}.
     */
    @Generated
    @ServiceMethod(returns = ReturnType.SINGLE)
    public Response<BinaryData> detectObjectsWithResponse(BinaryData imageUrl, RequestOptions requestOptions) {
        return this.client.detectObjectsWithResponse(imageUrl, requestOptions).block();
    }

    /**
     * This operation returns the list of domain-specific models that are supported by the Computer Vision API.
     * Currently, the API supports following domain-specific models: celebrity recognizer, landmark recognizer. A
     * successful response will be returned in JSON. If the request failed, the response will contain an error code and
     * a message to help understand what went wrong.
     *
     * <p><strong>Response Body Schema</strong>
     *
     * <pre>{@code
     * {
     *     models: [
     *         {
     *             name: String
     *             categories: [
     *                 String
     *             ]
     *         }
     *     ]
     * }
     * }</pre>
     *
     * @param requestOptions The options to configure the HTTP request before HTTP client sends it.
     * @throws HttpResponseException thrown if the request is rejected by server.
     * @throws ClientAuthenticationException thrown if the request is rejected by server on status code 401.
     * @throws ResourceNotFoundException thrown if the request is rejected by server on status code 404.
     * @throws ResourceModifiedException thrown if the request is rejected by server on status code 409.
     * @return result of the List Domain Models operation along with {@link Response}.
     */
    @Generated
    @ServiceMethod(returns = ReturnType.SINGLE)
    public Response<BinaryData> listModelsWithResponse(RequestOptions requestOptions) {
        return this.client.listModelsWithResponse(requestOptions).block();
    }

    /**
     * This operation recognizes content within an image by applying a domain-specific model. The list of
     * domain-specific models that are supported by the Computer Vision API can be retrieved using the /models GET
     * request. Currently, the API provides following domain-specific models: celebrities, landmarks. Two input methods
     * are supported -- (1) Uploading an image or (2) specifying an image URL. A successful response will be returned in
     * JSON. If the request failed, the response will contain an error code and a message to help understand what went
     * wrong.
     *
     * <p><strong>Query Parameters</strong>
     *
     * <table border="1">
     *     <caption>Query Parameters</caption>
     *     <tr><th>Name</th><th>Type</th><th>Required</th><th>Description</th></tr>
     *     <tr><td>language</td><td>String</td><td>No</td><td>The desired language for output generation. If this parameter is not specified, the default value is "en". See https://aka.ms/cv-languages for list of supported languages.</td></tr>
     *     <tr><td>model-version</td><td>String</td><td>No</td><td>Optional parameter to specify the version of the AI model. Accepted values are: "latest", "2021-04-01", "2021-05-01". Defaults to "latest".</td></tr>
     * </table>
     *
     * <p><strong>Request Body Schema</strong>
     *
     * <pre>{@code
     * {
     *     url: String
     * }
     * }</pre>
     *
     * <p><strong>Response Body Schema</strong>
     *
     * <pre>{@code
     * {
     *     result: Object
     *     requestId: String
     *     metadata: {
     *         width: Integer
     *         height: Integer
     *         format: String
     *     }
     *     modelVersion: String
     * }
     * }</pre>
     *
     * @param model The domain-specific content to recognize.
     * @param imageUrl A JSON document with a URL pointing to the image that is to be analyzed.
     * @param requestOptions The options to configure the HTTP request before HTTP client sends it.
     * @throws HttpResponseException thrown if the request is rejected by server.
     * @throws ClientAuthenticationException thrown if the request is rejected by server on status code 401.
     * @throws ResourceNotFoundException thrown if the request is rejected by server on status code 404.
     * @throws ResourceModifiedException thrown if the request is rejected by server on status code 409.
     * @return result of image analysis using a specific domain model including additional metadata along with {@link
     *     Response}.
     */
    @Generated
    @ServiceMethod(returns = ReturnType.SINGLE)
    public Response<BinaryData> analyzeImageByDomainWithResponse(
            String model, BinaryData imageUrl, RequestOptions requestOptions) {
        return this.client.analyzeImageByDomainWithResponse(model, imageUrl, requestOptions).block();
    }

    /**
     * Optical Character Recognition (OCR) detects text in an image and extracts the recognized characters into a
     * machine-usable character stream. Upon success, the OCR results will be returned. Upon failure, the error code
     * together with an error message will be returned. The error code can be one of InvalidImageUrl,
     * InvalidImageFormat, InvalidImageSize, NotSupportedImage, NotSupportedLanguage, or InternalServerError.
     *
     * <p><strong>Query Parameters</strong>
     *
     * <table border="1">
     *     <caption>Query Parameters</caption>
     *     <tr><th>Name</th><th>Type</th><th>Required</th><th>Description</th></tr>
     *     <tr><td>language</td><td>String</td><td>No</td><td>The BCP-47 language code of the text to be detected in the image. The default value is 'unk'.</td></tr>
     *     <tr><td>model-version</td><td>String</td><td>No</td><td>Optional parameter to specify the version of the AI model. Accepted values are: "latest", "2021-04-01", "2021-05-01". Defaults to "latest".</td></tr>
     * </table>
     *
     * <p><strong>Request Body Schema</strong>
     *
     * <pre>{@code
     * {
     *     url: String
     * }
     * }</pre>
     *
     * <p><strong>Response Body Schema</strong>
     *
     * <pre>{@code
     * {
     *     language: String
     *     textAngle: Double
     *     orientation: String
     *     regions: [
     *         {
     *             boundingBox: String
     *             lines: [
     *                 {
     *                     boundingBox: String
     *                     words: [
     *                         {
     *                             boundingBox: String
     *                             text: String
     *                         }
     *                     ]
     *                 }
     *             ]
     *         }
     *     ]
     *     modelVersion: String
     * }
     * }</pre>
     *
     * @param detectOrientation Whether detect the text orientation in the image. With detectOrientation=true the OCR
     *     service tries to detect the image orientation and correct it before further processing (e.g. if it's
     *     upside-down).
     * @param imageUrl A JSON document with a URL pointing to the image that is to be analyzed.
     * @param requestOptions The options to configure the HTTP request before HTTP client sends it.
     * @throws HttpResponseException thrown if the request is rejected by server.
     * @throws ClientAuthenticationException thrown if the request is rejected by server on status code 401.
     * @throws ResourceNotFoundException thrown if the request is rejected by server on status code 404.
     * @throws ResourceModifiedException thrown if the request is rejected by server on status code 409.
     * @return the response body along with {@link Response}.
     */
    @Generated
    @ServiceMethod(returns = ReturnType.SINGLE)
    public Response<BinaryData> recognizePrintedTextWithResponse(
            boolean detectOrientation, BinaryData imageUrl, RequestOptions requestOptions) {
        return this.client.recognizePrintedTextWithResponse(detectOrientation, imageUrl, requestOptions).block();
    }

    /**
     * This operation generates a list of words, or tags, that are relevant to the content of the supplied image. The
     * Computer Vision API can return tags based on objects, living beings, scenery or actions found in images. Unlike
     * categories, tags are not organized according to a hierarchical classification system, but correspond to image
     * content. Tags may contain hints to avoid ambiguity or provide context, for example the tag "ascomycete" may be
     * accompanied by the hint "fungus". Two input methods are supported -- (1) Uploading an image or (2) specifying an
     * image URL. A successful response will be returned in JSON. If the request failed, the response will contain an
     * error code and a message to help understand what went wrong.
     *
     * <p><strong>Query Parameters</strong>
     *
     * <table border="1">
     *     <caption>Query Parameters</caption>
     *     <tr><th>Name</th><th>Type</th><th>Required</th><th>Description</th></tr>
     *     <tr><td>language</td><td>String</td><td>No</td><td>The desired language for output generation. If this parameter is not specified, the default value is "en". See https://aka.ms/cv-languages for list of supported languages.</td></tr>
     *     <tr><td>model-version</td><td>String</td><td>No</td><td>Optional parameter to specify the version of the AI model. Accepted values are: "latest", "2021-04-01", "2021-05-01". Defaults to "latest".</td></tr>
     * </table>
     *
     * <p><strong>Request Body Schema</strong>
     *
     * <pre>{@code
     * {
     *     url: String
     * }
     * }</pre>
     *
     * <p><strong>Response Body Schema</strong>
     *
     * <pre>{@code
     * {
     *     tags: [
     *         {
     *             name: String
     *             confidence: Double
     *             hint: String
     *         }
     *     ]
     *     requestId: String
     *     metadata: {
     *         width: Integer
     *         height: Integer
     *         format: String
     *     }
     *     modelVersion: String
     * }
     * }</pre>
     *
     * @param imageUrl A JSON document with a URL pointing to the image that is to be analyzed.
     * @param requestOptions The options to configure the HTTP request before HTTP client sends it.
     * @throws HttpResponseException thrown if the request is rejected by server.
     * @throws ClientAuthenticationException thrown if the request is rejected by server on status code 401.
     * @throws ResourceNotFoundException thrown if the request is rejected by server on status code 404.
     * @throws ResourceModifiedException thrown if the request is rejected by server on status code 409.
     * @return the results of a image tag operation, including any tags and image metadata along with {@link Response}.
     */
    @Generated
    @ServiceMethod(returns = ReturnType.SINGLE)
    public Response<BinaryData> tagImageWithResponse(BinaryData imageUrl, RequestOptions requestOptions) {
        return this.client.tagImageWithResponse(imageUrl, requestOptions).block();
    }

    /**
     * This operation generates a thumbnail image with the user-specified width and height. By default, the service
     * analyzes the image, identifies the region of interest (ROI), and generates smart cropping coordinates based on
     * the ROI. Smart cropping helps when you specify an aspect ratio that differs from that of the input image. A
     * successful response contains the thumbnail image binary. If the request failed, the response contains an error
     * code and a message to help determine what went wrong. Upon failure, the error code and an error message are
     * returned. The error code could be one of InvalidImageUrl, InvalidImageFormat, InvalidImageSize,
     * InvalidThumbnailSize, NotSupportedImage, FailedToProcess, Timeout, or InternalServerError.
     *
     * <p><strong>Query Parameters</strong>
     *
     * <table border="1">
     *     <caption>Query Parameters</caption>
     *     <tr><th>Name</th><th>Type</th><th>Required</th><th>Description</th></tr>
     *     <tr><td>smartCropping</td><td>Boolean</td><td>No</td><td>Boolean flag for enabling smart cropping.</td></tr>
     *     <tr><td>model-version</td><td>String</td><td>No</td><td>Optional parameter to specify the version of the AI model. Accepted values are: "latest", "2021-04-01", "2021-05-01". Defaults to "latest".</td></tr>
     * </table>
     *
     * <p><strong>Request Body Schema</strong>
     *
     * <pre>{@code
     * {
     *     url: String
     * }
     * }</pre>
     *
     * @param width Width of the thumbnail, in pixels. It must be between 1 and 1024. Recommended minimum of 50.
     * @param height Height of the thumbnail, in pixels. It must be between 1 and 1024. Recommended minimum of 50.
     * @param imageUrl A JSON document with a URL pointing to the image that is to be analyzed.
     * @param requestOptions The options to configure the HTTP request before HTTP client sends it.
     * @throws HttpResponseException thrown if the request is rejected by server.
     * @throws ClientAuthenticationException thrown if the request is rejected by server on status code 401.
     * @throws ResourceNotFoundException thrown if the request is rejected by server on status code 404.
     * @throws ResourceModifiedException thrown if the request is rejected by server on status code 409.
     * @return the {@link Response}.
     */
    @Generated
    @ServiceMethod(returns = ReturnType.SINGLE)
    public Response<Void> generateThumbnailWithResponse(
            int width, int height, BinaryData imageUrl, RequestOptions requestOptions) {
        return this.client.generateThumbnailWithResponse(width, height, imageUrl, requestOptions).block();
    }

    /**
     * This operation returns a bounding box around the most important area of the image. A successful response will be
     * returned in JSON. If the request failed, the response contains an error code and a message to help determine what
     * went wrong. Upon failure, the error code and an error message are returned. The error code could be one of
     * InvalidImageUrl, InvalidImageFormat, InvalidImageSize, NotSupportedImage, FailedToProcess, Timeout, or
     * InternalServerError.
     *
     * <p><strong>Query Parameters</strong>
     *
     * <table border="1">
     *     <caption>Query Parameters</caption>
     *     <tr><th>Name</th><th>Type</th><th>Required</th><th>Description</th></tr>
     *     <tr><td>model-version</td><td>String</td><td>No</td><td>Optional parameter to specify the version of the AI model. Accepted values are: "latest", "2021-04-01", "2021-05-01". Defaults to "latest".</td></tr>
     * </table>
     *
     * <p><strong>Request Body Schema</strong>
     *
     * <pre>{@code
     * {
     *     url: String
     * }
     * }</pre>
     *
     * <p><strong>Response Body Schema</strong>
     *
     * <pre>{@code
     * {
     *     areaOfInterest: {
     *         x: Integer
     *         y: Integer
     *         w: Integer
     *         h: Integer
     *     }
     *     requestId: String
     *     metadata: {
     *         width: Integer
     *         height: Integer
     *         format: String
     *     }
     *     modelVersion: String
     * }
     * }</pre>
     *
     * @param imageUrl A JSON document with a URL pointing to the image that is to be analyzed.
     * @param requestOptions The options to configure the HTTP request before HTTP client sends it.
     * @throws HttpResponseException thrown if the request is rejected by server.
     * @throws ClientAuthenticationException thrown if the request is rejected by server on status code 401.
     * @throws ResourceNotFoundException thrown if the request is rejected by server on status code 404.
     * @throws ResourceModifiedException thrown if the request is rejected by server on status code 409.
     * @return result of AreaOfInterest operation along with {@link Response}.
     */
    @Generated
    @ServiceMethod(returns = ReturnType.SINGLE)
    public Response<BinaryData> getAreaOfInterestWithResponse(BinaryData imageUrl, RequestOptions requestOptions) {
        return this.client.getAreaOfInterestWithResponse(imageUrl, requestOptions).block();
    }

    /**
     * This operation extracts a rich set of visual features based on the image content. Two input methods are supported
     * -- (1) Uploading an image or (2) specifying an image URL. Within your request, there is an optional parameter to
     * allow you to choose which features to return. By default, image categories are returned in the response. A
     * successful response will be returned in JSON. If the request failed, the response will contain an error code and
     * a message to help understand what went wrong.
     *
     * <p><strong>Query Parameters</strong>
     *
     * <table border="1">
     *     <caption>Query Parameters</caption>
     *     <tr><th>Name</th><th>Type</th><th>Required</th><th>Description</th></tr>
     *     <tr><td>visualFeatures</td><td>List&lt;String&gt;</td><td>No</td><td>A string indicating what visual feature types to return. Multiple values should be comma-separated. Valid visual feature types include: Categories - categorizes image content according to a taxonomy defined in documentation. Tags - tags the image with a detailed list of words related to the image content. Description - describes the image content with a complete English sentence. Faces - detects if faces are present. If present, generate coordinates, gender and age. ImageType - detects if image is clipart or a line drawing. Color - determines the accent color, dominant color, and whether an image is black&amp;white. Adult - detects if the image is pornographic in nature (depicts nudity or a sex act), or is gory (depicts extreme violence or blood). Sexually suggestive content (aka racy content) is also detected. Objects - detects various objects within an image, including the approximate location. The Objects argument is only available in English. Brands - detects various brands within an image, including the approximate location. The Brands argument is only available in English. In the form of "," separated string.</td></tr>
     *     <tr><td>details</td><td>List&lt;String&gt;</td><td>No</td><td>A string indicating which domain-specific details to return. Multiple values should be comma-separated. Valid visual feature types include: Celebrities - identifies celebrities if detected in the image, Landmarks - identifies notable landmarks in the image. In the form of "," separated string.</td></tr>
     *     <tr><td>language</td><td>String</td><td>No</td><td>The desired language for output generation. If this parameter is not specified, the default value is "en". See https://aka.ms/cv-languages for list of supported languages.</td></tr>
     *     <tr><td>descriptionExclude</td><td>List&lt;String&gt;</td><td>No</td><td>Turn off specified domain models when generating the description. In the form of "," separated string.</td></tr>
     *     <tr><td>model-version</td><td>String</td><td>No</td><td>Optional parameter to specify the version of the AI model. Accepted values are: "latest", "2021-04-01", "2021-05-01". Defaults to "latest".</td></tr>
     * </table>
     *
     * <p><strong>Request Body Schema</strong>
     *
     * <pre>{@code
     * Flux<ByteBuffer>
     * }</pre>
     *
     * <p><strong>Response Body Schema</strong>
     *
     * <pre>{@code
     * {
     *     categories: [
     *         {
     *             name: String
     *             score: Double
     *             detail: {
     *                 celebrities: [
     *                     {
     *                         name: String
     *                         confidence: Double
     *                         faceRectangle: {
     *                             left: Integer
     *                             top: Integer
     *                             width: Integer
     *                             height: Integer
     *                         }
     *                     }
     *                 ]
     *                 landmarks: [
     *                     {
     *                         name: String
     *                         confidence: Double
     *                     }
     *                 ]
     *             }
     *         }
     *     ]
     *     adult: {
     *         isAdultContent: Boolean
     *         isRacyContent: Boolean
     *         isGoryContent: Boolean
     *         adultScore: Double
     *         racyScore: Double
     *         goreScore: Double
     *     }
     *     color: {
     *         dominantColorForeground: String
     *         dominantColorBackground: String
     *         dominantColors: [
     *             String
     *         ]
     *         accentColor: String
     *         isBWImg: Boolean
     *     }
     *     imageType: {
     *         clipArtType: Integer
     *         lineDrawingType: Integer
     *     }
     *     tags: [
     *         {
     *             name: String
     *             confidence: Double
     *             hint: String
     *         }
     *     ]
     *     description: {
     *         tags: [
     *             String
     *         ]
     *         captions: [
     *             {
     *                 text: String
     *                 confidence: Double
     *             }
     *         ]
     *     }
     *     faces: [
     *         {
     *             age: Integer
     *             gender: String(Male/Female)
     *             faceRectangle: (recursive schema, see faceRectangle above)
     *         }
     *     ]
     *     objects: [
     *         {
     *             rectangle: {
     *                 x: Integer
     *                 y: Integer
     *                 w: Integer
     *                 h: Integer
     *             }
     *             object: String
     *             confidence: Double
     *             parent: {
     *                 object: String
     *                 confidence: Double
     *                 parent: (recursive schema, see parent above)
     *             }
     *         }
     *     ]
     *     brands: [
     *         {
     *             name: String
     *             confidence: Double
     *             rectangle: (recursive schema, see rectangle above)
     *         }
     *     ]
     *     requestId: String
     *     metadata: {
     *         width: Integer
     *         height: Integer
     *         format: String
     *     }
     *     modelVersion: String
     * }
     * }</pre>
     *
     * @param contentType Upload file type.
     * @param image An image stream.
     * @param contentLength The contentLength parameter.
     * @param requestOptions The options to configure the HTTP request before HTTP client sends it.
     * @throws HttpResponseException thrown if the request is rejected by server.
     * @throws ClientAuthenticationException thrown if the request is rejected by server on status code 401.
     * @throws ResourceNotFoundException thrown if the request is rejected by server on status code 404.
     * @throws ResourceModifiedException thrown if the request is rejected by server on status code 409.
     * @return result of AnalyzeImage operation along with {@link Response}.
     */
    @Generated
    @ServiceMethod(returns = ReturnType.SINGLE)
    public Response<BinaryData> analyzeImageInStreamWithResponse(
            String contentType, BinaryData image, long contentLength, RequestOptions requestOptions) {
        return this.client.analyzeImageInStreamWithResponse(contentType, image, contentLength, requestOptions).block();
    }

    /**
     * This operation returns a bounding box around the most important area of the image. A successful response will be
     * returned in JSON. If the request failed, the response contains an error code and a message to help determine what
     * went wrong. Upon failure, the error code and an error message are returned. The error code could be one of
     * InvalidImageUrl, InvalidImageFormat, InvalidImageSize, NotSupportedImage, FailedToProcess, Timeout, or
     * InternalServerError.
     *
     * <p><strong>Query Parameters</strong>
     *
     * <table border="1">
     *     <caption>Query Parameters</caption>
     *     <tr><th>Name</th><th>Type</th><th>Required</th><th>Description</th></tr>
     *     <tr><td>model-version</td><td>String</td><td>No</td><td>Optional parameter to specify the version of the AI model. Accepted values are: "latest", "2021-04-01", "2021-05-01". Defaults to "latest".</td></tr>
     * </table>
     *
     * <p><strong>Request Body Schema</strong>
     *
     * <pre>{@code
     * Flux<ByteBuffer>
     * }</pre>
     *
     * <p><strong>Response Body Schema</strong>
     *
     * <pre>{@code
     * {
     *     areaOfInterest: {
     *         x: Integer
     *         y: Integer
     *         w: Integer
     *         h: Integer
     *     }
     *     requestId: String
     *     metadata: {
     *         width: Integer
     *         height: Integer
     *         format: String
     *     }
     *     modelVersion: String
     * }
     * }</pre>
     *
     * @param contentType Upload file type.
     * @param image An image stream.
     * @param contentLength The contentLength parameter.
     * @param requestOptions The options to configure the HTTP request before HTTP client sends it.
     * @throws HttpResponseException thrown if the request is rejected by server.
     * @throws ClientAuthenticationException thrown if the request is rejected by server on status code 401.
     * @throws ResourceNotFoundException thrown if the request is rejected by server on status code 404.
     * @throws ResourceModifiedException thrown if the request is rejected by server on status code 409.
     * @return result of AreaOfInterest operation along with {@link Response}.
     */
    @Generated
    @ServiceMethod(returns = ReturnType.SINGLE)
    public Response<BinaryData> getAreaOfInterestInStreamWithResponse(
            String contentType, BinaryData image, long contentLength, RequestOptions requestOptions) {
        return this.client
                .getAreaOfInterestInStreamWithResponse(contentType, image, contentLength, requestOptions)
                .block();
    }

    /**
     * This operation generates a description of an image in human readable language with complete sentences. The
     * description is based on a collection of content tags, which are also returned by the operation. More than one
     * description can be generated for each image. Descriptions are ordered by their confidence score. Descriptions may
     * include results from celebrity and landmark domain models, if applicable. Two input methods are supported -- (1)
     * Uploading an image or (2) specifying an image URL. A successful response will be returned in JSON. If the request
     * failed, the response will contain an error code and a message to help understand what went wrong.
     *
     * <p><strong>Query Parameters</strong>
     *
     * <table border="1">
     *     <caption>Query Parameters</caption>
     *     <tr><th>Name</th><th>Type</th><th>Required</th><th>Description</th></tr>
     *     <tr><td>maxCandidates</td><td>Integer</td><td>No</td><td>Maximum number of candidate descriptions to be returned.  The default is 1.</td></tr>
     *     <tr><td>language</td><td>String</td><td>No</td><td>The desired language for output generation. If this parameter is not specified, the default value is "en". See https://aka.ms/cv-languages for list of supported languages.</td></tr>
     *     <tr><td>descriptionExclude</td><td>List&lt;String&gt;</td><td>No</td><td>Turn off specified domain models when generating the description. In the form of "," separated string.</td></tr>
     *     <tr><td>model-version</td><td>String</td><td>No</td><td>Optional parameter to specify the version of the AI model. Accepted values are: "latest", "2021-04-01", "2021-05-01". Defaults to "latest".</td></tr>
     * </table>
     *
     * <p><strong>Request Body Schema</strong>
     *
     * <pre>{@code
     * Flux<ByteBuffer>
     * }</pre>
     *
     * <p><strong>Response Body Schema</strong>
     *
     * <pre>{@code
     * {
     *     description: {
     *         tags: [
     *             String
     *         ]
     *         captions: [
     *             {
     *                 text: String
     *                 confidence: Double
     *             }
     *         ]
     *     }
     *     requestId: String
     *     metadata: {
     *         width: Integer
     *         height: Integer
     *         format: String
     *     }
     *     modelVersion: String
     * }
     * }</pre>
     *
     * @param contentType Upload file type.
     * @param image An image stream.
     * @param contentLength The contentLength parameter.
     * @param requestOptions The options to configure the HTTP request before HTTP client sends it.
     * @throws HttpResponseException thrown if the request is rejected by server.
     * @throws ClientAuthenticationException thrown if the request is rejected by server on status code 401.
     * @throws ResourceNotFoundException thrown if the request is rejected by server on status code 404.
     * @throws ResourceModifiedException thrown if the request is rejected by server on status code 409.
     * @return a collection of content tags, along with a list of captions sorted by confidence level, and image
     *     metadata along with {@link Response}.
     */
    @Generated
    @ServiceMethod(returns = ReturnType.SINGLE)
    public Response<BinaryData> describeImageInStreamWithResponse(
            String contentType, BinaryData image, long contentLength, RequestOptions requestOptions) {
        return this.client.describeImageInStreamWithResponse(contentType, image, contentLength, requestOptions).block();
    }

    /**
     * Performs object detection on the specified image. Two input methods are supported -- (1) Uploading an image or
     * (2) specifying an image URL. A successful response will be returned in JSON. If the request failed, the response
     * will contain an error code and a message to help understand what went wrong.
     *
     * <p><strong>Query Parameters</strong>
     *
     * <table border="1">
     *     <caption>Query Parameters</caption>
     *     <tr><th>Name</th><th>Type</th><th>Required</th><th>Description</th></tr>
     *     <tr><td>model-version</td><td>String</td><td>No</td><td>Optional parameter to specify the version of the AI model. Accepted values are: "latest", "2021-04-01", "2021-05-01". Defaults to "latest".</td></tr>
     * </table>
     *
     * <p><strong>Request Body Schema</strong>
     *
     * <pre>{@code
     * Flux<ByteBuffer>
     * }</pre>
     *
     * <p><strong>Response Body Schema</strong>
     *
     * <pre>{@code
     * {
     *     objects: [
     *         {
     *             rectangle: {
     *                 x: Integer
     *                 y: Integer
     *                 w: Integer
     *                 h: Integer
     *             }
     *             object: String
     *             confidence: Double
     *             parent: {
     *                 object: String
     *                 confidence: Double
     *                 parent: (recursive schema, see parent above)
     *             }
     *         }
     *     ]
     *     requestId: String
     *     metadata: {
     *         width: Integer
     *         height: Integer
     *         format: String
     *     }
     *     modelVersion: String
     * }
     * }</pre>
     *
     * @param contentType Upload file type.
     * @param image An image stream.
     * @param contentLength The contentLength parameter.
     * @param requestOptions The options to configure the HTTP request before HTTP client sends it.
     * @throws HttpResponseException thrown if the request is rejected by server.
     * @throws ClientAuthenticationException thrown if the request is rejected by server on status code 401.
     * @throws ResourceNotFoundException thrown if the request is rejected by server on status code 404.
     * @throws ResourceModifiedException thrown if the request is rejected by server on status code 409.
     * @return result of a DetectImage call along with {@link Response}.
     */
    @Generated
    @ServiceMethod(returns = ReturnType.SINGLE)
    public Response<BinaryData> detectObjectsInStreamWithResponse(
            String contentType, BinaryData image, long contentLength, RequestOptions requestOptions) {
        return this.client.detectObjectsInStreamWithResponse(contentType, image, contentLength, requestOptions).block();
    }

    /**
     * This operation generates a thumbnail image with the user-specified width and height. By default, the service
     * analyzes the image, identifies the region of interest (ROI), and generates smart cropping coordinates based on
     * the ROI. Smart cropping helps when you specify an aspect ratio that differs from that of the input image. A
     * successful response contains the thumbnail image binary. If the request failed, the response contains an error
     * code and a message to help determine what went wrong. Upon failure, the error code and an error message are
     * returned. The error code could be one of InvalidImageUrl, InvalidImageFormat, InvalidImageSize,
     * InvalidThumbnailSize, NotSupportedImage, FailedToProcess, Timeout, or InternalServerError.
     *
     * <p><strong>Query Parameters</strong>
     *
     * <table border="1">
     *     <caption>Query Parameters</caption>
     *     <tr><th>Name</th><th>Type</th><th>Required</th><th>Description</th></tr>
     *     <tr><td>smartCropping</td><td>Boolean</td><td>No</td><td>Boolean flag for enabling smart cropping.</td></tr>
     *     <tr><td>model-version</td><td>String</td><td>No</td><td>Optional parameter to specify the version of the AI model. Accepted values are: "latest", "2021-04-01", "2021-05-01". Defaults to "latest".</td></tr>
     * </table>
     *
     * <p><strong>Request Body Schema</strong>
     *
     * <pre>{@code
     * Flux<ByteBuffer>
     * }</pre>
     *
     * @param width Width of the thumbnail, in pixels. It must be between 1 and 1024. Recommended minimum of 50.
     * @param height Height of the thumbnail, in pixels. It must be between 1 and 1024. Recommended minimum of 50.
     * @param contentType Upload file type.
     * @param image An image stream.
     * @param contentLength The contentLength parameter.
     * @param requestOptions The options to configure the HTTP request before HTTP client sends it.
     * @throws HttpResponseException thrown if the request is rejected by server.
     * @throws ClientAuthenticationException thrown if the request is rejected by server on status code 401.
     * @throws ResourceNotFoundException thrown if the request is rejected by server on status code 404.
     * @throws ResourceModifiedException thrown if the request is rejected by server on status code 409.
     * @return the {@link Response}.
     */
    @Generated
    @ServiceMethod(returns = ReturnType.SINGLE)
    public Response<Void> generateThumbnailInStreamWithResponse(
            int width,
            int height,
            String contentType,
            BinaryData image,
            long contentLength,
            RequestOptions requestOptions) {
        return this.client
                .generateThumbnailInStreamWithResponse(width, height, contentType, image, contentLength, requestOptions)
                .block();
    }

    /**
     * This operation recognizes content within an image by applying a domain-specific model. The list of
     * domain-specific models that are supported by the Computer Vision API can be retrieved using the /models GET
     * request. Currently, the API provides following domain-specific models: celebrities, landmarks. Two input methods
     * are supported -- (1) Uploading an image or (2) specifying an image URL. A successful response will be returned in
     * JSON. If the request failed, the response will contain an error code and a message to help understand what went
     * wrong.
     *
     * <p><strong>Query Parameters</strong>
     *
     * <table border="1">
     *     <caption>Query Parameters</caption>
     *     <tr><th>Name</th><th>Type</th><th>Required</th><th>Description</th></tr>
     *     <tr><td>language</td><td>String</td><td>No</td><td>The desired language for output generation. If this parameter is not specified, the default value is "en". See https://aka.ms/cv-languages for list of supported languages.</td></tr>
     *     <tr><td>model-version</td><td>String</td><td>No</td><td>Optional parameter to specify the version of the AI model. Accepted values are: "latest", "2021-04-01", "2021-05-01". Defaults to "latest".</td></tr>
     * </table>
     *
     * <p><strong>Request Body Schema</strong>
     *
     * <pre>{@code
     * Flux<ByteBuffer>
     * }</pre>
     *
     * <p><strong>Response Body Schema</strong>
     *
     * <pre>{@code
     * {
     *     result: Object
     *     requestId: String
     *     metadata: {
     *         width: Integer
     *         height: Integer
     *         format: String
     *     }
     *     modelVersion: String
     * }
     * }</pre>
     *
     * @param model The domain-specific content to recognize.
     * @param contentType Upload file type.
     * @param image An image stream.
     * @param contentLength The contentLength parameter.
     * @param requestOptions The options to configure the HTTP request before HTTP client sends it.
     * @throws HttpResponseException thrown if the request is rejected by server.
     * @throws ClientAuthenticationException thrown if the request is rejected by server on status code 401.
     * @throws ResourceNotFoundException thrown if the request is rejected by server on status code 404.
     * @throws ResourceModifiedException thrown if the request is rejected by server on status code 409.
     * @return result of image analysis using a specific domain model including additional metadata along with {@link
     *     Response}.
     */
    @Generated
    @ServiceMethod(returns = ReturnType.SINGLE)
    public Response<BinaryData> analyzeImageByDomainInStreamWithResponse(
            String model, String contentType, BinaryData image, long contentLength, RequestOptions requestOptions) {
        return this.client
                .analyzeImageByDomainInStreamWithResponse(model, contentType, image, contentLength, requestOptions)
                .block();
    }

    /**
     * Optical Character Recognition (OCR) detects text in an image and extracts the recognized characters into a
     * machine-usable character stream. Upon success, the OCR results will be returned. Upon failure, the error code
     * together with an error message will be returned. The error code can be one of InvalidImageUrl,
     * InvalidImageFormat, InvalidImageSize, NotSupportedImage, NotSupportedLanguage, or InternalServerError.
     *
     * <p><strong>Query Parameters</strong>
     *
     * <table border="1">
     *     <caption>Query Parameters</caption>
     *     <tr><th>Name</th><th>Type</th><th>Required</th><th>Description</th></tr>
     *     <tr><td>language</td><td>String</td><td>No</td><td>The BCP-47 language code of the text to be detected in the image. The default value is 'unk'.</td></tr>
     *     <tr><td>model-version</td><td>String</td><td>No</td><td>Optional parameter to specify the version of the AI model. Accepted values are: "latest", "2021-04-01", "2021-05-01". Defaults to "latest".</td></tr>
     * </table>
     *
     * <p><strong>Request Body Schema</strong>
     *
     * <pre>{@code
     * Flux<ByteBuffer>
     * }</pre>
     *
     * <p><strong>Response Body Schema</strong>
     *
     * <pre>{@code
     * {
     *     language: String
     *     textAngle: Double
     *     orientation: String
     *     regions: [
     *         {
     *             boundingBox: String
     *             lines: [
     *                 {
     *                     boundingBox: String
     *                     words: [
     *                         {
     *                             boundingBox: String
     *                             text: String
     *                         }
     *                     ]
     *                 }
     *             ]
     *         }
     *     ]
     *     modelVersion: String
     * }
     * }</pre>
     *
     * @param detectOrientation Whether detect the text orientation in the image. With detectOrientation=true the OCR
     *     service tries to detect the image orientation and correct it before further processing (e.g. if it's
     *     upside-down).
     * @param contentType Upload file type.
     * @param image An image stream.
     * @param contentLength The contentLength parameter.
     * @param requestOptions The options to configure the HTTP request before HTTP client sends it.
     * @throws HttpResponseException thrown if the request is rejected by server.
     * @throws ClientAuthenticationException thrown if the request is rejected by server on status code 401.
     * @throws ResourceNotFoundException thrown if the request is rejected by server on status code 404.
     * @throws ResourceModifiedException thrown if the request is rejected by server on status code 409.
     * @return the response body along with {@link Response}.
     */
    @Generated
    @ServiceMethod(returns = ReturnType.SINGLE)
    public Response<BinaryData> recognizePrintedTextInStreamWithResponse(
            boolean detectOrientation,
            String contentType,
            BinaryData image,
            long contentLength,
            RequestOptions requestOptions) {
        return this.client
                .recognizePrintedTextInStreamWithResponse(
                        detectOrientation, contentType, image, contentLength, requestOptions)
                .block();
    }

    /**
     * This operation generates a list of words, or tags, that are relevant to the content of the supplied image. The
     * Computer Vision API can return tags based on objects, living beings, scenery or actions found in images. Unlike
     * categories, tags are not organized according to a hierarchical classification system, but correspond to image
     * content. Tags may contain hints to avoid ambiguity or provide context, for example the tag "ascomycete" may be
     * accompanied by the hint "fungus". Two input methods are supported -- (1) Uploading an image or (2) specifying an
     * image URL. A successful response will be returned in JSON. If the request failed, the response will contain an
     * error code and a message to help understand what went wrong.
     *
     * <p><strong>Query Parameters</strong>
     *
     * <table border="1">
     *     <caption>Query Parameters</caption>
     *     <tr><th>Name</th><th>Type</th><th>Required</th><th>Description</th></tr>
     *     <tr><td>language</td><td>String</td><td>No</td><td>The desired language for output generation. If this parameter is not specified, the default value is "en". See https://aka.ms/cv-languages for list of supported languages.</td></tr>
     *     <tr><td>model-version</td><td>String</td><td>No</td><td>Optional parameter to specify the version of the AI model. Accepted values are: "latest", "2021-04-01", "2021-05-01". Defaults to "latest".</td></tr>
     * </table>
     *
     * <p><strong>Request Body Schema</strong>
     *
     * <pre>{@code
     * Flux<ByteBuffer>
     * }</pre>
     *
     * <p><strong>Response Body Schema</strong>
     *
     * <pre>{@code
     * {
     *     tags: [
     *         {
     *             name: String
     *             confidence: Double
     *             hint: String
     *         }
     *     ]
     *     requestId: String
     *     metadata: {
     *         width: Integer
     *         height: Integer
     *         format: String
     *     }
     *     modelVersion: String
     * }
     * }</pre>
     *
     * @param contentType Upload file type.
     * @param image An image stream.
     * @param contentLength The contentLength parameter.
     * @param requestOptions The options to configure the HTTP request before HTTP client sends it.
     * @throws HttpResponseException thrown if the request is rejected by server.
     * @throws ClientAuthenticationException thrown if the request is rejected by server on status code 401.
     * @throws ResourceNotFoundException thrown if the request is rejected by server on status code 404.
     * @throws ResourceModifiedException thrown if the request is rejected by server on status code 409.
     * @return the results of a image tag operation, including any tags and image metadata along with {@link Response}.
     */
    @Generated
    @ServiceMethod(returns = ReturnType.SINGLE)
    public Response<BinaryData> tagImageInStreamWithResponse(
            String contentType, BinaryData image, long contentLength, RequestOptions requestOptions) {
        return this.client.tagImageInStreamWithResponse(contentType, image, contentLength, requestOptions).block();
    }

    /**
     * Use this interface to get the result of a Read operation, employing the state-of-the-art Optical Character
     * Recognition (OCR) algorithms optimized for text-heavy documents. When you use the Read interface, the response
     * contains a field called 'Operation-Location'. The 'Operation-Location' field contains the URL that you must use
     * for your 'GetReadResult' operation to access OCR results..
     *
     * <p><strong>Query Parameters</strong>
     *
     * <table border="1">
     *     <caption>Query Parameters</caption>
     *     <tr><th>Name</th><th>Type</th><th>Required</th><th>Description</th></tr>
     *     <tr><td>language</td><td>String</td><td>No</td><td>The BCP-47 language code of the text in the document. Read supports auto language identification and multi-language documents, so only provide a language code if you would like to force the document to be processed in that specific language. See https://aka.ms/ocr-languages for list of supported languages.</td></tr>
     *     <tr><td>pages</td><td>List&lt;String&gt;</td><td>No</td><td>Custom page numbers for multi-page documents(PDF/TIFF), input the number of the pages you want to get OCR result. For a range of pages, use a hyphen. Separate each page or range with a comma. In the form of "," separated string.</td></tr>
     *     <tr><td>model-version</td><td>String</td><td>No</td><td>Optional parameter to specify the version of the OCR model used for text extraction. Accepted values are: "latest", "latest-preview", "2021-04-12". Defaults to "latest".</td></tr>
     *     <tr><td>readingOrder</td><td>String</td><td>No</td><td>Optional parameter to specify which reading order algorithm should be applied when ordering the extract text elements. Can be either 'basic' or 'natural'. Will default to 'basic' if not specified</td></tr>
     * </table>
     *
     * <p><strong>Request Body Schema</strong>
     *
     * <pre>{@code
     * {
     *     url: String
     * }
     * }</pre>
     *
     * @param imageUrl A JSON document with a URL pointing to the image that is to be analyzed.
     * @param requestOptions The options to configure the HTTP request before HTTP client sends it.
     * @throws HttpResponseException thrown if the request is rejected by server.
     * @throws ClientAuthenticationException thrown if the request is rejected by server on status code 401.
     * @throws ResourceNotFoundException thrown if the request is rejected by server on status code 404.
     * @throws ResourceModifiedException thrown if the request is rejected by server on status code 409.
     * @return the {@link Response}.
     */
    @Generated
    @ServiceMethod(returns = ReturnType.SINGLE)
    public Response<Void> readWithResponse(BinaryData imageUrl, RequestOptions requestOptions) {
        return this.client.readWithResponse(imageUrl, requestOptions).block();
    }

    /**
     * This interface is used for getting OCR results of Read operation. The URL to this interface should be retrieved
     * from 'Operation-Location' field returned from Read interface.
     *
     * <p><strong>Response Body Schema</strong>
     *
     * <pre>{@code
     * {
     *     status: String(notStarted/running/failed/succeeded)
     *     createdDateTime: String
     *     lastUpdatedDateTime: String
     *     analyzeResult: {
     *         version: String
     *         modelVersion: String
     *         readResults: [
     *             {
     *                 page: int
     *                 language: String
     *                 angle: float
     *                 width: float
     *                 height: float
     *                 unit: String(pixel/inch)
     *                 lines: [
     *                     {
     *                         language: String
     *                         boundingBox: [
     *                             float
     *                         ]
     *                         appearance: {
     *                             style: {
     *                                 name: String(other/handwriting)
     *                                 confidence: float
     *                             }
     *                         }
     *                         text: String
     *                         words: [
     *                             {
     *                                 boundingBox: [
     *                                     float
     *                                 ]
     *                                 text: String
     *                                 confidence: float
     *                             }
     *                         ]
     *                     }
     *                 ]
     *             }
     *         ]
     *     }
     * }
     * }</pre>
     *
     * @param operationId Id of read operation returned in the response of the 'Read' interface.
     * @param requestOptions The options to configure the HTTP request before HTTP client sends it.
     * @throws HttpResponseException thrown if the request is rejected by server.
     * @throws ClientAuthenticationException thrown if the request is rejected by server on status code 401.
     * @throws ResourceNotFoundException thrown if the request is rejected by server on status code 404.
     * @throws ResourceModifiedException thrown if the request is rejected by server on status code 409.
     * @return oCR result of the read operation along with {@link Response}.
     */
    @Generated
    @ServiceMethod(returns = ReturnType.SINGLE)
    public Response<BinaryData> getReadResultWithResponse(String operationId, RequestOptions requestOptions) {
        return this.client.getReadResultWithResponse(operationId, requestOptions).block();
    }

    /**
     * Use this interface to get the result of a Read operation, employing the state-of-the-art Optical Character
     * Recognition (OCR) algorithms optimized for text-heavy documents. When you use the Read interface, the response
     * contains a field called 'Operation-Location'. The 'Operation-Location' field contains the URL that you must use
     * for your 'GetReadResult' operation to access OCR results..
     *
     * <p><strong>Query Parameters</strong>
     *
     * <table border="1">
     *     <caption>Query Parameters</caption>
     *     <tr><th>Name</th><th>Type</th><th>Required</th><th>Description</th></tr>
     *     <tr><td>language</td><td>String</td><td>No</td><td>The BCP-47 language code of the text in the document. Read supports auto language identification and multi-language documents, so only provide a language code if you would like to force the document to be processed in that specific language. See https://aka.ms/ocr-languages for list of supported languages.</td></tr>
     *     <tr><td>pages</td><td>List&lt;String&gt;</td><td>No</td><td>Custom page numbers for multi-page documents(PDF/TIFF), input the number of the pages you want to get OCR result. For a range of pages, use a hyphen. Separate each page or range with a comma. In the form of "," separated string.</td></tr>
     *     <tr><td>model-version</td><td>String</td><td>No</td><td>Optional parameter to specify the version of the OCR model used for text extraction. Accepted values are: "latest", "latest-preview", "2021-04-12". Defaults to "latest".</td></tr>
     *     <tr><td>readingOrder</td><td>String</td><td>No</td><td>Optional parameter to specify which reading order algorithm should be applied when ordering the extract text elements. Can be either 'basic' or 'natural'. Will default to 'basic' if not specified</td></tr>
     * </table>
     *
     * <p><strong>Request Body Schema</strong>
     *
     * <pre>{@code
     * Flux<ByteBuffer>
     * }</pre>
     *
     * @param image An image stream.
     * @param contentLength The contentLength parameter.
     * @param requestOptions The options to configure the HTTP request before HTTP client sends it.
     * @throws HttpResponseException thrown if the request is rejected by server.
     * @throws ClientAuthenticationException thrown if the request is rejected by server on status code 401.
     * @throws ResourceNotFoundException thrown if the request is rejected by server on status code 404.
     * @throws ResourceModifiedException thrown if the request is rejected by server on status code 409.
     * @return the {@link Response}.
     */
    @Generated
    @ServiceMethod(returns = ReturnType.SINGLE)
    public Response<Void> readInStreamWithResponse(
            BinaryData image, long contentLength, RequestOptions requestOptions) {
        return this.client.readInStreamWithResponse(image, contentLength, requestOptions).block();
    }
}
