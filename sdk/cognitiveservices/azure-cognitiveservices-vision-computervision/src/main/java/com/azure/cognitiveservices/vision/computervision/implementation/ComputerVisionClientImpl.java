// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT License.
// Code generated by Microsoft (R) AutoRest Code Generator.

package com.azure.cognitiveservices.vision.computervision.implementation;

import com.azure.core.annotation.BodyParam;
import com.azure.core.annotation.ExpectedResponses;
import com.azure.core.annotation.Get;
import com.azure.core.annotation.HeaderParam;
import com.azure.core.annotation.Host;
import com.azure.core.annotation.HostParam;
import com.azure.core.annotation.PathParam;
import com.azure.core.annotation.Post;
import com.azure.core.annotation.QueryParam;
import com.azure.core.annotation.ReturnType;
import com.azure.core.annotation.ServiceInterface;
import com.azure.core.annotation.ServiceMethod;
import com.azure.core.annotation.UnexpectedResponseExceptionType;
import com.azure.core.exception.ClientAuthenticationException;
import com.azure.core.exception.HttpResponseException;
import com.azure.core.exception.ResourceModifiedException;
import com.azure.core.exception.ResourceNotFoundException;
import com.azure.core.http.HttpPipeline;
import com.azure.core.http.HttpPipelineBuilder;
import com.azure.core.http.policy.CookiePolicy;
import com.azure.core.http.policy.RetryPolicy;
import com.azure.core.http.policy.UserAgentPolicy;
import com.azure.core.http.rest.RequestOptions;
import com.azure.core.http.rest.Response;
import com.azure.core.http.rest.RestProxy;
import com.azure.core.util.BinaryData;
import com.azure.core.util.Context;
import com.azure.core.util.FluxUtil;
import com.azure.core.util.serializer.JacksonAdapter;
import com.azure.core.util.serializer.SerializerAdapter;
import reactor.core.publisher.Mono;

/** Initializes a new instance of the ComputerVisionClient type. */
public final class ComputerVisionClientImpl {
    /** The proxy service used to perform REST calls. */
    private final ComputerVisionClientService service;

    /** Supported Cognitive Services endpoints. */
    private final String endpoint;

    /**
     * Gets Supported Cognitive Services endpoints.
     *
     * @return the endpoint value.
     */
    public String getEndpoint() {
        return this.endpoint;
    }

    /** The HTTP pipeline to send requests through. */
    private final HttpPipeline httpPipeline;

    /**
     * Gets The HTTP pipeline to send requests through.
     *
     * @return the httpPipeline value.
     */
    public HttpPipeline getHttpPipeline() {
        return this.httpPipeline;
    }

    /** The serializer to serialize an object into a string. */
    private final SerializerAdapter serializerAdapter;

    /**
     * Gets The serializer to serialize an object into a string.
     *
     * @return the serializerAdapter value.
     */
    public SerializerAdapter getSerializerAdapter() {
        return this.serializerAdapter;
    }

    /**
     * Initializes an instance of ComputerVisionClient client.
     *
     * @param endpoint Supported Cognitive Services endpoints.
     */
    public ComputerVisionClientImpl(String endpoint) {
        this(
                new HttpPipelineBuilder()
                        .policies(new UserAgentPolicy(), new RetryPolicy(), new CookiePolicy())
                        .build(),
                JacksonAdapter.createDefaultSerializerAdapter(),
                endpoint);
    }

    /**
     * Initializes an instance of ComputerVisionClient client.
     *
     * @param httpPipeline The HTTP pipeline to send requests through.
     * @param endpoint Supported Cognitive Services endpoints.
     */
    public ComputerVisionClientImpl(HttpPipeline httpPipeline, String endpoint) {
        this(httpPipeline, JacksonAdapter.createDefaultSerializerAdapter(), endpoint);
    }

    /**
     * Initializes an instance of ComputerVisionClient client.
     *
     * @param httpPipeline The HTTP pipeline to send requests through.
     * @param serializerAdapter The serializer to serialize an object into a string.
     * @param endpoint Supported Cognitive Services endpoints.
     */
    public ComputerVisionClientImpl(HttpPipeline httpPipeline, SerializerAdapter serializerAdapter, String endpoint) {
        this.httpPipeline = httpPipeline;
        this.serializerAdapter = serializerAdapter;
        this.endpoint = endpoint;
        this.service =
                RestProxy.create(ComputerVisionClientService.class, this.httpPipeline, this.getSerializerAdapter());
    }

    /**
     * The interface defining all the services for ComputerVisionClient to be used by the proxy service to perform REST
     * calls.
     */
    @Host("{Endpoint}/vision/v3.2")
    @ServiceInterface(name = "ComputerVisionClient")
    private interface ComputerVisionClientService {
        @Post("/analyze")
        @ExpectedResponses({200})
        @UnexpectedResponseExceptionType(
                value = ClientAuthenticationException.class,
                code = {401})
        @UnexpectedResponseExceptionType(
                value = ResourceNotFoundException.class,
                code = {404})
        @UnexpectedResponseExceptionType(
                value = ResourceModifiedException.class,
                code = {409})
        @UnexpectedResponseExceptionType(HttpResponseException.class)
        Mono<Response<BinaryData>> analyzeImage(
                @HostParam("Endpoint") String endpoint,
                @BodyParam("application/json") BinaryData imageUrl,
                @HeaderParam("Accept") String accept,
                RequestOptions requestOptions,
                Context context);

        @Post("/describe")
        @ExpectedResponses({200})
        @UnexpectedResponseExceptionType(
                value = ClientAuthenticationException.class,
                code = {401})
        @UnexpectedResponseExceptionType(
                value = ResourceNotFoundException.class,
                code = {404})
        @UnexpectedResponseExceptionType(
                value = ResourceModifiedException.class,
                code = {409})
        @UnexpectedResponseExceptionType(HttpResponseException.class)
        Mono<Response<BinaryData>> describeImage(
                @HostParam("Endpoint") String endpoint,
                @BodyParam("application/json") BinaryData imageUrl,
                @HeaderParam("Accept") String accept,
                RequestOptions requestOptions,
                Context context);

        @Post("/detect")
        @ExpectedResponses({200})
        @UnexpectedResponseExceptionType(
                value = ClientAuthenticationException.class,
                code = {401})
        @UnexpectedResponseExceptionType(
                value = ResourceNotFoundException.class,
                code = {404})
        @UnexpectedResponseExceptionType(
                value = ResourceModifiedException.class,
                code = {409})
        @UnexpectedResponseExceptionType(HttpResponseException.class)
        Mono<Response<BinaryData>> detectObjects(
                @HostParam("Endpoint") String endpoint,
                @BodyParam("application/json") BinaryData imageUrl,
                @HeaderParam("Accept") String accept,
                RequestOptions requestOptions,
                Context context);

        @Get("/models")
        @ExpectedResponses({200})
        @UnexpectedResponseExceptionType(
                value = ClientAuthenticationException.class,
                code = {401})
        @UnexpectedResponseExceptionType(
                value = ResourceNotFoundException.class,
                code = {404})
        @UnexpectedResponseExceptionType(
                value = ResourceModifiedException.class,
                code = {409})
        @UnexpectedResponseExceptionType(HttpResponseException.class)
        Mono<Response<BinaryData>> listModels(
                @HostParam("Endpoint") String endpoint,
                @HeaderParam("Accept") String accept,
                RequestOptions requestOptions,
                Context context);

        @Post("/models/{model}/analyze")
        @ExpectedResponses({200})
        @UnexpectedResponseExceptionType(
                value = ClientAuthenticationException.class,
                code = {401})
        @UnexpectedResponseExceptionType(
                value = ResourceNotFoundException.class,
                code = {404})
        @UnexpectedResponseExceptionType(
                value = ResourceModifiedException.class,
                code = {409})
        @UnexpectedResponseExceptionType(HttpResponseException.class)
        Mono<Response<BinaryData>> analyzeImageByDomain(
                @HostParam("Endpoint") String endpoint,
                @PathParam("model") String model,
                @BodyParam("application/json") BinaryData imageUrl,
                @HeaderParam("Accept") String accept,
                RequestOptions requestOptions,
                Context context);

        @Post("/ocr")
        @ExpectedResponses({200})
        @UnexpectedResponseExceptionType(
                value = ClientAuthenticationException.class,
                code = {401})
        @UnexpectedResponseExceptionType(
                value = ResourceNotFoundException.class,
                code = {404})
        @UnexpectedResponseExceptionType(
                value = ResourceModifiedException.class,
                code = {409})
        @UnexpectedResponseExceptionType(HttpResponseException.class)
        Mono<Response<BinaryData>> recognizePrintedText(
                @HostParam("Endpoint") String endpoint,
                @QueryParam("detectOrientation") boolean detectOrientation,
                @BodyParam("application/json") BinaryData imageUrl,
                @HeaderParam("Accept") String accept,
                RequestOptions requestOptions,
                Context context);

        @Post("/tag")
        @ExpectedResponses({200})
        @UnexpectedResponseExceptionType(
                value = ClientAuthenticationException.class,
                code = {401})
        @UnexpectedResponseExceptionType(
                value = ResourceNotFoundException.class,
                code = {404})
        @UnexpectedResponseExceptionType(
                value = ResourceModifiedException.class,
                code = {409})
        @UnexpectedResponseExceptionType(HttpResponseException.class)
        Mono<Response<BinaryData>> tagImage(
                @HostParam("Endpoint") String endpoint,
                @BodyParam("application/json") BinaryData imageUrl,
                @HeaderParam("Accept") String accept,
                RequestOptions requestOptions,
                Context context);

        @Post("/generateThumbnail")
        @ExpectedResponses({200})
        @UnexpectedResponseExceptionType(
                value = ClientAuthenticationException.class,
                code = {401})
        @UnexpectedResponseExceptionType(
                value = ResourceNotFoundException.class,
                code = {404})
        @UnexpectedResponseExceptionType(
                value = ResourceModifiedException.class,
                code = {409})
        @UnexpectedResponseExceptionType(HttpResponseException.class)
        Mono<Response<Void>> generateThumbnail(
                @HostParam("Endpoint") String endpoint,
                @QueryParam("width") int width,
                @QueryParam("height") int height,
                @BodyParam("application/json") BinaryData imageUrl,
                @HeaderParam("Accept") String accept,
                RequestOptions requestOptions,
                Context context);

        @Post("/areaOfInterest")
        @ExpectedResponses({200})
        @UnexpectedResponseExceptionType(
                value = ClientAuthenticationException.class,
                code = {401})
        @UnexpectedResponseExceptionType(
                value = ResourceNotFoundException.class,
                code = {404})
        @UnexpectedResponseExceptionType(
                value = ResourceModifiedException.class,
                code = {409})
        @UnexpectedResponseExceptionType(HttpResponseException.class)
        Mono<Response<BinaryData>> getAreaOfInterest(
                @HostParam("Endpoint") String endpoint,
                @BodyParam("application/json") BinaryData imageUrl,
                @HeaderParam("Accept") String accept,
                RequestOptions requestOptions,
                Context context);

        @Post("/analyze")
        @ExpectedResponses({200})
        @UnexpectedResponseExceptionType(
                value = ClientAuthenticationException.class,
                code = {401})
        @UnexpectedResponseExceptionType(
                value = ResourceNotFoundException.class,
                code = {404})
        @UnexpectedResponseExceptionType(
                value = ResourceModifiedException.class,
                code = {409})
        @UnexpectedResponseExceptionType(HttpResponseException.class)
        Mono<Response<BinaryData>> analyzeImageInStream(
                @HostParam("Endpoint") String endpoint,
                @HeaderParam("Content-Type") String contentType,
                @BodyParam("application/octet-stream") BinaryData image,
                @HeaderParam("Content-Length") long contentLength,
                @HeaderParam("Accept") String accept,
                RequestOptions requestOptions,
                Context context);

        @Post("/areaOfInterest")
        @ExpectedResponses({200})
        @UnexpectedResponseExceptionType(
                value = ClientAuthenticationException.class,
                code = {401})
        @UnexpectedResponseExceptionType(
                value = ResourceNotFoundException.class,
                code = {404})
        @UnexpectedResponseExceptionType(
                value = ResourceModifiedException.class,
                code = {409})
        @UnexpectedResponseExceptionType(HttpResponseException.class)
        Mono<Response<BinaryData>> getAreaOfInterestInStream(
                @HostParam("Endpoint") String endpoint,
                @HeaderParam("Content-Type") String contentType,
                @BodyParam("application/octet-stream") BinaryData image,
                @HeaderParam("Content-Length") long contentLength,
                @HeaderParam("Accept") String accept,
                RequestOptions requestOptions,
                Context context);

        @Post("/describe")
        @ExpectedResponses({200})
        @UnexpectedResponseExceptionType(
                value = ClientAuthenticationException.class,
                code = {401})
        @UnexpectedResponseExceptionType(
                value = ResourceNotFoundException.class,
                code = {404})
        @UnexpectedResponseExceptionType(
                value = ResourceModifiedException.class,
                code = {409})
        @UnexpectedResponseExceptionType(HttpResponseException.class)
        Mono<Response<BinaryData>> describeImageInStream(
                @HostParam("Endpoint") String endpoint,
                @HeaderParam("Content-Type") String contentType,
                @BodyParam("application/octet-stream") BinaryData image,
                @HeaderParam("Content-Length") long contentLength,
                @HeaderParam("Accept") String accept,
                RequestOptions requestOptions,
                Context context);

        @Post("/detect")
        @ExpectedResponses({200})
        @UnexpectedResponseExceptionType(
                value = ClientAuthenticationException.class,
                code = {401})
        @UnexpectedResponseExceptionType(
                value = ResourceNotFoundException.class,
                code = {404})
        @UnexpectedResponseExceptionType(
                value = ResourceModifiedException.class,
                code = {409})
        @UnexpectedResponseExceptionType(HttpResponseException.class)
        Mono<Response<BinaryData>> detectObjectsInStream(
                @HostParam("Endpoint") String endpoint,
                @HeaderParam("Content-Type") String contentType,
                @BodyParam("application/octet-stream") BinaryData image,
                @HeaderParam("Content-Length") long contentLength,
                @HeaderParam("Accept") String accept,
                RequestOptions requestOptions,
                Context context);

        @Post("/generateThumbnail")
        @ExpectedResponses({200})
        @UnexpectedResponseExceptionType(
                value = ClientAuthenticationException.class,
                code = {401})
        @UnexpectedResponseExceptionType(
                value = ResourceNotFoundException.class,
                code = {404})
        @UnexpectedResponseExceptionType(
                value = ResourceModifiedException.class,
                code = {409})
        @UnexpectedResponseExceptionType(HttpResponseException.class)
        Mono<Response<Void>> generateThumbnailInStream(
                @HostParam("Endpoint") String endpoint,
                @QueryParam("width") int width,
                @QueryParam("height") int height,
                @HeaderParam("Content-Type") String contentType,
                @BodyParam("application/octet-stream") BinaryData image,
                @HeaderParam("Content-Length") long contentLength,
                @HeaderParam("Accept") String accept,
                RequestOptions requestOptions,
                Context context);

        @Post("/models/{model}/analyze")
        @ExpectedResponses({200})
        @UnexpectedResponseExceptionType(
                value = ClientAuthenticationException.class,
                code = {401})
        @UnexpectedResponseExceptionType(
                value = ResourceNotFoundException.class,
                code = {404})
        @UnexpectedResponseExceptionType(
                value = ResourceModifiedException.class,
                code = {409})
        @UnexpectedResponseExceptionType(HttpResponseException.class)
        Mono<Response<BinaryData>> analyzeImageByDomainInStream(
                @HostParam("Endpoint") String endpoint,
                @PathParam("model") String model,
                @HeaderParam("Content-Type") String contentType,
                @BodyParam("application/octet-stream") BinaryData image,
                @HeaderParam("Content-Length") long contentLength,
                @HeaderParam("Accept") String accept,
                RequestOptions requestOptions,
                Context context);

        @Post("/ocr")
        @ExpectedResponses({200})
        @UnexpectedResponseExceptionType(
                value = ClientAuthenticationException.class,
                code = {401})
        @UnexpectedResponseExceptionType(
                value = ResourceNotFoundException.class,
                code = {404})
        @UnexpectedResponseExceptionType(
                value = ResourceModifiedException.class,
                code = {409})
        @UnexpectedResponseExceptionType(HttpResponseException.class)
        Mono<Response<BinaryData>> recognizePrintedTextInStream(
                @HostParam("Endpoint") String endpoint,
                @QueryParam("detectOrientation") boolean detectOrientation,
                @HeaderParam("Content-Type") String contentType,
                @BodyParam("application/octet-stream") BinaryData image,
                @HeaderParam("Content-Length") long contentLength,
                @HeaderParam("Accept") String accept,
                RequestOptions requestOptions,
                Context context);

        @Post("/tag")
        @ExpectedResponses({200})
        @UnexpectedResponseExceptionType(
                value = ClientAuthenticationException.class,
                code = {401})
        @UnexpectedResponseExceptionType(
                value = ResourceNotFoundException.class,
                code = {404})
        @UnexpectedResponseExceptionType(
                value = ResourceModifiedException.class,
                code = {409})
        @UnexpectedResponseExceptionType(HttpResponseException.class)
        Mono<Response<BinaryData>> tagImageInStream(
                @HostParam("Endpoint") String endpoint,
                @HeaderParam("Content-Type") String contentType,
                @BodyParam("application/octet-stream") BinaryData image,
                @HeaderParam("Content-Length") long contentLength,
                @HeaderParam("Accept") String accept,
                RequestOptions requestOptions,
                Context context);

        @Post("/read/analyze")
        @ExpectedResponses({202})
        @UnexpectedResponseExceptionType(
                value = ClientAuthenticationException.class,
                code = {401})
        @UnexpectedResponseExceptionType(
                value = ResourceNotFoundException.class,
                code = {404})
        @UnexpectedResponseExceptionType(
                value = ResourceModifiedException.class,
                code = {409})
        @UnexpectedResponseExceptionType(HttpResponseException.class)
        Mono<Response<Void>> read(
                @HostParam("Endpoint") String endpoint,
                @BodyParam("application/json") BinaryData imageUrl,
                @HeaderParam("Accept") String accept,
                RequestOptions requestOptions,
                Context context);

        @Get("/read/analyzeResults/{operationId}")
        @ExpectedResponses({200})
        @UnexpectedResponseExceptionType(
                value = ClientAuthenticationException.class,
                code = {401})
        @UnexpectedResponseExceptionType(
                value = ResourceNotFoundException.class,
                code = {404})
        @UnexpectedResponseExceptionType(
                value = ResourceModifiedException.class,
                code = {409})
        @UnexpectedResponseExceptionType(HttpResponseException.class)
        Mono<Response<BinaryData>> getReadResult(
                @HostParam("Endpoint") String endpoint,
                @PathParam("operationId") String operationId,
                @HeaderParam("Accept") String accept,
                RequestOptions requestOptions,
                Context context);

        @Post("/read/analyze")
        @ExpectedResponses({202})
        @UnexpectedResponseExceptionType(
                value = ClientAuthenticationException.class,
                code = {401})
        @UnexpectedResponseExceptionType(
                value = ResourceNotFoundException.class,
                code = {404})
        @UnexpectedResponseExceptionType(
                value = ResourceModifiedException.class,
                code = {409})
        @UnexpectedResponseExceptionType(HttpResponseException.class)
        Mono<Response<Void>> readInStream(
                @HostParam("Endpoint") String endpoint,
                @BodyParam("application/octet-stream") BinaryData image,
                @HeaderParam("Content-Length") long contentLength,
                @HeaderParam("Accept") String accept,
                RequestOptions requestOptions,
                Context context);
    }

    /**
     * This operation extracts a rich set of visual features based on the image content. Two input methods are supported
     * -- (1) Uploading an image or (2) specifying an image URL. Within your request, there is an optional parameter to
     * allow you to choose which features to return. By default, image categories are returned in the response. A
     * successful response will be returned in JSON. If the request failed, the response will contain an error code and
     * a message to help understand what went wrong.
     *
     * <p><strong>Query Parameters</strong>
     *
     * <table border="1">
     *     <caption>Query Parameters</caption>
     *     <tr><th>Name</th><th>Type</th><th>Required</th><th>Description</th></tr>
     *     <tr><td>visualFeatures</td><td>List&lt;String&gt;</td><td>No</td><td>A string indicating what visual feature types to return. Multiple values should be comma-separated. Valid visual feature types include: Categories - categorizes image content according to a taxonomy defined in documentation. Tags - tags the image with a detailed list of words related to the image content. Description - describes the image content with a complete English sentence. Faces - detects if faces are present. If present, generate coordinates, gender and age. ImageType - detects if image is clipart or a line drawing. Color - determines the accent color, dominant color, and whether an image is black&amp;white. Adult - detects if the image is pornographic in nature (depicts nudity or a sex act), or is gory (depicts extreme violence or blood). Sexually suggestive content (aka racy content) is also detected. Objects - detects various objects within an image, including the approximate location. The Objects argument is only available in English. Brands - detects various brands within an image, including the approximate location. The Brands argument is only available in English. In the form of "," separated string.</td></tr>
     *     <tr><td>details</td><td>List&lt;String&gt;</td><td>No</td><td>A string indicating which domain-specific details to return. Multiple values should be comma-separated. Valid visual feature types include: Celebrities - identifies celebrities if detected in the image, Landmarks - identifies notable landmarks in the image. In the form of "," separated string.</td></tr>
     *     <tr><td>language</td><td>String</td><td>No</td><td>The desired language for output generation. If this parameter is not specified, the default value is "en". See https://aka.ms/cv-languages for list of supported languages.</td></tr>
     *     <tr><td>descriptionExclude</td><td>List&lt;String&gt;</td><td>No</td><td>Turn off specified domain models when generating the description. In the form of "," separated string.</td></tr>
     *     <tr><td>model-version</td><td>String</td><td>No</td><td>Optional parameter to specify the version of the AI model. Accepted values are: "latest", "2021-04-01", "2021-05-01". Defaults to "latest".</td></tr>
     * </table>
     *
     * <p><strong>Request Body Schema</strong>
     *
     * <pre>{@code
     * {
     *     url: String
     * }
     * }</pre>
     *
     * <p><strong>Response Body Schema</strong>
     *
     * <pre>{@code
     * {
     *     categories: [
     *         {
     *             name: String
     *             score: Double
     *             detail: {
     *                 celebrities: [
     *                     {
     *                         name: String
     *                         confidence: Double
     *                         faceRectangle: {
     *                             left: Integer
     *                             top: Integer
     *                             width: Integer
     *                             height: Integer
     *                         }
     *                     }
     *                 ]
     *                 landmarks: [
     *                     {
     *                         name: String
     *                         confidence: Double
     *                     }
     *                 ]
     *             }
     *         }
     *     ]
     *     adult: {
     *         isAdultContent: Boolean
     *         isRacyContent: Boolean
     *         isGoryContent: Boolean
     *         adultScore: Double
     *         racyScore: Double
     *         goreScore: Double
     *     }
     *     color: {
     *         dominantColorForeground: String
     *         dominantColorBackground: String
     *         dominantColors: [
     *             String
     *         ]
     *         accentColor: String
     *         isBWImg: Boolean
     *     }
     *     imageType: {
     *         clipArtType: Integer
     *         lineDrawingType: Integer
     *     }
     *     tags: [
     *         {
     *             name: String
     *             confidence: Double
     *             hint: String
     *         }
     *     ]
     *     description: {
     *         tags: [
     *             String
     *         ]
     *         captions: [
     *             {
     *                 text: String
     *                 confidence: Double
     *             }
     *         ]
     *     }
     *     faces: [
     *         {
     *             age: Integer
     *             gender: String(Male/Female)
     *             faceRectangle: (recursive schema, see faceRectangle above)
     *         }
     *     ]
     *     objects: [
     *         {
     *             rectangle: {
     *                 x: Integer
     *                 y: Integer
     *                 w: Integer
     *                 h: Integer
     *             }
     *             object: String
     *             confidence: Double
     *             parent: {
     *                 object: String
     *                 confidence: Double
     *                 parent: (recursive schema, see parent above)
     *             }
     *         }
     *     ]
     *     brands: [
     *         {
     *             name: String
     *             confidence: Double
     *             rectangle: (recursive schema, see rectangle above)
     *         }
     *     ]
     *     requestId: String
     *     metadata: {
     *         width: Integer
     *         height: Integer
     *         format: String
     *     }
     *     modelVersion: String
     * }
     * }</pre>
     *
     * @param imageUrl A JSON document with a URL pointing to the image that is to be analyzed.
     * @param requestOptions The options to configure the HTTP request before HTTP client sends it.
     * @throws HttpResponseException thrown if the request is rejected by server.
     * @throws ClientAuthenticationException thrown if the request is rejected by server on status code 401.
     * @throws ResourceNotFoundException thrown if the request is rejected by server on status code 404.
     * @throws ResourceModifiedException thrown if the request is rejected by server on status code 409.
     * @return result of AnalyzeImage operation along with {@link Response} on successful completion of {@link Mono}.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    public Mono<Response<BinaryData>> analyzeImageWithResponseAsync(
            BinaryData imageUrl, RequestOptions requestOptions) {
        final String accept = "application/json";
        return FluxUtil.withContext(
                context -> service.analyzeImage(this.getEndpoint(), imageUrl, accept, requestOptions, context));
    }

    /**
     * This operation extracts a rich set of visual features based on the image content. Two input methods are supported
     * -- (1) Uploading an image or (2) specifying an image URL. Within your request, there is an optional parameter to
     * allow you to choose which features to return. By default, image categories are returned in the response. A
     * successful response will be returned in JSON. If the request failed, the response will contain an error code and
     * a message to help understand what went wrong.
     *
     * <p><strong>Query Parameters</strong>
     *
     * <table border="1">
     *     <caption>Query Parameters</caption>
     *     <tr><th>Name</th><th>Type</th><th>Required</th><th>Description</th></tr>
     *     <tr><td>visualFeatures</td><td>List&lt;String&gt;</td><td>No</td><td>A string indicating what visual feature types to return. Multiple values should be comma-separated. Valid visual feature types include: Categories - categorizes image content according to a taxonomy defined in documentation. Tags - tags the image with a detailed list of words related to the image content. Description - describes the image content with a complete English sentence. Faces - detects if faces are present. If present, generate coordinates, gender and age. ImageType - detects if image is clipart or a line drawing. Color - determines the accent color, dominant color, and whether an image is black&amp;white. Adult - detects if the image is pornographic in nature (depicts nudity or a sex act), or is gory (depicts extreme violence or blood). Sexually suggestive content (aka racy content) is also detected. Objects - detects various objects within an image, including the approximate location. The Objects argument is only available in English. Brands - detects various brands within an image, including the approximate location. The Brands argument is only available in English. In the form of "," separated string.</td></tr>
     *     <tr><td>details</td><td>List&lt;String&gt;</td><td>No</td><td>A string indicating which domain-specific details to return. Multiple values should be comma-separated. Valid visual feature types include: Celebrities - identifies celebrities if detected in the image, Landmarks - identifies notable landmarks in the image. In the form of "," separated string.</td></tr>
     *     <tr><td>language</td><td>String</td><td>No</td><td>The desired language for output generation. If this parameter is not specified, the default value is "en". See https://aka.ms/cv-languages for list of supported languages.</td></tr>
     *     <tr><td>descriptionExclude</td><td>List&lt;String&gt;</td><td>No</td><td>Turn off specified domain models when generating the description. In the form of "," separated string.</td></tr>
     *     <tr><td>model-version</td><td>String</td><td>No</td><td>Optional parameter to specify the version of the AI model. Accepted values are: "latest", "2021-04-01", "2021-05-01". Defaults to "latest".</td></tr>
     * </table>
     *
     * <p><strong>Request Body Schema</strong>
     *
     * <pre>{@code
     * {
     *     url: String
     * }
     * }</pre>
     *
     * <p><strong>Response Body Schema</strong>
     *
     * <pre>{@code
     * {
     *     categories: [
     *         {
     *             name: String
     *             score: Double
     *             detail: {
     *                 celebrities: [
     *                     {
     *                         name: String
     *                         confidence: Double
     *                         faceRectangle: {
     *                             left: Integer
     *                             top: Integer
     *                             width: Integer
     *                             height: Integer
     *                         }
     *                     }
     *                 ]
     *                 landmarks: [
     *                     {
     *                         name: String
     *                         confidence: Double
     *                     }
     *                 ]
     *             }
     *         }
     *     ]
     *     adult: {
     *         isAdultContent: Boolean
     *         isRacyContent: Boolean
     *         isGoryContent: Boolean
     *         adultScore: Double
     *         racyScore: Double
     *         goreScore: Double
     *     }
     *     color: {
     *         dominantColorForeground: String
     *         dominantColorBackground: String
     *         dominantColors: [
     *             String
     *         ]
     *         accentColor: String
     *         isBWImg: Boolean
     *     }
     *     imageType: {
     *         clipArtType: Integer
     *         lineDrawingType: Integer
     *     }
     *     tags: [
     *         {
     *             name: String
     *             confidence: Double
     *             hint: String
     *         }
     *     ]
     *     description: {
     *         tags: [
     *             String
     *         ]
     *         captions: [
     *             {
     *                 text: String
     *                 confidence: Double
     *             }
     *         ]
     *     }
     *     faces: [
     *         {
     *             age: Integer
     *             gender: String(Male/Female)
     *             faceRectangle: (recursive schema, see faceRectangle above)
     *         }
     *     ]
     *     objects: [
     *         {
     *             rectangle: {
     *                 x: Integer
     *                 y: Integer
     *                 w: Integer
     *                 h: Integer
     *             }
     *             object: String
     *             confidence: Double
     *             parent: {
     *                 object: String
     *                 confidence: Double
     *                 parent: (recursive schema, see parent above)
     *             }
     *         }
     *     ]
     *     brands: [
     *         {
     *             name: String
     *             confidence: Double
     *             rectangle: (recursive schema, see rectangle above)
     *         }
     *     ]
     *     requestId: String
     *     metadata: {
     *         width: Integer
     *         height: Integer
     *         format: String
     *     }
     *     modelVersion: String
     * }
     * }</pre>
     *
     * @param imageUrl A JSON document with a URL pointing to the image that is to be analyzed.
     * @param requestOptions The options to configure the HTTP request before HTTP client sends it.
     * @param context The context to associate with this operation.
     * @throws HttpResponseException thrown if the request is rejected by server.
     * @throws ClientAuthenticationException thrown if the request is rejected by server on status code 401.
     * @throws ResourceNotFoundException thrown if the request is rejected by server on status code 404.
     * @throws ResourceModifiedException thrown if the request is rejected by server on status code 409.
     * @return result of AnalyzeImage operation along with {@link Response} on successful completion of {@link Mono}.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    public Mono<Response<BinaryData>> analyzeImageWithResponseAsync(
            BinaryData imageUrl, RequestOptions requestOptions, Context context) {
        final String accept = "application/json";
        return service.analyzeImage(this.getEndpoint(), imageUrl, accept, requestOptions, context);
    }

    /**
     * This operation extracts a rich set of visual features based on the image content. Two input methods are supported
     * -- (1) Uploading an image or (2) specifying an image URL. Within your request, there is an optional parameter to
     * allow you to choose which features to return. By default, image categories are returned in the response. A
     * successful response will be returned in JSON. If the request failed, the response will contain an error code and
     * a message to help understand what went wrong.
     *
     * <p><strong>Query Parameters</strong>
     *
     * <table border="1">
     *     <caption>Query Parameters</caption>
     *     <tr><th>Name</th><th>Type</th><th>Required</th><th>Description</th></tr>
     *     <tr><td>visualFeatures</td><td>List&lt;String&gt;</td><td>No</td><td>A string indicating what visual feature types to return. Multiple values should be comma-separated. Valid visual feature types include: Categories - categorizes image content according to a taxonomy defined in documentation. Tags - tags the image with a detailed list of words related to the image content. Description - describes the image content with a complete English sentence. Faces - detects if faces are present. If present, generate coordinates, gender and age. ImageType - detects if image is clipart or a line drawing. Color - determines the accent color, dominant color, and whether an image is black&amp;white. Adult - detects if the image is pornographic in nature (depicts nudity or a sex act), or is gory (depicts extreme violence or blood). Sexually suggestive content (aka racy content) is also detected. Objects - detects various objects within an image, including the approximate location. The Objects argument is only available in English. Brands - detects various brands within an image, including the approximate location. The Brands argument is only available in English. In the form of "," separated string.</td></tr>
     *     <tr><td>details</td><td>List&lt;String&gt;</td><td>No</td><td>A string indicating which domain-specific details to return. Multiple values should be comma-separated. Valid visual feature types include: Celebrities - identifies celebrities if detected in the image, Landmarks - identifies notable landmarks in the image. In the form of "," separated string.</td></tr>
     *     <tr><td>language</td><td>String</td><td>No</td><td>The desired language for output generation. If this parameter is not specified, the default value is "en". See https://aka.ms/cv-languages for list of supported languages.</td></tr>
     *     <tr><td>descriptionExclude</td><td>List&lt;String&gt;</td><td>No</td><td>Turn off specified domain models when generating the description. In the form of "," separated string.</td></tr>
     *     <tr><td>model-version</td><td>String</td><td>No</td><td>Optional parameter to specify the version of the AI model. Accepted values are: "latest", "2021-04-01", "2021-05-01". Defaults to "latest".</td></tr>
     * </table>
     *
     * <p><strong>Request Body Schema</strong>
     *
     * <pre>{@code
     * {
     *     url: String
     * }
     * }</pre>
     *
     * <p><strong>Response Body Schema</strong>
     *
     * <pre>{@code
     * {
     *     categories: [
     *         {
     *             name: String
     *             score: Double
     *             detail: {
     *                 celebrities: [
     *                     {
     *                         name: String
     *                         confidence: Double
     *                         faceRectangle: {
     *                             left: Integer
     *                             top: Integer
     *                             width: Integer
     *                             height: Integer
     *                         }
     *                     }
     *                 ]
     *                 landmarks: [
     *                     {
     *                         name: String
     *                         confidence: Double
     *                     }
     *                 ]
     *             }
     *         }
     *     ]
     *     adult: {
     *         isAdultContent: Boolean
     *         isRacyContent: Boolean
     *         isGoryContent: Boolean
     *         adultScore: Double
     *         racyScore: Double
     *         goreScore: Double
     *     }
     *     color: {
     *         dominantColorForeground: String
     *         dominantColorBackground: String
     *         dominantColors: [
     *             String
     *         ]
     *         accentColor: String
     *         isBWImg: Boolean
     *     }
     *     imageType: {
     *         clipArtType: Integer
     *         lineDrawingType: Integer
     *     }
     *     tags: [
     *         {
     *             name: String
     *             confidence: Double
     *             hint: String
     *         }
     *     ]
     *     description: {
     *         tags: [
     *             String
     *         ]
     *         captions: [
     *             {
     *                 text: String
     *                 confidence: Double
     *             }
     *         ]
     *     }
     *     faces: [
     *         {
     *             age: Integer
     *             gender: String(Male/Female)
     *             faceRectangle: (recursive schema, see faceRectangle above)
     *         }
     *     ]
     *     objects: [
     *         {
     *             rectangle: {
     *                 x: Integer
     *                 y: Integer
     *                 w: Integer
     *                 h: Integer
     *             }
     *             object: String
     *             confidence: Double
     *             parent: {
     *                 object: String
     *                 confidence: Double
     *                 parent: (recursive schema, see parent above)
     *             }
     *         }
     *     ]
     *     brands: [
     *         {
     *             name: String
     *             confidence: Double
     *             rectangle: (recursive schema, see rectangle above)
     *         }
     *     ]
     *     requestId: String
     *     metadata: {
     *         width: Integer
     *         height: Integer
     *         format: String
     *     }
     *     modelVersion: String
     * }
     * }</pre>
     *
     * @param imageUrl A JSON document with a URL pointing to the image that is to be analyzed.
     * @param requestOptions The options to configure the HTTP request before HTTP client sends it.
     * @throws HttpResponseException thrown if the request is rejected by server.
     * @throws ClientAuthenticationException thrown if the request is rejected by server on status code 401.
     * @throws ResourceNotFoundException thrown if the request is rejected by server on status code 404.
     * @throws ResourceModifiedException thrown if the request is rejected by server on status code 409.
     * @return result of AnalyzeImage operation along with {@link Response}.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    public Response<BinaryData> analyzeImageWithResponse(BinaryData imageUrl, RequestOptions requestOptions) {
        return analyzeImageWithResponseAsync(imageUrl, requestOptions).block();
    }

    /**
     * This operation generates a description of an image in human readable language with complete sentences. The
     * description is based on a collection of content tags, which are also returned by the operation. More than one
     * description can be generated for each image. Descriptions are ordered by their confidence score. Descriptions may
     * include results from celebrity and landmark domain models, if applicable. Two input methods are supported -- (1)
     * Uploading an image or (2) specifying an image URL. A successful response will be returned in JSON. If the request
     * failed, the response will contain an error code and a message to help understand what went wrong.
     *
     * <p><strong>Query Parameters</strong>
     *
     * <table border="1">
     *     <caption>Query Parameters</caption>
     *     <tr><th>Name</th><th>Type</th><th>Required</th><th>Description</th></tr>
     *     <tr><td>maxCandidates</td><td>Integer</td><td>No</td><td>Maximum number of candidate descriptions to be returned.  The default is 1.</td></tr>
     *     <tr><td>language</td><td>String</td><td>No</td><td>The desired language for output generation. If this parameter is not specified, the default value is "en". See https://aka.ms/cv-languages for list of supported languages.</td></tr>
     *     <tr><td>descriptionExclude</td><td>List&lt;String&gt;</td><td>No</td><td>Turn off specified domain models when generating the description. In the form of "," separated string.</td></tr>
     *     <tr><td>model-version</td><td>String</td><td>No</td><td>Optional parameter to specify the version of the AI model. Accepted values are: "latest", "2021-04-01", "2021-05-01". Defaults to "latest".</td></tr>
     * </table>
     *
     * <p><strong>Request Body Schema</strong>
     *
     * <pre>{@code
     * {
     *     url: String
     * }
     * }</pre>
     *
     * <p><strong>Response Body Schema</strong>
     *
     * <pre>{@code
     * {
     *     description: {
     *         tags: [
     *             String
     *         ]
     *         captions: [
     *             {
     *                 text: String
     *                 confidence: Double
     *             }
     *         ]
     *     }
     *     requestId: String
     *     metadata: {
     *         width: Integer
     *         height: Integer
     *         format: String
     *     }
     *     modelVersion: String
     * }
     * }</pre>
     *
     * @param imageUrl A JSON document with a URL pointing to the image that is to be analyzed.
     * @param requestOptions The options to configure the HTTP request before HTTP client sends it.
     * @throws HttpResponseException thrown if the request is rejected by server.
     * @throws ClientAuthenticationException thrown if the request is rejected by server on status code 401.
     * @throws ResourceNotFoundException thrown if the request is rejected by server on status code 404.
     * @throws ResourceModifiedException thrown if the request is rejected by server on status code 409.
     * @return a collection of content tags, along with a list of captions sorted by confidence level, and image
     *     metadata along with {@link Response} on successful completion of {@link Mono}.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    public Mono<Response<BinaryData>> describeImageWithResponseAsync(
            BinaryData imageUrl, RequestOptions requestOptions) {
        final String accept = "application/json";
        return FluxUtil.withContext(
                context -> service.describeImage(this.getEndpoint(), imageUrl, accept, requestOptions, context));
    }

    /**
     * This operation generates a description of an image in human readable language with complete sentences. The
     * description is based on a collection of content tags, which are also returned by the operation. More than one
     * description can be generated for each image. Descriptions are ordered by their confidence score. Descriptions may
     * include results from celebrity and landmark domain models, if applicable. Two input methods are supported -- (1)
     * Uploading an image or (2) specifying an image URL. A successful response will be returned in JSON. If the request
     * failed, the response will contain an error code and a message to help understand what went wrong.
     *
     * <p><strong>Query Parameters</strong>
     *
     * <table border="1">
     *     <caption>Query Parameters</caption>
     *     <tr><th>Name</th><th>Type</th><th>Required</th><th>Description</th></tr>
     *     <tr><td>maxCandidates</td><td>Integer</td><td>No</td><td>Maximum number of candidate descriptions to be returned.  The default is 1.</td></tr>
     *     <tr><td>language</td><td>String</td><td>No</td><td>The desired language for output generation. If this parameter is not specified, the default value is "en". See https://aka.ms/cv-languages for list of supported languages.</td></tr>
     *     <tr><td>descriptionExclude</td><td>List&lt;String&gt;</td><td>No</td><td>Turn off specified domain models when generating the description. In the form of "," separated string.</td></tr>
     *     <tr><td>model-version</td><td>String</td><td>No</td><td>Optional parameter to specify the version of the AI model. Accepted values are: "latest", "2021-04-01", "2021-05-01". Defaults to "latest".</td></tr>
     * </table>
     *
     * <p><strong>Request Body Schema</strong>
     *
     * <pre>{@code
     * {
     *     url: String
     * }
     * }</pre>
     *
     * <p><strong>Response Body Schema</strong>
     *
     * <pre>{@code
     * {
     *     description: {
     *         tags: [
     *             String
     *         ]
     *         captions: [
     *             {
     *                 text: String
     *                 confidence: Double
     *             }
     *         ]
     *     }
     *     requestId: String
     *     metadata: {
     *         width: Integer
     *         height: Integer
     *         format: String
     *     }
     *     modelVersion: String
     * }
     * }</pre>
     *
     * @param imageUrl A JSON document with a URL pointing to the image that is to be analyzed.
     * @param requestOptions The options to configure the HTTP request before HTTP client sends it.
     * @param context The context to associate with this operation.
     * @throws HttpResponseException thrown if the request is rejected by server.
     * @throws ClientAuthenticationException thrown if the request is rejected by server on status code 401.
     * @throws ResourceNotFoundException thrown if the request is rejected by server on status code 404.
     * @throws ResourceModifiedException thrown if the request is rejected by server on status code 409.
     * @return a collection of content tags, along with a list of captions sorted by confidence level, and image
     *     metadata along with {@link Response} on successful completion of {@link Mono}.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    public Mono<Response<BinaryData>> describeImageWithResponseAsync(
            BinaryData imageUrl, RequestOptions requestOptions, Context context) {
        final String accept = "application/json";
        return service.describeImage(this.getEndpoint(), imageUrl, accept, requestOptions, context);
    }

    /**
     * This operation generates a description of an image in human readable language with complete sentences. The
     * description is based on a collection of content tags, which are also returned by the operation. More than one
     * description can be generated for each image. Descriptions are ordered by their confidence score. Descriptions may
     * include results from celebrity and landmark domain models, if applicable. Two input methods are supported -- (1)
     * Uploading an image or (2) specifying an image URL. A successful response will be returned in JSON. If the request
     * failed, the response will contain an error code and a message to help understand what went wrong.
     *
     * <p><strong>Query Parameters</strong>
     *
     * <table border="1">
     *     <caption>Query Parameters</caption>
     *     <tr><th>Name</th><th>Type</th><th>Required</th><th>Description</th></tr>
     *     <tr><td>maxCandidates</td><td>Integer</td><td>No</td><td>Maximum number of candidate descriptions to be returned.  The default is 1.</td></tr>
     *     <tr><td>language</td><td>String</td><td>No</td><td>The desired language for output generation. If this parameter is not specified, the default value is "en". See https://aka.ms/cv-languages for list of supported languages.</td></tr>
     *     <tr><td>descriptionExclude</td><td>List&lt;String&gt;</td><td>No</td><td>Turn off specified domain models when generating the description. In the form of "," separated string.</td></tr>
     *     <tr><td>model-version</td><td>String</td><td>No</td><td>Optional parameter to specify the version of the AI model. Accepted values are: "latest", "2021-04-01", "2021-05-01". Defaults to "latest".</td></tr>
     * </table>
     *
     * <p><strong>Request Body Schema</strong>
     *
     * <pre>{@code
     * {
     *     url: String
     * }
     * }</pre>
     *
     * <p><strong>Response Body Schema</strong>
     *
     * <pre>{@code
     * {
     *     description: {
     *         tags: [
     *             String
     *         ]
     *         captions: [
     *             {
     *                 text: String
     *                 confidence: Double
     *             }
     *         ]
     *     }
     *     requestId: String
     *     metadata: {
     *         width: Integer
     *         height: Integer
     *         format: String
     *     }
     *     modelVersion: String
     * }
     * }</pre>
     *
     * @param imageUrl A JSON document with a URL pointing to the image that is to be analyzed.
     * @param requestOptions The options to configure the HTTP request before HTTP client sends it.
     * @throws HttpResponseException thrown if the request is rejected by server.
     * @throws ClientAuthenticationException thrown if the request is rejected by server on status code 401.
     * @throws ResourceNotFoundException thrown if the request is rejected by server on status code 404.
     * @throws ResourceModifiedException thrown if the request is rejected by server on status code 409.
     * @return a collection of content tags, along with a list of captions sorted by confidence level, and image
     *     metadata along with {@link Response}.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    public Response<BinaryData> describeImageWithResponse(BinaryData imageUrl, RequestOptions requestOptions) {
        return describeImageWithResponseAsync(imageUrl, requestOptions).block();
    }

    /**
     * Performs object detection on the specified image. Two input methods are supported -- (1) Uploading an image or
     * (2) specifying an image URL. A successful response will be returned in JSON. If the request failed, the response
     * will contain an error code and a message to help understand what went wrong.
     *
     * <p><strong>Query Parameters</strong>
     *
     * <table border="1">
     *     <caption>Query Parameters</caption>
     *     <tr><th>Name</th><th>Type</th><th>Required</th><th>Description</th></tr>
     *     <tr><td>model-version</td><td>String</td><td>No</td><td>Optional parameter to specify the version of the AI model. Accepted values are: "latest", "2021-04-01", "2021-05-01". Defaults to "latest".</td></tr>
     * </table>
     *
     * <p><strong>Request Body Schema</strong>
     *
     * <pre>{@code
     * {
     *     url: String
     * }
     * }</pre>
     *
     * <p><strong>Response Body Schema</strong>
     *
     * <pre>{@code
     * {
     *     objects: [
     *         {
     *             rectangle: {
     *                 x: Integer
     *                 y: Integer
     *                 w: Integer
     *                 h: Integer
     *             }
     *             object: String
     *             confidence: Double
     *             parent: {
     *                 object: String
     *                 confidence: Double
     *                 parent: (recursive schema, see parent above)
     *             }
     *         }
     *     ]
     *     requestId: String
     *     metadata: {
     *         width: Integer
     *         height: Integer
     *         format: String
     *     }
     *     modelVersion: String
     * }
     * }</pre>
     *
     * @param imageUrl A JSON document with a URL pointing to the image that is to be analyzed.
     * @param requestOptions The options to configure the HTTP request before HTTP client sends it.
     * @throws HttpResponseException thrown if the request is rejected by server.
     * @throws ClientAuthenticationException thrown if the request is rejected by server on status code 401.
     * @throws ResourceNotFoundException thrown if the request is rejected by server on status code 404.
     * @throws ResourceModifiedException thrown if the request is rejected by server on status code 409.
     * @return result of a DetectImage call along with {@link Response} on successful completion of {@link Mono}.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    public Mono<Response<BinaryData>> detectObjectsWithResponseAsync(
            BinaryData imageUrl, RequestOptions requestOptions) {
        final String accept = "application/json";
        return FluxUtil.withContext(
                context -> service.detectObjects(this.getEndpoint(), imageUrl, accept, requestOptions, context));
    }

    /**
     * Performs object detection on the specified image. Two input methods are supported -- (1) Uploading an image or
     * (2) specifying an image URL. A successful response will be returned in JSON. If the request failed, the response
     * will contain an error code and a message to help understand what went wrong.
     *
     * <p><strong>Query Parameters</strong>
     *
     * <table border="1">
     *     <caption>Query Parameters</caption>
     *     <tr><th>Name</th><th>Type</th><th>Required</th><th>Description</th></tr>
     *     <tr><td>model-version</td><td>String</td><td>No</td><td>Optional parameter to specify the version of the AI model. Accepted values are: "latest", "2021-04-01", "2021-05-01". Defaults to "latest".</td></tr>
     * </table>
     *
     * <p><strong>Request Body Schema</strong>
     *
     * <pre>{@code
     * {
     *     url: String
     * }
     * }</pre>
     *
     * <p><strong>Response Body Schema</strong>
     *
     * <pre>{@code
     * {
     *     objects: [
     *         {
     *             rectangle: {
     *                 x: Integer
     *                 y: Integer
     *                 w: Integer
     *                 h: Integer
     *             }
     *             object: String
     *             confidence: Double
     *             parent: {
     *                 object: String
     *                 confidence: Double
     *                 parent: (recursive schema, see parent above)
     *             }
     *         }
     *     ]
     *     requestId: String
     *     metadata: {
     *         width: Integer
     *         height: Integer
     *         format: String
     *     }
     *     modelVersion: String
     * }
     * }</pre>
     *
     * @param imageUrl A JSON document with a URL pointing to the image that is to be analyzed.
     * @param requestOptions The options to configure the HTTP request before HTTP client sends it.
     * @param context The context to associate with this operation.
     * @throws HttpResponseException thrown if the request is rejected by server.
     * @throws ClientAuthenticationException thrown if the request is rejected by server on status code 401.
     * @throws ResourceNotFoundException thrown if the request is rejected by server on status code 404.
     * @throws ResourceModifiedException thrown if the request is rejected by server on status code 409.
     * @return result of a DetectImage call along with {@link Response} on successful completion of {@link Mono}.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    public Mono<Response<BinaryData>> detectObjectsWithResponseAsync(
            BinaryData imageUrl, RequestOptions requestOptions, Context context) {
        final String accept = "application/json";
        return service.detectObjects(this.getEndpoint(), imageUrl, accept, requestOptions, context);
    }

    /**
     * Performs object detection on the specified image. Two input methods are supported -- (1) Uploading an image or
     * (2) specifying an image URL. A successful response will be returned in JSON. If the request failed, the response
     * will contain an error code and a message to help understand what went wrong.
     *
     * <p><strong>Query Parameters</strong>
     *
     * <table border="1">
     *     <caption>Query Parameters</caption>
     *     <tr><th>Name</th><th>Type</th><th>Required</th><th>Description</th></tr>
     *     <tr><td>model-version</td><td>String</td><td>No</td><td>Optional parameter to specify the version of the AI model. Accepted values are: "latest", "2021-04-01", "2021-05-01". Defaults to "latest".</td></tr>
     * </table>
     *
     * <p><strong>Request Body Schema</strong>
     *
     * <pre>{@code
     * {
     *     url: String
     * }
     * }</pre>
     *
     * <p><strong>Response Body Schema</strong>
     *
     * <pre>{@code
     * {
     *     objects: [
     *         {
     *             rectangle: {
     *                 x: Integer
     *                 y: Integer
     *                 w: Integer
     *                 h: Integer
     *             }
     *             object: String
     *             confidence: Double
     *             parent: {
     *                 object: String
     *                 confidence: Double
     *                 parent: (recursive schema, see parent above)
     *             }
     *         }
     *     ]
     *     requestId: String
     *     metadata: {
     *         width: Integer
     *         height: Integer
     *         format: String
     *     }
     *     modelVersion: String
     * }
     * }</pre>
     *
     * @param imageUrl A JSON document with a URL pointing to the image that is to be analyzed.
     * @param requestOptions The options to configure the HTTP request before HTTP client sends it.
     * @throws HttpResponseException thrown if the request is rejected by server.
     * @throws ClientAuthenticationException thrown if the request is rejected by server on status code 401.
     * @throws ResourceNotFoundException thrown if the request is rejected by server on status code 404.
     * @throws ResourceModifiedException thrown if the request is rejected by server on status code 409.
     * @return result of a DetectImage call along with {@link Response}.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    public Response<BinaryData> detectObjectsWithResponse(BinaryData imageUrl, RequestOptions requestOptions) {
        return detectObjectsWithResponseAsync(imageUrl, requestOptions).block();
    }

    /**
     * This operation returns the list of domain-specific models that are supported by the Computer Vision API.
     * Currently, the API supports following domain-specific models: celebrity recognizer, landmark recognizer. A
     * successful response will be returned in JSON. If the request failed, the response will contain an error code and
     * a message to help understand what went wrong.
     *
     * <p><strong>Response Body Schema</strong>
     *
     * <pre>{@code
     * {
     *     models: [
     *         {
     *             name: String
     *             categories: [
     *                 String
     *             ]
     *         }
     *     ]
     * }
     * }</pre>
     *
     * @param requestOptions The options to configure the HTTP request before HTTP client sends it.
     * @throws HttpResponseException thrown if the request is rejected by server.
     * @throws ClientAuthenticationException thrown if the request is rejected by server on status code 401.
     * @throws ResourceNotFoundException thrown if the request is rejected by server on status code 404.
     * @throws ResourceModifiedException thrown if the request is rejected by server on status code 409.
     * @return result of the List Domain Models operation along with {@link Response} on successful completion of {@link
     *     Mono}.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    public Mono<Response<BinaryData>> listModelsWithResponseAsync(RequestOptions requestOptions) {
        final String accept = "application/json";
        return FluxUtil.withContext(context -> service.listModels(this.getEndpoint(), accept, requestOptions, context));
    }

    /**
     * This operation returns the list of domain-specific models that are supported by the Computer Vision API.
     * Currently, the API supports following domain-specific models: celebrity recognizer, landmark recognizer. A
     * successful response will be returned in JSON. If the request failed, the response will contain an error code and
     * a message to help understand what went wrong.
     *
     * <p><strong>Response Body Schema</strong>
     *
     * <pre>{@code
     * {
     *     models: [
     *         {
     *             name: String
     *             categories: [
     *                 String
     *             ]
     *         }
     *     ]
     * }
     * }</pre>
     *
     * @param requestOptions The options to configure the HTTP request before HTTP client sends it.
     * @param context The context to associate with this operation.
     * @throws HttpResponseException thrown if the request is rejected by server.
     * @throws ClientAuthenticationException thrown if the request is rejected by server on status code 401.
     * @throws ResourceNotFoundException thrown if the request is rejected by server on status code 404.
     * @throws ResourceModifiedException thrown if the request is rejected by server on status code 409.
     * @return result of the List Domain Models operation along with {@link Response} on successful completion of {@link
     *     Mono}.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    public Mono<Response<BinaryData>> listModelsWithResponseAsync(RequestOptions requestOptions, Context context) {
        final String accept = "application/json";
        return service.listModels(this.getEndpoint(), accept, requestOptions, context);
    }

    /**
     * This operation returns the list of domain-specific models that are supported by the Computer Vision API.
     * Currently, the API supports following domain-specific models: celebrity recognizer, landmark recognizer. A
     * successful response will be returned in JSON. If the request failed, the response will contain an error code and
     * a message to help understand what went wrong.
     *
     * <p><strong>Response Body Schema</strong>
     *
     * <pre>{@code
     * {
     *     models: [
     *         {
     *             name: String
     *             categories: [
     *                 String
     *             ]
     *         }
     *     ]
     * }
     * }</pre>
     *
     * @param requestOptions The options to configure the HTTP request before HTTP client sends it.
     * @throws HttpResponseException thrown if the request is rejected by server.
     * @throws ClientAuthenticationException thrown if the request is rejected by server on status code 401.
     * @throws ResourceNotFoundException thrown if the request is rejected by server on status code 404.
     * @throws ResourceModifiedException thrown if the request is rejected by server on status code 409.
     * @return result of the List Domain Models operation along with {@link Response}.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    public Response<BinaryData> listModelsWithResponse(RequestOptions requestOptions) {
        return listModelsWithResponseAsync(requestOptions).block();
    }

    /**
     * This operation recognizes content within an image by applying a domain-specific model. The list of
     * domain-specific models that are supported by the Computer Vision API can be retrieved using the /models GET
     * request. Currently, the API provides following domain-specific models: celebrities, landmarks. Two input methods
     * are supported -- (1) Uploading an image or (2) specifying an image URL. A successful response will be returned in
     * JSON. If the request failed, the response will contain an error code and a message to help understand what went
     * wrong.
     *
     * <p><strong>Query Parameters</strong>
     *
     * <table border="1">
     *     <caption>Query Parameters</caption>
     *     <tr><th>Name</th><th>Type</th><th>Required</th><th>Description</th></tr>
     *     <tr><td>language</td><td>String</td><td>No</td><td>The desired language for output generation. If this parameter is not specified, the default value is "en". See https://aka.ms/cv-languages for list of supported languages.</td></tr>
     *     <tr><td>model-version</td><td>String</td><td>No</td><td>Optional parameter to specify the version of the AI model. Accepted values are: "latest", "2021-04-01", "2021-05-01". Defaults to "latest".</td></tr>
     * </table>
     *
     * <p><strong>Request Body Schema</strong>
     *
     * <pre>{@code
     * {
     *     url: String
     * }
     * }</pre>
     *
     * <p><strong>Response Body Schema</strong>
     *
     * <pre>{@code
     * {
     *     result: Object
     *     requestId: String
     *     metadata: {
     *         width: Integer
     *         height: Integer
     *         format: String
     *     }
     *     modelVersion: String
     * }
     * }</pre>
     *
     * @param model The domain-specific content to recognize.
     * @param imageUrl A JSON document with a URL pointing to the image that is to be analyzed.
     * @param requestOptions The options to configure the HTTP request before HTTP client sends it.
     * @throws HttpResponseException thrown if the request is rejected by server.
     * @throws ClientAuthenticationException thrown if the request is rejected by server on status code 401.
     * @throws ResourceNotFoundException thrown if the request is rejected by server on status code 404.
     * @throws ResourceModifiedException thrown if the request is rejected by server on status code 409.
     * @return result of image analysis using a specific domain model including additional metadata along with {@link
     *     Response} on successful completion of {@link Mono}.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    public Mono<Response<BinaryData>> analyzeImageByDomainWithResponseAsync(
            String model, BinaryData imageUrl, RequestOptions requestOptions) {
        final String accept = "application/json";
        return FluxUtil.withContext(
                context ->
                        service.analyzeImageByDomain(
                                this.getEndpoint(), model, imageUrl, accept, requestOptions, context));
    }

    /**
     * This operation recognizes content within an image by applying a domain-specific model. The list of
     * domain-specific models that are supported by the Computer Vision API can be retrieved using the /models GET
     * request. Currently, the API provides following domain-specific models: celebrities, landmarks. Two input methods
     * are supported -- (1) Uploading an image or (2) specifying an image URL. A successful response will be returned in
     * JSON. If the request failed, the response will contain an error code and a message to help understand what went
     * wrong.
     *
     * <p><strong>Query Parameters</strong>
     *
     * <table border="1">
     *     <caption>Query Parameters</caption>
     *     <tr><th>Name</th><th>Type</th><th>Required</th><th>Description</th></tr>
     *     <tr><td>language</td><td>String</td><td>No</td><td>The desired language for output generation. If this parameter is not specified, the default value is "en". See https://aka.ms/cv-languages for list of supported languages.</td></tr>
     *     <tr><td>model-version</td><td>String</td><td>No</td><td>Optional parameter to specify the version of the AI model. Accepted values are: "latest", "2021-04-01", "2021-05-01". Defaults to "latest".</td></tr>
     * </table>
     *
     * <p><strong>Request Body Schema</strong>
     *
     * <pre>{@code
     * {
     *     url: String
     * }
     * }</pre>
     *
     * <p><strong>Response Body Schema</strong>
     *
     * <pre>{@code
     * {
     *     result: Object
     *     requestId: String
     *     metadata: {
     *         width: Integer
     *         height: Integer
     *         format: String
     *     }
     *     modelVersion: String
     * }
     * }</pre>
     *
     * @param model The domain-specific content to recognize.
     * @param imageUrl A JSON document with a URL pointing to the image that is to be analyzed.
     * @param requestOptions The options to configure the HTTP request before HTTP client sends it.
     * @param context The context to associate with this operation.
     * @throws HttpResponseException thrown if the request is rejected by server.
     * @throws ClientAuthenticationException thrown if the request is rejected by server on status code 401.
     * @throws ResourceNotFoundException thrown if the request is rejected by server on status code 404.
     * @throws ResourceModifiedException thrown if the request is rejected by server on status code 409.
     * @return result of image analysis using a specific domain model including additional metadata along with {@link
     *     Response} on successful completion of {@link Mono}.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    public Mono<Response<BinaryData>> analyzeImageByDomainWithResponseAsync(
            String model, BinaryData imageUrl, RequestOptions requestOptions, Context context) {
        final String accept = "application/json";
        return service.analyzeImageByDomain(this.getEndpoint(), model, imageUrl, accept, requestOptions, context);
    }

    /**
     * This operation recognizes content within an image by applying a domain-specific model. The list of
     * domain-specific models that are supported by the Computer Vision API can be retrieved using the /models GET
     * request. Currently, the API provides following domain-specific models: celebrities, landmarks. Two input methods
     * are supported -- (1) Uploading an image or (2) specifying an image URL. A successful response will be returned in
     * JSON. If the request failed, the response will contain an error code and a message to help understand what went
     * wrong.
     *
     * <p><strong>Query Parameters</strong>
     *
     * <table border="1">
     *     <caption>Query Parameters</caption>
     *     <tr><th>Name</th><th>Type</th><th>Required</th><th>Description</th></tr>
     *     <tr><td>language</td><td>String</td><td>No</td><td>The desired language for output generation. If this parameter is not specified, the default value is "en". See https://aka.ms/cv-languages for list of supported languages.</td></tr>
     *     <tr><td>model-version</td><td>String</td><td>No</td><td>Optional parameter to specify the version of the AI model. Accepted values are: "latest", "2021-04-01", "2021-05-01". Defaults to "latest".</td></tr>
     * </table>
     *
     * <p><strong>Request Body Schema</strong>
     *
     * <pre>{@code
     * {
     *     url: String
     * }
     * }</pre>
     *
     * <p><strong>Response Body Schema</strong>
     *
     * <pre>{@code
     * {
     *     result: Object
     *     requestId: String
     *     metadata: {
     *         width: Integer
     *         height: Integer
     *         format: String
     *     }
     *     modelVersion: String
     * }
     * }</pre>
     *
     * @param model The domain-specific content to recognize.
     * @param imageUrl A JSON document with a URL pointing to the image that is to be analyzed.
     * @param requestOptions The options to configure the HTTP request before HTTP client sends it.
     * @throws HttpResponseException thrown if the request is rejected by server.
     * @throws ClientAuthenticationException thrown if the request is rejected by server on status code 401.
     * @throws ResourceNotFoundException thrown if the request is rejected by server on status code 404.
     * @throws ResourceModifiedException thrown if the request is rejected by server on status code 409.
     * @return result of image analysis using a specific domain model including additional metadata along with {@link
     *     Response}.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    public Response<BinaryData> analyzeImageByDomainWithResponse(
            String model, BinaryData imageUrl, RequestOptions requestOptions) {
        return analyzeImageByDomainWithResponseAsync(model, imageUrl, requestOptions).block();
    }

    /**
     * Optical Character Recognition (OCR) detects text in an image and extracts the recognized characters into a
     * machine-usable character stream. Upon success, the OCR results will be returned. Upon failure, the error code
     * together with an error message will be returned. The error code can be one of InvalidImageUrl,
     * InvalidImageFormat, InvalidImageSize, NotSupportedImage, NotSupportedLanguage, or InternalServerError.
     *
     * <p><strong>Query Parameters</strong>
     *
     * <table border="1">
     *     <caption>Query Parameters</caption>
     *     <tr><th>Name</th><th>Type</th><th>Required</th><th>Description</th></tr>
     *     <tr><td>language</td><td>String</td><td>No</td><td>The BCP-47 language code of the text to be detected in the image. The default value is 'unk'.</td></tr>
     *     <tr><td>model-version</td><td>String</td><td>No</td><td>Optional parameter to specify the version of the AI model. Accepted values are: "latest", "2021-04-01", "2021-05-01". Defaults to "latest".</td></tr>
     * </table>
     *
     * <p><strong>Request Body Schema</strong>
     *
     * <pre>{@code
     * {
     *     url: String
     * }
     * }</pre>
     *
     * <p><strong>Response Body Schema</strong>
     *
     * <pre>{@code
     * {
     *     language: String
     *     textAngle: Double
     *     orientation: String
     *     regions: [
     *         {
     *             boundingBox: String
     *             lines: [
     *                 {
     *                     boundingBox: String
     *                     words: [
     *                         {
     *                             boundingBox: String
     *                             text: String
     *                         }
     *                     ]
     *                 }
     *             ]
     *         }
     *     ]
     *     modelVersion: String
     * }
     * }</pre>
     *
     * @param detectOrientation Whether detect the text orientation in the image. With detectOrientation=true the OCR
     *     service tries to detect the image orientation and correct it before further processing (e.g. if it's
     *     upside-down).
     * @param imageUrl A JSON document with a URL pointing to the image that is to be analyzed.
     * @param requestOptions The options to configure the HTTP request before HTTP client sends it.
     * @throws HttpResponseException thrown if the request is rejected by server.
     * @throws ClientAuthenticationException thrown if the request is rejected by server on status code 401.
     * @throws ResourceNotFoundException thrown if the request is rejected by server on status code 404.
     * @throws ResourceModifiedException thrown if the request is rejected by server on status code 409.
     * @return the response body along with {@link Response} on successful completion of {@link Mono}.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    public Mono<Response<BinaryData>> recognizePrintedTextWithResponseAsync(
            boolean detectOrientation, BinaryData imageUrl, RequestOptions requestOptions) {
        final String accept = "application/json";
        return FluxUtil.withContext(
                context ->
                        service.recognizePrintedText(
                                this.getEndpoint(), detectOrientation, imageUrl, accept, requestOptions, context));
    }

    /**
     * Optical Character Recognition (OCR) detects text in an image and extracts the recognized characters into a
     * machine-usable character stream. Upon success, the OCR results will be returned. Upon failure, the error code
     * together with an error message will be returned. The error code can be one of InvalidImageUrl,
     * InvalidImageFormat, InvalidImageSize, NotSupportedImage, NotSupportedLanguage, or InternalServerError.
     *
     * <p><strong>Query Parameters</strong>
     *
     * <table border="1">
     *     <caption>Query Parameters</caption>
     *     <tr><th>Name</th><th>Type</th><th>Required</th><th>Description</th></tr>
     *     <tr><td>language</td><td>String</td><td>No</td><td>The BCP-47 language code of the text to be detected in the image. The default value is 'unk'.</td></tr>
     *     <tr><td>model-version</td><td>String</td><td>No</td><td>Optional parameter to specify the version of the AI model. Accepted values are: "latest", "2021-04-01", "2021-05-01". Defaults to "latest".</td></tr>
     * </table>
     *
     * <p><strong>Request Body Schema</strong>
     *
     * <pre>{@code
     * {
     *     url: String
     * }
     * }</pre>
     *
     * <p><strong>Response Body Schema</strong>
     *
     * <pre>{@code
     * {
     *     language: String
     *     textAngle: Double
     *     orientation: String
     *     regions: [
     *         {
     *             boundingBox: String
     *             lines: [
     *                 {
     *                     boundingBox: String
     *                     words: [
     *                         {
     *                             boundingBox: String
     *                             text: String
     *                         }
     *                     ]
     *                 }
     *             ]
     *         }
     *     ]
     *     modelVersion: String
     * }
     * }</pre>
     *
     * @param detectOrientation Whether detect the text orientation in the image. With detectOrientation=true the OCR
     *     service tries to detect the image orientation and correct it before further processing (e.g. if it's
     *     upside-down).
     * @param imageUrl A JSON document with a URL pointing to the image that is to be analyzed.
     * @param requestOptions The options to configure the HTTP request before HTTP client sends it.
     * @param context The context to associate with this operation.
     * @throws HttpResponseException thrown if the request is rejected by server.
     * @throws ClientAuthenticationException thrown if the request is rejected by server on status code 401.
     * @throws ResourceNotFoundException thrown if the request is rejected by server on status code 404.
     * @throws ResourceModifiedException thrown if the request is rejected by server on status code 409.
     * @return the response body along with {@link Response} on successful completion of {@link Mono}.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    public Mono<Response<BinaryData>> recognizePrintedTextWithResponseAsync(
            boolean detectOrientation, BinaryData imageUrl, RequestOptions requestOptions, Context context) {
        final String accept = "application/json";
        return service.recognizePrintedText(
                this.getEndpoint(), detectOrientation, imageUrl, accept, requestOptions, context);
    }

    /**
     * Optical Character Recognition (OCR) detects text in an image and extracts the recognized characters into a
     * machine-usable character stream. Upon success, the OCR results will be returned. Upon failure, the error code
     * together with an error message will be returned. The error code can be one of InvalidImageUrl,
     * InvalidImageFormat, InvalidImageSize, NotSupportedImage, NotSupportedLanguage, or InternalServerError.
     *
     * <p><strong>Query Parameters</strong>
     *
     * <table border="1">
     *     <caption>Query Parameters</caption>
     *     <tr><th>Name</th><th>Type</th><th>Required</th><th>Description</th></tr>
     *     <tr><td>language</td><td>String</td><td>No</td><td>The BCP-47 language code of the text to be detected in the image. The default value is 'unk'.</td></tr>
     *     <tr><td>model-version</td><td>String</td><td>No</td><td>Optional parameter to specify the version of the AI model. Accepted values are: "latest", "2021-04-01", "2021-05-01". Defaults to "latest".</td></tr>
     * </table>
     *
     * <p><strong>Request Body Schema</strong>
     *
     * <pre>{@code
     * {
     *     url: String
     * }
     * }</pre>
     *
     * <p><strong>Response Body Schema</strong>
     *
     * <pre>{@code
     * {
     *     language: String
     *     textAngle: Double
     *     orientation: String
     *     regions: [
     *         {
     *             boundingBox: String
     *             lines: [
     *                 {
     *                     boundingBox: String
     *                     words: [
     *                         {
     *                             boundingBox: String
     *                             text: String
     *                         }
     *                     ]
     *                 }
     *             ]
     *         }
     *     ]
     *     modelVersion: String
     * }
     * }</pre>
     *
     * @param detectOrientation Whether detect the text orientation in the image. With detectOrientation=true the OCR
     *     service tries to detect the image orientation and correct it before further processing (e.g. if it's
     *     upside-down).
     * @param imageUrl A JSON document with a URL pointing to the image that is to be analyzed.
     * @param requestOptions The options to configure the HTTP request before HTTP client sends it.
     * @throws HttpResponseException thrown if the request is rejected by server.
     * @throws ClientAuthenticationException thrown if the request is rejected by server on status code 401.
     * @throws ResourceNotFoundException thrown if the request is rejected by server on status code 404.
     * @throws ResourceModifiedException thrown if the request is rejected by server on status code 409.
     * @return the response body along with {@link Response}.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    public Response<BinaryData> recognizePrintedTextWithResponse(
            boolean detectOrientation, BinaryData imageUrl, RequestOptions requestOptions) {
        return recognizePrintedTextWithResponseAsync(detectOrientation, imageUrl, requestOptions).block();
    }

    /**
     * This operation generates a list of words, or tags, that are relevant to the content of the supplied image. The
     * Computer Vision API can return tags based on objects, living beings, scenery or actions found in images. Unlike
     * categories, tags are not organized according to a hierarchical classification system, but correspond to image
     * content. Tags may contain hints to avoid ambiguity or provide context, for example the tag "ascomycete" may be
     * accompanied by the hint "fungus". Two input methods are supported -- (1) Uploading an image or (2) specifying an
     * image URL. A successful response will be returned in JSON. If the request failed, the response will contain an
     * error code and a message to help understand what went wrong.
     *
     * <p><strong>Query Parameters</strong>
     *
     * <table border="1">
     *     <caption>Query Parameters</caption>
     *     <tr><th>Name</th><th>Type</th><th>Required</th><th>Description</th></tr>
     *     <tr><td>language</td><td>String</td><td>No</td><td>The desired language for output generation. If this parameter is not specified, the default value is "en". See https://aka.ms/cv-languages for list of supported languages.</td></tr>
     *     <tr><td>model-version</td><td>String</td><td>No</td><td>Optional parameter to specify the version of the AI model. Accepted values are: "latest", "2021-04-01", "2021-05-01". Defaults to "latest".</td></tr>
     * </table>
     *
     * <p><strong>Request Body Schema</strong>
     *
     * <pre>{@code
     * {
     *     url: String
     * }
     * }</pre>
     *
     * <p><strong>Response Body Schema</strong>
     *
     * <pre>{@code
     * {
     *     tags: [
     *         {
     *             name: String
     *             confidence: Double
     *             hint: String
     *         }
     *     ]
     *     requestId: String
     *     metadata: {
     *         width: Integer
     *         height: Integer
     *         format: String
     *     }
     *     modelVersion: String
     * }
     * }</pre>
     *
     * @param imageUrl A JSON document with a URL pointing to the image that is to be analyzed.
     * @param requestOptions The options to configure the HTTP request before HTTP client sends it.
     * @throws HttpResponseException thrown if the request is rejected by server.
     * @throws ClientAuthenticationException thrown if the request is rejected by server on status code 401.
     * @throws ResourceNotFoundException thrown if the request is rejected by server on status code 404.
     * @throws ResourceModifiedException thrown if the request is rejected by server on status code 409.
     * @return the results of a image tag operation, including any tags and image metadata along with {@link Response}
     *     on successful completion of {@link Mono}.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    public Mono<Response<BinaryData>> tagImageWithResponseAsync(BinaryData imageUrl, RequestOptions requestOptions) {
        final String accept = "application/json";
        return FluxUtil.withContext(
                context -> service.tagImage(this.getEndpoint(), imageUrl, accept, requestOptions, context));
    }

    /**
     * This operation generates a list of words, or tags, that are relevant to the content of the supplied image. The
     * Computer Vision API can return tags based on objects, living beings, scenery or actions found in images. Unlike
     * categories, tags are not organized according to a hierarchical classification system, but correspond to image
     * content. Tags may contain hints to avoid ambiguity or provide context, for example the tag "ascomycete" may be
     * accompanied by the hint "fungus". Two input methods are supported -- (1) Uploading an image or (2) specifying an
     * image URL. A successful response will be returned in JSON. If the request failed, the response will contain an
     * error code and a message to help understand what went wrong.
     *
     * <p><strong>Query Parameters</strong>
     *
     * <table border="1">
     *     <caption>Query Parameters</caption>
     *     <tr><th>Name</th><th>Type</th><th>Required</th><th>Description</th></tr>
     *     <tr><td>language</td><td>String</td><td>No</td><td>The desired language for output generation. If this parameter is not specified, the default value is "en". See https://aka.ms/cv-languages for list of supported languages.</td></tr>
     *     <tr><td>model-version</td><td>String</td><td>No</td><td>Optional parameter to specify the version of the AI model. Accepted values are: "latest", "2021-04-01", "2021-05-01". Defaults to "latest".</td></tr>
     * </table>
     *
     * <p><strong>Request Body Schema</strong>
     *
     * <pre>{@code
     * {
     *     url: String
     * }
     * }</pre>
     *
     * <p><strong>Response Body Schema</strong>
     *
     * <pre>{@code
     * {
     *     tags: [
     *         {
     *             name: String
     *             confidence: Double
     *             hint: String
     *         }
     *     ]
     *     requestId: String
     *     metadata: {
     *         width: Integer
     *         height: Integer
     *         format: String
     *     }
     *     modelVersion: String
     * }
     * }</pre>
     *
     * @param imageUrl A JSON document with a URL pointing to the image that is to be analyzed.
     * @param requestOptions The options to configure the HTTP request before HTTP client sends it.
     * @param context The context to associate with this operation.
     * @throws HttpResponseException thrown if the request is rejected by server.
     * @throws ClientAuthenticationException thrown if the request is rejected by server on status code 401.
     * @throws ResourceNotFoundException thrown if the request is rejected by server on status code 404.
     * @throws ResourceModifiedException thrown if the request is rejected by server on status code 409.
     * @return the results of a image tag operation, including any tags and image metadata along with {@link Response}
     *     on successful completion of {@link Mono}.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    public Mono<Response<BinaryData>> tagImageWithResponseAsync(
            BinaryData imageUrl, RequestOptions requestOptions, Context context) {
        final String accept = "application/json";
        return service.tagImage(this.getEndpoint(), imageUrl, accept, requestOptions, context);
    }

    /**
     * This operation generates a list of words, or tags, that are relevant to the content of the supplied image. The
     * Computer Vision API can return tags based on objects, living beings, scenery or actions found in images. Unlike
     * categories, tags are not organized according to a hierarchical classification system, but correspond to image
     * content. Tags may contain hints to avoid ambiguity or provide context, for example the tag "ascomycete" may be
     * accompanied by the hint "fungus". Two input methods are supported -- (1) Uploading an image or (2) specifying an
     * image URL. A successful response will be returned in JSON. If the request failed, the response will contain an
     * error code and a message to help understand what went wrong.
     *
     * <p><strong>Query Parameters</strong>
     *
     * <table border="1">
     *     <caption>Query Parameters</caption>
     *     <tr><th>Name</th><th>Type</th><th>Required</th><th>Description</th></tr>
     *     <tr><td>language</td><td>String</td><td>No</td><td>The desired language for output generation. If this parameter is not specified, the default value is "en". See https://aka.ms/cv-languages for list of supported languages.</td></tr>
     *     <tr><td>model-version</td><td>String</td><td>No</td><td>Optional parameter to specify the version of the AI model. Accepted values are: "latest", "2021-04-01", "2021-05-01". Defaults to "latest".</td></tr>
     * </table>
     *
     * <p><strong>Request Body Schema</strong>
     *
     * <pre>{@code
     * {
     *     url: String
     * }
     * }</pre>
     *
     * <p><strong>Response Body Schema</strong>
     *
     * <pre>{@code
     * {
     *     tags: [
     *         {
     *             name: String
     *             confidence: Double
     *             hint: String
     *         }
     *     ]
     *     requestId: String
     *     metadata: {
     *         width: Integer
     *         height: Integer
     *         format: String
     *     }
     *     modelVersion: String
     * }
     * }</pre>
     *
     * @param imageUrl A JSON document with a URL pointing to the image that is to be analyzed.
     * @param requestOptions The options to configure the HTTP request before HTTP client sends it.
     * @throws HttpResponseException thrown if the request is rejected by server.
     * @throws ClientAuthenticationException thrown if the request is rejected by server on status code 401.
     * @throws ResourceNotFoundException thrown if the request is rejected by server on status code 404.
     * @throws ResourceModifiedException thrown if the request is rejected by server on status code 409.
     * @return the results of a image tag operation, including any tags and image metadata along with {@link Response}.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    public Response<BinaryData> tagImageWithResponse(BinaryData imageUrl, RequestOptions requestOptions) {
        return tagImageWithResponseAsync(imageUrl, requestOptions).block();
    }

    /**
     * This operation generates a thumbnail image with the user-specified width and height. By default, the service
     * analyzes the image, identifies the region of interest (ROI), and generates smart cropping coordinates based on
     * the ROI. Smart cropping helps when you specify an aspect ratio that differs from that of the input image. A
     * successful response contains the thumbnail image binary. If the request failed, the response contains an error
     * code and a message to help determine what went wrong. Upon failure, the error code and an error message are
     * returned. The error code could be one of InvalidImageUrl, InvalidImageFormat, InvalidImageSize,
     * InvalidThumbnailSize, NotSupportedImage, FailedToProcess, Timeout, or InternalServerError.
     *
     * <p><strong>Query Parameters</strong>
     *
     * <table border="1">
     *     <caption>Query Parameters</caption>
     *     <tr><th>Name</th><th>Type</th><th>Required</th><th>Description</th></tr>
     *     <tr><td>smartCropping</td><td>Boolean</td><td>No</td><td>Boolean flag for enabling smart cropping.</td></tr>
     *     <tr><td>model-version</td><td>String</td><td>No</td><td>Optional parameter to specify the version of the AI model. Accepted values are: "latest", "2021-04-01", "2021-05-01". Defaults to "latest".</td></tr>
     * </table>
     *
     * <p><strong>Request Body Schema</strong>
     *
     * <pre>{@code
     * {
     *     url: String
     * }
     * }</pre>
     *
     * @param width Width of the thumbnail, in pixels. It must be between 1 and 1024. Recommended minimum of 50.
     * @param height Height of the thumbnail, in pixels. It must be between 1 and 1024. Recommended minimum of 50.
     * @param imageUrl A JSON document with a URL pointing to the image that is to be analyzed.
     * @param requestOptions The options to configure the HTTP request before HTTP client sends it.
     * @throws HttpResponseException thrown if the request is rejected by server.
     * @throws ClientAuthenticationException thrown if the request is rejected by server on status code 401.
     * @throws ResourceNotFoundException thrown if the request is rejected by server on status code 404.
     * @throws ResourceModifiedException thrown if the request is rejected by server on status code 409.
     * @return the {@link Response} on successful completion of {@link Mono}.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    public Mono<Response<Void>> generateThumbnailWithResponseAsync(
            int width, int height, BinaryData imageUrl, RequestOptions requestOptions) {
        final String accept = "application/octet-stream";
        return FluxUtil.withContext(
                context ->
                        service.generateThumbnail(
                                this.getEndpoint(), width, height, imageUrl, accept, requestOptions, context));
    }

    /**
     * This operation generates a thumbnail image with the user-specified width and height. By default, the service
     * analyzes the image, identifies the region of interest (ROI), and generates smart cropping coordinates based on
     * the ROI. Smart cropping helps when you specify an aspect ratio that differs from that of the input image. A
     * successful response contains the thumbnail image binary. If the request failed, the response contains an error
     * code and a message to help determine what went wrong. Upon failure, the error code and an error message are
     * returned. The error code could be one of InvalidImageUrl, InvalidImageFormat, InvalidImageSize,
     * InvalidThumbnailSize, NotSupportedImage, FailedToProcess, Timeout, or InternalServerError.
     *
     * <p><strong>Query Parameters</strong>
     *
     * <table border="1">
     *     <caption>Query Parameters</caption>
     *     <tr><th>Name</th><th>Type</th><th>Required</th><th>Description</th></tr>
     *     <tr><td>smartCropping</td><td>Boolean</td><td>No</td><td>Boolean flag for enabling smart cropping.</td></tr>
     *     <tr><td>model-version</td><td>String</td><td>No</td><td>Optional parameter to specify the version of the AI model. Accepted values are: "latest", "2021-04-01", "2021-05-01". Defaults to "latest".</td></tr>
     * </table>
     *
     * <p><strong>Request Body Schema</strong>
     *
     * <pre>{@code
     * {
     *     url: String
     * }
     * }</pre>
     *
     * @param width Width of the thumbnail, in pixels. It must be between 1 and 1024. Recommended minimum of 50.
     * @param height Height of the thumbnail, in pixels. It must be between 1 and 1024. Recommended minimum of 50.
     * @param imageUrl A JSON document with a URL pointing to the image that is to be analyzed.
     * @param requestOptions The options to configure the HTTP request before HTTP client sends it.
     * @param context The context to associate with this operation.
     * @throws HttpResponseException thrown if the request is rejected by server.
     * @throws ClientAuthenticationException thrown if the request is rejected by server on status code 401.
     * @throws ResourceNotFoundException thrown if the request is rejected by server on status code 404.
     * @throws ResourceModifiedException thrown if the request is rejected by server on status code 409.
     * @return the {@link Response} on successful completion of {@link Mono}.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    public Mono<Response<Void>> generateThumbnailWithResponseAsync(
            int width, int height, BinaryData imageUrl, RequestOptions requestOptions, Context context) {
        final String accept = "application/octet-stream";
        return service.generateThumbnail(this.getEndpoint(), width, height, imageUrl, accept, requestOptions, context);
    }

    /**
     * This operation generates a thumbnail image with the user-specified width and height. By default, the service
     * analyzes the image, identifies the region of interest (ROI), and generates smart cropping coordinates based on
     * the ROI. Smart cropping helps when you specify an aspect ratio that differs from that of the input image. A
     * successful response contains the thumbnail image binary. If the request failed, the response contains an error
     * code and a message to help determine what went wrong. Upon failure, the error code and an error message are
     * returned. The error code could be one of InvalidImageUrl, InvalidImageFormat, InvalidImageSize,
     * InvalidThumbnailSize, NotSupportedImage, FailedToProcess, Timeout, or InternalServerError.
     *
     * <p><strong>Query Parameters</strong>
     *
     * <table border="1">
     *     <caption>Query Parameters</caption>
     *     <tr><th>Name</th><th>Type</th><th>Required</th><th>Description</th></tr>
     *     <tr><td>smartCropping</td><td>Boolean</td><td>No</td><td>Boolean flag for enabling smart cropping.</td></tr>
     *     <tr><td>model-version</td><td>String</td><td>No</td><td>Optional parameter to specify the version of the AI model. Accepted values are: "latest", "2021-04-01", "2021-05-01". Defaults to "latest".</td></tr>
     * </table>
     *
     * <p><strong>Request Body Schema</strong>
     *
     * <pre>{@code
     * {
     *     url: String
     * }
     * }</pre>
     *
     * @param width Width of the thumbnail, in pixels. It must be between 1 and 1024. Recommended minimum of 50.
     * @param height Height of the thumbnail, in pixels. It must be between 1 and 1024. Recommended minimum of 50.
     * @param imageUrl A JSON document with a URL pointing to the image that is to be analyzed.
     * @param requestOptions The options to configure the HTTP request before HTTP client sends it.
     * @throws HttpResponseException thrown if the request is rejected by server.
     * @throws ClientAuthenticationException thrown if the request is rejected by server on status code 401.
     * @throws ResourceNotFoundException thrown if the request is rejected by server on status code 404.
     * @throws ResourceModifiedException thrown if the request is rejected by server on status code 409.
     * @return the {@link Response}.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    public Response<Void> generateThumbnailWithResponse(
            int width, int height, BinaryData imageUrl, RequestOptions requestOptions) {
        return generateThumbnailWithResponseAsync(width, height, imageUrl, requestOptions).block();
    }

    /**
     * This operation returns a bounding box around the most important area of the image. A successful response will be
     * returned in JSON. If the request failed, the response contains an error code and a message to help determine what
     * went wrong. Upon failure, the error code and an error message are returned. The error code could be one of
     * InvalidImageUrl, InvalidImageFormat, InvalidImageSize, NotSupportedImage, FailedToProcess, Timeout, or
     * InternalServerError.
     *
     * <p><strong>Query Parameters</strong>
     *
     * <table border="1">
     *     <caption>Query Parameters</caption>
     *     <tr><th>Name</th><th>Type</th><th>Required</th><th>Description</th></tr>
     *     <tr><td>model-version</td><td>String</td><td>No</td><td>Optional parameter to specify the version of the AI model. Accepted values are: "latest", "2021-04-01", "2021-05-01". Defaults to "latest".</td></tr>
     * </table>
     *
     * <p><strong>Request Body Schema</strong>
     *
     * <pre>{@code
     * {
     *     url: String
     * }
     * }</pre>
     *
     * <p><strong>Response Body Schema</strong>
     *
     * <pre>{@code
     * {
     *     areaOfInterest: {
     *         x: Integer
     *         y: Integer
     *         w: Integer
     *         h: Integer
     *     }
     *     requestId: String
     *     metadata: {
     *         width: Integer
     *         height: Integer
     *         format: String
     *     }
     *     modelVersion: String
     * }
     * }</pre>
     *
     * @param imageUrl A JSON document with a URL pointing to the image that is to be analyzed.
     * @param requestOptions The options to configure the HTTP request before HTTP client sends it.
     * @throws HttpResponseException thrown if the request is rejected by server.
     * @throws ClientAuthenticationException thrown if the request is rejected by server on status code 401.
     * @throws ResourceNotFoundException thrown if the request is rejected by server on status code 404.
     * @throws ResourceModifiedException thrown if the request is rejected by server on status code 409.
     * @return result of AreaOfInterest operation along with {@link Response} on successful completion of {@link Mono}.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    public Mono<Response<BinaryData>> getAreaOfInterestWithResponseAsync(
            BinaryData imageUrl, RequestOptions requestOptions) {
        final String accept = "application/json";
        return FluxUtil.withContext(
                context -> service.getAreaOfInterest(this.getEndpoint(), imageUrl, accept, requestOptions, context));
    }

    /**
     * This operation returns a bounding box around the most important area of the image. A successful response will be
     * returned in JSON. If the request failed, the response contains an error code and a message to help determine what
     * went wrong. Upon failure, the error code and an error message are returned. The error code could be one of
     * InvalidImageUrl, InvalidImageFormat, InvalidImageSize, NotSupportedImage, FailedToProcess, Timeout, or
     * InternalServerError.
     *
     * <p><strong>Query Parameters</strong>
     *
     * <table border="1">
     *     <caption>Query Parameters</caption>
     *     <tr><th>Name</th><th>Type</th><th>Required</th><th>Description</th></tr>
     *     <tr><td>model-version</td><td>String</td><td>No</td><td>Optional parameter to specify the version of the AI model. Accepted values are: "latest", "2021-04-01", "2021-05-01". Defaults to "latest".</td></tr>
     * </table>
     *
     * <p><strong>Request Body Schema</strong>
     *
     * <pre>{@code
     * {
     *     url: String
     * }
     * }</pre>
     *
     * <p><strong>Response Body Schema</strong>
     *
     * <pre>{@code
     * {
     *     areaOfInterest: {
     *         x: Integer
     *         y: Integer
     *         w: Integer
     *         h: Integer
     *     }
     *     requestId: String
     *     metadata: {
     *         width: Integer
     *         height: Integer
     *         format: String
     *     }
     *     modelVersion: String
     * }
     * }</pre>
     *
     * @param imageUrl A JSON document with a URL pointing to the image that is to be analyzed.
     * @param requestOptions The options to configure the HTTP request before HTTP client sends it.
     * @param context The context to associate with this operation.
     * @throws HttpResponseException thrown if the request is rejected by server.
     * @throws ClientAuthenticationException thrown if the request is rejected by server on status code 401.
     * @throws ResourceNotFoundException thrown if the request is rejected by server on status code 404.
     * @throws ResourceModifiedException thrown if the request is rejected by server on status code 409.
     * @return result of AreaOfInterest operation along with {@link Response} on successful completion of {@link Mono}.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    public Mono<Response<BinaryData>> getAreaOfInterestWithResponseAsync(
            BinaryData imageUrl, RequestOptions requestOptions, Context context) {
        final String accept = "application/json";
        return service.getAreaOfInterest(this.getEndpoint(), imageUrl, accept, requestOptions, context);
    }

    /**
     * This operation returns a bounding box around the most important area of the image. A successful response will be
     * returned in JSON. If the request failed, the response contains an error code and a message to help determine what
     * went wrong. Upon failure, the error code and an error message are returned. The error code could be one of
     * InvalidImageUrl, InvalidImageFormat, InvalidImageSize, NotSupportedImage, FailedToProcess, Timeout, or
     * InternalServerError.
     *
     * <p><strong>Query Parameters</strong>
     *
     * <table border="1">
     *     <caption>Query Parameters</caption>
     *     <tr><th>Name</th><th>Type</th><th>Required</th><th>Description</th></tr>
     *     <tr><td>model-version</td><td>String</td><td>No</td><td>Optional parameter to specify the version of the AI model. Accepted values are: "latest", "2021-04-01", "2021-05-01". Defaults to "latest".</td></tr>
     * </table>
     *
     * <p><strong>Request Body Schema</strong>
     *
     * <pre>{@code
     * {
     *     url: String
     * }
     * }</pre>
     *
     * <p><strong>Response Body Schema</strong>
     *
     * <pre>{@code
     * {
     *     areaOfInterest: {
     *         x: Integer
     *         y: Integer
     *         w: Integer
     *         h: Integer
     *     }
     *     requestId: String
     *     metadata: {
     *         width: Integer
     *         height: Integer
     *         format: String
     *     }
     *     modelVersion: String
     * }
     * }</pre>
     *
     * @param imageUrl A JSON document with a URL pointing to the image that is to be analyzed.
     * @param requestOptions The options to configure the HTTP request before HTTP client sends it.
     * @throws HttpResponseException thrown if the request is rejected by server.
     * @throws ClientAuthenticationException thrown if the request is rejected by server on status code 401.
     * @throws ResourceNotFoundException thrown if the request is rejected by server on status code 404.
     * @throws ResourceModifiedException thrown if the request is rejected by server on status code 409.
     * @return result of AreaOfInterest operation along with {@link Response}.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    public Response<BinaryData> getAreaOfInterestWithResponse(BinaryData imageUrl, RequestOptions requestOptions) {
        return getAreaOfInterestWithResponseAsync(imageUrl, requestOptions).block();
    }

    /**
     * This operation extracts a rich set of visual features based on the image content. Two input methods are supported
     * -- (1) Uploading an image or (2) specifying an image URL. Within your request, there is an optional parameter to
     * allow you to choose which features to return. By default, image categories are returned in the response. A
     * successful response will be returned in JSON. If the request failed, the response will contain an error code and
     * a message to help understand what went wrong.
     *
     * <p><strong>Query Parameters</strong>
     *
     * <table border="1">
     *     <caption>Query Parameters</caption>
     *     <tr><th>Name</th><th>Type</th><th>Required</th><th>Description</th></tr>
     *     <tr><td>visualFeatures</td><td>List&lt;String&gt;</td><td>No</td><td>A string indicating what visual feature types to return. Multiple values should be comma-separated. Valid visual feature types include: Categories - categorizes image content according to a taxonomy defined in documentation. Tags - tags the image with a detailed list of words related to the image content. Description - describes the image content with a complete English sentence. Faces - detects if faces are present. If present, generate coordinates, gender and age. ImageType - detects if image is clipart or a line drawing. Color - determines the accent color, dominant color, and whether an image is black&amp;white. Adult - detects if the image is pornographic in nature (depicts nudity or a sex act), or is gory (depicts extreme violence or blood). Sexually suggestive content (aka racy content) is also detected. Objects - detects various objects within an image, including the approximate location. The Objects argument is only available in English. Brands - detects various brands within an image, including the approximate location. The Brands argument is only available in English. In the form of "," separated string.</td></tr>
     *     <tr><td>details</td><td>List&lt;String&gt;</td><td>No</td><td>A string indicating which domain-specific details to return. Multiple values should be comma-separated. Valid visual feature types include: Celebrities - identifies celebrities if detected in the image, Landmarks - identifies notable landmarks in the image. In the form of "," separated string.</td></tr>
     *     <tr><td>language</td><td>String</td><td>No</td><td>The desired language for output generation. If this parameter is not specified, the default value is "en". See https://aka.ms/cv-languages for list of supported languages.</td></tr>
     *     <tr><td>descriptionExclude</td><td>List&lt;String&gt;</td><td>No</td><td>Turn off specified domain models when generating the description. In the form of "," separated string.</td></tr>
     *     <tr><td>model-version</td><td>String</td><td>No</td><td>Optional parameter to specify the version of the AI model. Accepted values are: "latest", "2021-04-01", "2021-05-01". Defaults to "latest".</td></tr>
     * </table>
     *
     * <p><strong>Request Body Schema</strong>
     *
     * <pre>{@code
     * Flux<ByteBuffer>
     * }</pre>
     *
     * <p><strong>Response Body Schema</strong>
     *
     * <pre>{@code
     * {
     *     categories: [
     *         {
     *             name: String
     *             score: Double
     *             detail: {
     *                 celebrities: [
     *                     {
     *                         name: String
     *                         confidence: Double
     *                         faceRectangle: {
     *                             left: Integer
     *                             top: Integer
     *                             width: Integer
     *                             height: Integer
     *                         }
     *                     }
     *                 ]
     *                 landmarks: [
     *                     {
     *                         name: String
     *                         confidence: Double
     *                     }
     *                 ]
     *             }
     *         }
     *     ]
     *     adult: {
     *         isAdultContent: Boolean
     *         isRacyContent: Boolean
     *         isGoryContent: Boolean
     *         adultScore: Double
     *         racyScore: Double
     *         goreScore: Double
     *     }
     *     color: {
     *         dominantColorForeground: String
     *         dominantColorBackground: String
     *         dominantColors: [
     *             String
     *         ]
     *         accentColor: String
     *         isBWImg: Boolean
     *     }
     *     imageType: {
     *         clipArtType: Integer
     *         lineDrawingType: Integer
     *     }
     *     tags: [
     *         {
     *             name: String
     *             confidence: Double
     *             hint: String
     *         }
     *     ]
     *     description: {
     *         tags: [
     *             String
     *         ]
     *         captions: [
     *             {
     *                 text: String
     *                 confidence: Double
     *             }
     *         ]
     *     }
     *     faces: [
     *         {
     *             age: Integer
     *             gender: String(Male/Female)
     *             faceRectangle: (recursive schema, see faceRectangle above)
     *         }
     *     ]
     *     objects: [
     *         {
     *             rectangle: {
     *                 x: Integer
     *                 y: Integer
     *                 w: Integer
     *                 h: Integer
     *             }
     *             object: String
     *             confidence: Double
     *             parent: {
     *                 object: String
     *                 confidence: Double
     *                 parent: (recursive schema, see parent above)
     *             }
     *         }
     *     ]
     *     brands: [
     *         {
     *             name: String
     *             confidence: Double
     *             rectangle: (recursive schema, see rectangle above)
     *         }
     *     ]
     *     requestId: String
     *     metadata: {
     *         width: Integer
     *         height: Integer
     *         format: String
     *     }
     *     modelVersion: String
     * }
     * }</pre>
     *
     * @param contentType Upload file type.
     * @param image An image stream.
     * @param contentLength The contentLength parameter.
     * @param requestOptions The options to configure the HTTP request before HTTP client sends it.
     * @throws HttpResponseException thrown if the request is rejected by server.
     * @throws ClientAuthenticationException thrown if the request is rejected by server on status code 401.
     * @throws ResourceNotFoundException thrown if the request is rejected by server on status code 404.
     * @throws ResourceModifiedException thrown if the request is rejected by server on status code 409.
     * @return result of AnalyzeImage operation along with {@link Response} on successful completion of {@link Mono}.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    public Mono<Response<BinaryData>> analyzeImageInStreamWithResponseAsync(
            String contentType, BinaryData image, long contentLength, RequestOptions requestOptions) {
        final String accept = "application/json";
        return FluxUtil.withContext(
                context ->
                        service.analyzeImageInStream(
                                this.getEndpoint(),
                                contentType,
                                image,
                                contentLength,
                                accept,
                                requestOptions,
                                context));
    }

    /**
     * This operation extracts a rich set of visual features based on the image content. Two input methods are supported
     * -- (1) Uploading an image or (2) specifying an image URL. Within your request, there is an optional parameter to
     * allow you to choose which features to return. By default, image categories are returned in the response. A
     * successful response will be returned in JSON. If the request failed, the response will contain an error code and
     * a message to help understand what went wrong.
     *
     * <p><strong>Query Parameters</strong>
     *
     * <table border="1">
     *     <caption>Query Parameters</caption>
     *     <tr><th>Name</th><th>Type</th><th>Required</th><th>Description</th></tr>
     *     <tr><td>visualFeatures</td><td>List&lt;String&gt;</td><td>No</td><td>A string indicating what visual feature types to return. Multiple values should be comma-separated. Valid visual feature types include: Categories - categorizes image content according to a taxonomy defined in documentation. Tags - tags the image with a detailed list of words related to the image content. Description - describes the image content with a complete English sentence. Faces - detects if faces are present. If present, generate coordinates, gender and age. ImageType - detects if image is clipart or a line drawing. Color - determines the accent color, dominant color, and whether an image is black&amp;white. Adult - detects if the image is pornographic in nature (depicts nudity or a sex act), or is gory (depicts extreme violence or blood). Sexually suggestive content (aka racy content) is also detected. Objects - detects various objects within an image, including the approximate location. The Objects argument is only available in English. Brands - detects various brands within an image, including the approximate location. The Brands argument is only available in English. In the form of "," separated string.</td></tr>
     *     <tr><td>details</td><td>List&lt;String&gt;</td><td>No</td><td>A string indicating which domain-specific details to return. Multiple values should be comma-separated. Valid visual feature types include: Celebrities - identifies celebrities if detected in the image, Landmarks - identifies notable landmarks in the image. In the form of "," separated string.</td></tr>
     *     <tr><td>language</td><td>String</td><td>No</td><td>The desired language for output generation. If this parameter is not specified, the default value is "en". See https://aka.ms/cv-languages for list of supported languages.</td></tr>
     *     <tr><td>descriptionExclude</td><td>List&lt;String&gt;</td><td>No</td><td>Turn off specified domain models when generating the description. In the form of "," separated string.</td></tr>
     *     <tr><td>model-version</td><td>String</td><td>No</td><td>Optional parameter to specify the version of the AI model. Accepted values are: "latest", "2021-04-01", "2021-05-01". Defaults to "latest".</td></tr>
     * </table>
     *
     * <p><strong>Request Body Schema</strong>
     *
     * <pre>{@code
     * Flux<ByteBuffer>
     * }</pre>
     *
     * <p><strong>Response Body Schema</strong>
     *
     * <pre>{@code
     * {
     *     categories: [
     *         {
     *             name: String
     *             score: Double
     *             detail: {
     *                 celebrities: [
     *                     {
     *                         name: String
     *                         confidence: Double
     *                         faceRectangle: {
     *                             left: Integer
     *                             top: Integer
     *                             width: Integer
     *                             height: Integer
     *                         }
     *                     }
     *                 ]
     *                 landmarks: [
     *                     {
     *                         name: String
     *                         confidence: Double
     *                     }
     *                 ]
     *             }
     *         }
     *     ]
     *     adult: {
     *         isAdultContent: Boolean
     *         isRacyContent: Boolean
     *         isGoryContent: Boolean
     *         adultScore: Double
     *         racyScore: Double
     *         goreScore: Double
     *     }
     *     color: {
     *         dominantColorForeground: String
     *         dominantColorBackground: String
     *         dominantColors: [
     *             String
     *         ]
     *         accentColor: String
     *         isBWImg: Boolean
     *     }
     *     imageType: {
     *         clipArtType: Integer
     *         lineDrawingType: Integer
     *     }
     *     tags: [
     *         {
     *             name: String
     *             confidence: Double
     *             hint: String
     *         }
     *     ]
     *     description: {
     *         tags: [
     *             String
     *         ]
     *         captions: [
     *             {
     *                 text: String
     *                 confidence: Double
     *             }
     *         ]
     *     }
     *     faces: [
     *         {
     *             age: Integer
     *             gender: String(Male/Female)
     *             faceRectangle: (recursive schema, see faceRectangle above)
     *         }
     *     ]
     *     objects: [
     *         {
     *             rectangle: {
     *                 x: Integer
     *                 y: Integer
     *                 w: Integer
     *                 h: Integer
     *             }
     *             object: String
     *             confidence: Double
     *             parent: {
     *                 object: String
     *                 confidence: Double
     *                 parent: (recursive schema, see parent above)
     *             }
     *         }
     *     ]
     *     brands: [
     *         {
     *             name: String
     *             confidence: Double
     *             rectangle: (recursive schema, see rectangle above)
     *         }
     *     ]
     *     requestId: String
     *     metadata: {
     *         width: Integer
     *         height: Integer
     *         format: String
     *     }
     *     modelVersion: String
     * }
     * }</pre>
     *
     * @param contentType Upload file type.
     * @param image An image stream.
     * @param contentLength The contentLength parameter.
     * @param requestOptions The options to configure the HTTP request before HTTP client sends it.
     * @param context The context to associate with this operation.
     * @throws HttpResponseException thrown if the request is rejected by server.
     * @throws ClientAuthenticationException thrown if the request is rejected by server on status code 401.
     * @throws ResourceNotFoundException thrown if the request is rejected by server on status code 404.
     * @throws ResourceModifiedException thrown if the request is rejected by server on status code 409.
     * @return result of AnalyzeImage operation along with {@link Response} on successful completion of {@link Mono}.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    public Mono<Response<BinaryData>> analyzeImageInStreamWithResponseAsync(
            String contentType, BinaryData image, long contentLength, RequestOptions requestOptions, Context context) {
        final String accept = "application/json";
        return service.analyzeImageInStream(
                this.getEndpoint(), contentType, image, contentLength, accept, requestOptions, context);
    }

    /**
     * This operation extracts a rich set of visual features based on the image content. Two input methods are supported
     * -- (1) Uploading an image or (2) specifying an image URL. Within your request, there is an optional parameter to
     * allow you to choose which features to return. By default, image categories are returned in the response. A
     * successful response will be returned in JSON. If the request failed, the response will contain an error code and
     * a message to help understand what went wrong.
     *
     * <p><strong>Query Parameters</strong>
     *
     * <table border="1">
     *     <caption>Query Parameters</caption>
     *     <tr><th>Name</th><th>Type</th><th>Required</th><th>Description</th></tr>
     *     <tr><td>visualFeatures</td><td>List&lt;String&gt;</td><td>No</td><td>A string indicating what visual feature types to return. Multiple values should be comma-separated. Valid visual feature types include: Categories - categorizes image content according to a taxonomy defined in documentation. Tags - tags the image with a detailed list of words related to the image content. Description - describes the image content with a complete English sentence. Faces - detects if faces are present. If present, generate coordinates, gender and age. ImageType - detects if image is clipart or a line drawing. Color - determines the accent color, dominant color, and whether an image is black&amp;white. Adult - detects if the image is pornographic in nature (depicts nudity or a sex act), or is gory (depicts extreme violence or blood). Sexually suggestive content (aka racy content) is also detected. Objects - detects various objects within an image, including the approximate location. The Objects argument is only available in English. Brands - detects various brands within an image, including the approximate location. The Brands argument is only available in English. In the form of "," separated string.</td></tr>
     *     <tr><td>details</td><td>List&lt;String&gt;</td><td>No</td><td>A string indicating which domain-specific details to return. Multiple values should be comma-separated. Valid visual feature types include: Celebrities - identifies celebrities if detected in the image, Landmarks - identifies notable landmarks in the image. In the form of "," separated string.</td></tr>
     *     <tr><td>language</td><td>String</td><td>No</td><td>The desired language for output generation. If this parameter is not specified, the default value is "en". See https://aka.ms/cv-languages for list of supported languages.</td></tr>
     *     <tr><td>descriptionExclude</td><td>List&lt;String&gt;</td><td>No</td><td>Turn off specified domain models when generating the description. In the form of "," separated string.</td></tr>
     *     <tr><td>model-version</td><td>String</td><td>No</td><td>Optional parameter to specify the version of the AI model. Accepted values are: "latest", "2021-04-01", "2021-05-01". Defaults to "latest".</td></tr>
     * </table>
     *
     * <p><strong>Request Body Schema</strong>
     *
     * <pre>{@code
     * Flux<ByteBuffer>
     * }</pre>
     *
     * <p><strong>Response Body Schema</strong>
     *
     * <pre>{@code
     * {
     *     categories: [
     *         {
     *             name: String
     *             score: Double
     *             detail: {
     *                 celebrities: [
     *                     {
     *                         name: String
     *                         confidence: Double
     *                         faceRectangle: {
     *                             left: Integer
     *                             top: Integer
     *                             width: Integer
     *                             height: Integer
     *                         }
     *                     }
     *                 ]
     *                 landmarks: [
     *                     {
     *                         name: String
     *                         confidence: Double
     *                     }
     *                 ]
     *             }
     *         }
     *     ]
     *     adult: {
     *         isAdultContent: Boolean
     *         isRacyContent: Boolean
     *         isGoryContent: Boolean
     *         adultScore: Double
     *         racyScore: Double
     *         goreScore: Double
     *     }
     *     color: {
     *         dominantColorForeground: String
     *         dominantColorBackground: String
     *         dominantColors: [
     *             String
     *         ]
     *         accentColor: String
     *         isBWImg: Boolean
     *     }
     *     imageType: {
     *         clipArtType: Integer
     *         lineDrawingType: Integer
     *     }
     *     tags: [
     *         {
     *             name: String
     *             confidence: Double
     *             hint: String
     *         }
     *     ]
     *     description: {
     *         tags: [
     *             String
     *         ]
     *         captions: [
     *             {
     *                 text: String
     *                 confidence: Double
     *             }
     *         ]
     *     }
     *     faces: [
     *         {
     *             age: Integer
     *             gender: String(Male/Female)
     *             faceRectangle: (recursive schema, see faceRectangle above)
     *         }
     *     ]
     *     objects: [
     *         {
     *             rectangle: {
     *                 x: Integer
     *                 y: Integer
     *                 w: Integer
     *                 h: Integer
     *             }
     *             object: String
     *             confidence: Double
     *             parent: {
     *                 object: String
     *                 confidence: Double
     *                 parent: (recursive schema, see parent above)
     *             }
     *         }
     *     ]
     *     brands: [
     *         {
     *             name: String
     *             confidence: Double
     *             rectangle: (recursive schema, see rectangle above)
     *         }
     *     ]
     *     requestId: String
     *     metadata: {
     *         width: Integer
     *         height: Integer
     *         format: String
     *     }
     *     modelVersion: String
     * }
     * }</pre>
     *
     * @param contentType Upload file type.
     * @param image An image stream.
     * @param contentLength The contentLength parameter.
     * @param requestOptions The options to configure the HTTP request before HTTP client sends it.
     * @throws HttpResponseException thrown if the request is rejected by server.
     * @throws ClientAuthenticationException thrown if the request is rejected by server on status code 401.
     * @throws ResourceNotFoundException thrown if the request is rejected by server on status code 404.
     * @throws ResourceModifiedException thrown if the request is rejected by server on status code 409.
     * @return result of AnalyzeImage operation along with {@link Response}.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    public Response<BinaryData> analyzeImageInStreamWithResponse(
            String contentType, BinaryData image, long contentLength, RequestOptions requestOptions) {
        return analyzeImageInStreamWithResponseAsync(contentType, image, contentLength, requestOptions).block();
    }

    /**
     * This operation returns a bounding box around the most important area of the image. A successful response will be
     * returned in JSON. If the request failed, the response contains an error code and a message to help determine what
     * went wrong. Upon failure, the error code and an error message are returned. The error code could be one of
     * InvalidImageUrl, InvalidImageFormat, InvalidImageSize, NotSupportedImage, FailedToProcess, Timeout, or
     * InternalServerError.
     *
     * <p><strong>Query Parameters</strong>
     *
     * <table border="1">
     *     <caption>Query Parameters</caption>
     *     <tr><th>Name</th><th>Type</th><th>Required</th><th>Description</th></tr>
     *     <tr><td>model-version</td><td>String</td><td>No</td><td>Optional parameter to specify the version of the AI model. Accepted values are: "latest", "2021-04-01", "2021-05-01". Defaults to "latest".</td></tr>
     * </table>
     *
     * <p><strong>Request Body Schema</strong>
     *
     * <pre>{@code
     * Flux<ByteBuffer>
     * }</pre>
     *
     * <p><strong>Response Body Schema</strong>
     *
     * <pre>{@code
     * {
     *     areaOfInterest: {
     *         x: Integer
     *         y: Integer
     *         w: Integer
     *         h: Integer
     *     }
     *     requestId: String
     *     metadata: {
     *         width: Integer
     *         height: Integer
     *         format: String
     *     }
     *     modelVersion: String
     * }
     * }</pre>
     *
     * @param contentType Upload file type.
     * @param image An image stream.
     * @param contentLength The contentLength parameter.
     * @param requestOptions The options to configure the HTTP request before HTTP client sends it.
     * @throws HttpResponseException thrown if the request is rejected by server.
     * @throws ClientAuthenticationException thrown if the request is rejected by server on status code 401.
     * @throws ResourceNotFoundException thrown if the request is rejected by server on status code 404.
     * @throws ResourceModifiedException thrown if the request is rejected by server on status code 409.
     * @return result of AreaOfInterest operation along with {@link Response} on successful completion of {@link Mono}.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    public Mono<Response<BinaryData>> getAreaOfInterestInStreamWithResponseAsync(
            String contentType, BinaryData image, long contentLength, RequestOptions requestOptions) {
        final String accept = "application/json";
        return FluxUtil.withContext(
                context ->
                        service.getAreaOfInterestInStream(
                                this.getEndpoint(),
                                contentType,
                                image,
                                contentLength,
                                accept,
                                requestOptions,
                                context));
    }

    /**
     * This operation returns a bounding box around the most important area of the image. A successful response will be
     * returned in JSON. If the request failed, the response contains an error code and a message to help determine what
     * went wrong. Upon failure, the error code and an error message are returned. The error code could be one of
     * InvalidImageUrl, InvalidImageFormat, InvalidImageSize, NotSupportedImage, FailedToProcess, Timeout, or
     * InternalServerError.
     *
     * <p><strong>Query Parameters</strong>
     *
     * <table border="1">
     *     <caption>Query Parameters</caption>
     *     <tr><th>Name</th><th>Type</th><th>Required</th><th>Description</th></tr>
     *     <tr><td>model-version</td><td>String</td><td>No</td><td>Optional parameter to specify the version of the AI model. Accepted values are: "latest", "2021-04-01", "2021-05-01". Defaults to "latest".</td></tr>
     * </table>
     *
     * <p><strong>Request Body Schema</strong>
     *
     * <pre>{@code
     * Flux<ByteBuffer>
     * }</pre>
     *
     * <p><strong>Response Body Schema</strong>
     *
     * <pre>{@code
     * {
     *     areaOfInterest: {
     *         x: Integer
     *         y: Integer
     *         w: Integer
     *         h: Integer
     *     }
     *     requestId: String
     *     metadata: {
     *         width: Integer
     *         height: Integer
     *         format: String
     *     }
     *     modelVersion: String
     * }
     * }</pre>
     *
     * @param contentType Upload file type.
     * @param image An image stream.
     * @param contentLength The contentLength parameter.
     * @param requestOptions The options to configure the HTTP request before HTTP client sends it.
     * @param context The context to associate with this operation.
     * @throws HttpResponseException thrown if the request is rejected by server.
     * @throws ClientAuthenticationException thrown if the request is rejected by server on status code 401.
     * @throws ResourceNotFoundException thrown if the request is rejected by server on status code 404.
     * @throws ResourceModifiedException thrown if the request is rejected by server on status code 409.
     * @return result of AreaOfInterest operation along with {@link Response} on successful completion of {@link Mono}.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    public Mono<Response<BinaryData>> getAreaOfInterestInStreamWithResponseAsync(
            String contentType, BinaryData image, long contentLength, RequestOptions requestOptions, Context context) {
        final String accept = "application/json";
        return service.getAreaOfInterestInStream(
                this.getEndpoint(), contentType, image, contentLength, accept, requestOptions, context);
    }

    /**
     * This operation returns a bounding box around the most important area of the image. A successful response will be
     * returned in JSON. If the request failed, the response contains an error code and a message to help determine what
     * went wrong. Upon failure, the error code and an error message are returned. The error code could be one of
     * InvalidImageUrl, InvalidImageFormat, InvalidImageSize, NotSupportedImage, FailedToProcess, Timeout, or
     * InternalServerError.
     *
     * <p><strong>Query Parameters</strong>
     *
     * <table border="1">
     *     <caption>Query Parameters</caption>
     *     <tr><th>Name</th><th>Type</th><th>Required</th><th>Description</th></tr>
     *     <tr><td>model-version</td><td>String</td><td>No</td><td>Optional parameter to specify the version of the AI model. Accepted values are: "latest", "2021-04-01", "2021-05-01". Defaults to "latest".</td></tr>
     * </table>
     *
     * <p><strong>Request Body Schema</strong>
     *
     * <pre>{@code
     * Flux<ByteBuffer>
     * }</pre>
     *
     * <p><strong>Response Body Schema</strong>
     *
     * <pre>{@code
     * {
     *     areaOfInterest: {
     *         x: Integer
     *         y: Integer
     *         w: Integer
     *         h: Integer
     *     }
     *     requestId: String
     *     metadata: {
     *         width: Integer
     *         height: Integer
     *         format: String
     *     }
     *     modelVersion: String
     * }
     * }</pre>
     *
     * @param contentType Upload file type.
     * @param image An image stream.
     * @param contentLength The contentLength parameter.
     * @param requestOptions The options to configure the HTTP request before HTTP client sends it.
     * @throws HttpResponseException thrown if the request is rejected by server.
     * @throws ClientAuthenticationException thrown if the request is rejected by server on status code 401.
     * @throws ResourceNotFoundException thrown if the request is rejected by server on status code 404.
     * @throws ResourceModifiedException thrown if the request is rejected by server on status code 409.
     * @return result of AreaOfInterest operation along with {@link Response}.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    public Response<BinaryData> getAreaOfInterestInStreamWithResponse(
            String contentType, BinaryData image, long contentLength, RequestOptions requestOptions) {
        return getAreaOfInterestInStreamWithResponseAsync(contentType, image, contentLength, requestOptions).block();
    }

    /**
     * This operation generates a description of an image in human readable language with complete sentences. The
     * description is based on a collection of content tags, which are also returned by the operation. More than one
     * description can be generated for each image. Descriptions are ordered by their confidence score. Descriptions may
     * include results from celebrity and landmark domain models, if applicable. Two input methods are supported -- (1)
     * Uploading an image or (2) specifying an image URL. A successful response will be returned in JSON. If the request
     * failed, the response will contain an error code and a message to help understand what went wrong.
     *
     * <p><strong>Query Parameters</strong>
     *
     * <table border="1">
     *     <caption>Query Parameters</caption>
     *     <tr><th>Name</th><th>Type</th><th>Required</th><th>Description</th></tr>
     *     <tr><td>maxCandidates</td><td>Integer</td><td>No</td><td>Maximum number of candidate descriptions to be returned.  The default is 1.</td></tr>
     *     <tr><td>language</td><td>String</td><td>No</td><td>The desired language for output generation. If this parameter is not specified, the default value is "en". See https://aka.ms/cv-languages for list of supported languages.</td></tr>
     *     <tr><td>descriptionExclude</td><td>List&lt;String&gt;</td><td>No</td><td>Turn off specified domain models when generating the description. In the form of "," separated string.</td></tr>
     *     <tr><td>model-version</td><td>String</td><td>No</td><td>Optional parameter to specify the version of the AI model. Accepted values are: "latest", "2021-04-01", "2021-05-01". Defaults to "latest".</td></tr>
     * </table>
     *
     * <p><strong>Request Body Schema</strong>
     *
     * <pre>{@code
     * Flux<ByteBuffer>
     * }</pre>
     *
     * <p><strong>Response Body Schema</strong>
     *
     * <pre>{@code
     * {
     *     description: {
     *         tags: [
     *             String
     *         ]
     *         captions: [
     *             {
     *                 text: String
     *                 confidence: Double
     *             }
     *         ]
     *     }
     *     requestId: String
     *     metadata: {
     *         width: Integer
     *         height: Integer
     *         format: String
     *     }
     *     modelVersion: String
     * }
     * }</pre>
     *
     * @param contentType Upload file type.
     * @param image An image stream.
     * @param contentLength The contentLength parameter.
     * @param requestOptions The options to configure the HTTP request before HTTP client sends it.
     * @throws HttpResponseException thrown if the request is rejected by server.
     * @throws ClientAuthenticationException thrown if the request is rejected by server on status code 401.
     * @throws ResourceNotFoundException thrown if the request is rejected by server on status code 404.
     * @throws ResourceModifiedException thrown if the request is rejected by server on status code 409.
     * @return a collection of content tags, along with a list of captions sorted by confidence level, and image
     *     metadata along with {@link Response} on successful completion of {@link Mono}.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    public Mono<Response<BinaryData>> describeImageInStreamWithResponseAsync(
            String contentType, BinaryData image, long contentLength, RequestOptions requestOptions) {
        final String accept = "application/json";
        return FluxUtil.withContext(
                context ->
                        service.describeImageInStream(
                                this.getEndpoint(),
                                contentType,
                                image,
                                contentLength,
                                accept,
                                requestOptions,
                                context));
    }

    /**
     * This operation generates a description of an image in human readable language with complete sentences. The
     * description is based on a collection of content tags, which are also returned by the operation. More than one
     * description can be generated for each image. Descriptions are ordered by their confidence score. Descriptions may
     * include results from celebrity and landmark domain models, if applicable. Two input methods are supported -- (1)
     * Uploading an image or (2) specifying an image URL. A successful response will be returned in JSON. If the request
     * failed, the response will contain an error code and a message to help understand what went wrong.
     *
     * <p><strong>Query Parameters</strong>
     *
     * <table border="1">
     *     <caption>Query Parameters</caption>
     *     <tr><th>Name</th><th>Type</th><th>Required</th><th>Description</th></tr>
     *     <tr><td>maxCandidates</td><td>Integer</td><td>No</td><td>Maximum number of candidate descriptions to be returned.  The default is 1.</td></tr>
     *     <tr><td>language</td><td>String</td><td>No</td><td>The desired language for output generation. If this parameter is not specified, the default value is "en". See https://aka.ms/cv-languages for list of supported languages.</td></tr>
     *     <tr><td>descriptionExclude</td><td>List&lt;String&gt;</td><td>No</td><td>Turn off specified domain models when generating the description. In the form of "," separated string.</td></tr>
     *     <tr><td>model-version</td><td>String</td><td>No</td><td>Optional parameter to specify the version of the AI model. Accepted values are: "latest", "2021-04-01", "2021-05-01". Defaults to "latest".</td></tr>
     * </table>
     *
     * <p><strong>Request Body Schema</strong>
     *
     * <pre>{@code
     * Flux<ByteBuffer>
     * }</pre>
     *
     * <p><strong>Response Body Schema</strong>
     *
     * <pre>{@code
     * {
     *     description: {
     *         tags: [
     *             String
     *         ]
     *         captions: [
     *             {
     *                 text: String
     *                 confidence: Double
     *             }
     *         ]
     *     }
     *     requestId: String
     *     metadata: {
     *         width: Integer
     *         height: Integer
     *         format: String
     *     }
     *     modelVersion: String
     * }
     * }</pre>
     *
     * @param contentType Upload file type.
     * @param image An image stream.
     * @param contentLength The contentLength parameter.
     * @param requestOptions The options to configure the HTTP request before HTTP client sends it.
     * @param context The context to associate with this operation.
     * @throws HttpResponseException thrown if the request is rejected by server.
     * @throws ClientAuthenticationException thrown if the request is rejected by server on status code 401.
     * @throws ResourceNotFoundException thrown if the request is rejected by server on status code 404.
     * @throws ResourceModifiedException thrown if the request is rejected by server on status code 409.
     * @return a collection of content tags, along with a list of captions sorted by confidence level, and image
     *     metadata along with {@link Response} on successful completion of {@link Mono}.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    public Mono<Response<BinaryData>> describeImageInStreamWithResponseAsync(
            String contentType, BinaryData image, long contentLength, RequestOptions requestOptions, Context context) {
        final String accept = "application/json";
        return service.describeImageInStream(
                this.getEndpoint(), contentType, image, contentLength, accept, requestOptions, context);
    }

    /**
     * This operation generates a description of an image in human readable language with complete sentences. The
     * description is based on a collection of content tags, which are also returned by the operation. More than one
     * description can be generated for each image. Descriptions are ordered by their confidence score. Descriptions may
     * include results from celebrity and landmark domain models, if applicable. Two input methods are supported -- (1)
     * Uploading an image or (2) specifying an image URL. A successful response will be returned in JSON. If the request
     * failed, the response will contain an error code and a message to help understand what went wrong.
     *
     * <p><strong>Query Parameters</strong>
     *
     * <table border="1">
     *     <caption>Query Parameters</caption>
     *     <tr><th>Name</th><th>Type</th><th>Required</th><th>Description</th></tr>
     *     <tr><td>maxCandidates</td><td>Integer</td><td>No</td><td>Maximum number of candidate descriptions to be returned.  The default is 1.</td></tr>
     *     <tr><td>language</td><td>String</td><td>No</td><td>The desired language for output generation. If this parameter is not specified, the default value is "en". See https://aka.ms/cv-languages for list of supported languages.</td></tr>
     *     <tr><td>descriptionExclude</td><td>List&lt;String&gt;</td><td>No</td><td>Turn off specified domain models when generating the description. In the form of "," separated string.</td></tr>
     *     <tr><td>model-version</td><td>String</td><td>No</td><td>Optional parameter to specify the version of the AI model. Accepted values are: "latest", "2021-04-01", "2021-05-01". Defaults to "latest".</td></tr>
     * </table>
     *
     * <p><strong>Request Body Schema</strong>
     *
     * <pre>{@code
     * Flux<ByteBuffer>
     * }</pre>
     *
     * <p><strong>Response Body Schema</strong>
     *
     * <pre>{@code
     * {
     *     description: {
     *         tags: [
     *             String
     *         ]
     *         captions: [
     *             {
     *                 text: String
     *                 confidence: Double
     *             }
     *         ]
     *     }
     *     requestId: String
     *     metadata: {
     *         width: Integer
     *         height: Integer
     *         format: String
     *     }
     *     modelVersion: String
     * }
     * }</pre>
     *
     * @param contentType Upload file type.
     * @param image An image stream.
     * @param contentLength The contentLength parameter.
     * @param requestOptions The options to configure the HTTP request before HTTP client sends it.
     * @throws HttpResponseException thrown if the request is rejected by server.
     * @throws ClientAuthenticationException thrown if the request is rejected by server on status code 401.
     * @throws ResourceNotFoundException thrown if the request is rejected by server on status code 404.
     * @throws ResourceModifiedException thrown if the request is rejected by server on status code 409.
     * @return a collection of content tags, along with a list of captions sorted by confidence level, and image
     *     metadata along with {@link Response}.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    public Response<BinaryData> describeImageInStreamWithResponse(
            String contentType, BinaryData image, long contentLength, RequestOptions requestOptions) {
        return describeImageInStreamWithResponseAsync(contentType, image, contentLength, requestOptions).block();
    }

    /**
     * Performs object detection on the specified image. Two input methods are supported -- (1) Uploading an image or
     * (2) specifying an image URL. A successful response will be returned in JSON. If the request failed, the response
     * will contain an error code and a message to help understand what went wrong.
     *
     * <p><strong>Query Parameters</strong>
     *
     * <table border="1">
     *     <caption>Query Parameters</caption>
     *     <tr><th>Name</th><th>Type</th><th>Required</th><th>Description</th></tr>
     *     <tr><td>model-version</td><td>String</td><td>No</td><td>Optional parameter to specify the version of the AI model. Accepted values are: "latest", "2021-04-01", "2021-05-01". Defaults to "latest".</td></tr>
     * </table>
     *
     * <p><strong>Request Body Schema</strong>
     *
     * <pre>{@code
     * Flux<ByteBuffer>
     * }</pre>
     *
     * <p><strong>Response Body Schema</strong>
     *
     * <pre>{@code
     * {
     *     objects: [
     *         {
     *             rectangle: {
     *                 x: Integer
     *                 y: Integer
     *                 w: Integer
     *                 h: Integer
     *             }
     *             object: String
     *             confidence: Double
     *             parent: {
     *                 object: String
     *                 confidence: Double
     *                 parent: (recursive schema, see parent above)
     *             }
     *         }
     *     ]
     *     requestId: String
     *     metadata: {
     *         width: Integer
     *         height: Integer
     *         format: String
     *     }
     *     modelVersion: String
     * }
     * }</pre>
     *
     * @param contentType Upload file type.
     * @param image An image stream.
     * @param contentLength The contentLength parameter.
     * @param requestOptions The options to configure the HTTP request before HTTP client sends it.
     * @throws HttpResponseException thrown if the request is rejected by server.
     * @throws ClientAuthenticationException thrown if the request is rejected by server on status code 401.
     * @throws ResourceNotFoundException thrown if the request is rejected by server on status code 404.
     * @throws ResourceModifiedException thrown if the request is rejected by server on status code 409.
     * @return result of a DetectImage call along with {@link Response} on successful completion of {@link Mono}.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    public Mono<Response<BinaryData>> detectObjectsInStreamWithResponseAsync(
            String contentType, BinaryData image, long contentLength, RequestOptions requestOptions) {
        final String accept = "application/json";
        return FluxUtil.withContext(
                context ->
                        service.detectObjectsInStream(
                                this.getEndpoint(),
                                contentType,
                                image,
                                contentLength,
                                accept,
                                requestOptions,
                                context));
    }

    /**
     * Performs object detection on the specified image. Two input methods are supported -- (1) Uploading an image or
     * (2) specifying an image URL. A successful response will be returned in JSON. If the request failed, the response
     * will contain an error code and a message to help understand what went wrong.
     *
     * <p><strong>Query Parameters</strong>
     *
     * <table border="1">
     *     <caption>Query Parameters</caption>
     *     <tr><th>Name</th><th>Type</th><th>Required</th><th>Description</th></tr>
     *     <tr><td>model-version</td><td>String</td><td>No</td><td>Optional parameter to specify the version of the AI model. Accepted values are: "latest", "2021-04-01", "2021-05-01". Defaults to "latest".</td></tr>
     * </table>
     *
     * <p><strong>Request Body Schema</strong>
     *
     * <pre>{@code
     * Flux<ByteBuffer>
     * }</pre>
     *
     * <p><strong>Response Body Schema</strong>
     *
     * <pre>{@code
     * {
     *     objects: [
     *         {
     *             rectangle: {
     *                 x: Integer
     *                 y: Integer
     *                 w: Integer
     *                 h: Integer
     *             }
     *             object: String
     *             confidence: Double
     *             parent: {
     *                 object: String
     *                 confidence: Double
     *                 parent: (recursive schema, see parent above)
     *             }
     *         }
     *     ]
     *     requestId: String
     *     metadata: {
     *         width: Integer
     *         height: Integer
     *         format: String
     *     }
     *     modelVersion: String
     * }
     * }</pre>
     *
     * @param contentType Upload file type.
     * @param image An image stream.
     * @param contentLength The contentLength parameter.
     * @param requestOptions The options to configure the HTTP request before HTTP client sends it.
     * @param context The context to associate with this operation.
     * @throws HttpResponseException thrown if the request is rejected by server.
     * @throws ClientAuthenticationException thrown if the request is rejected by server on status code 401.
     * @throws ResourceNotFoundException thrown if the request is rejected by server on status code 404.
     * @throws ResourceModifiedException thrown if the request is rejected by server on status code 409.
     * @return result of a DetectImage call along with {@link Response} on successful completion of {@link Mono}.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    public Mono<Response<BinaryData>> detectObjectsInStreamWithResponseAsync(
            String contentType, BinaryData image, long contentLength, RequestOptions requestOptions, Context context) {
        final String accept = "application/json";
        return service.detectObjectsInStream(
                this.getEndpoint(), contentType, image, contentLength, accept, requestOptions, context);
    }

    /**
     * Performs object detection on the specified image. Two input methods are supported -- (1) Uploading an image or
     * (2) specifying an image URL. A successful response will be returned in JSON. If the request failed, the response
     * will contain an error code and a message to help understand what went wrong.
     *
     * <p><strong>Query Parameters</strong>
     *
     * <table border="1">
     *     <caption>Query Parameters</caption>
     *     <tr><th>Name</th><th>Type</th><th>Required</th><th>Description</th></tr>
     *     <tr><td>model-version</td><td>String</td><td>No</td><td>Optional parameter to specify the version of the AI model. Accepted values are: "latest", "2021-04-01", "2021-05-01". Defaults to "latest".</td></tr>
     * </table>
     *
     * <p><strong>Request Body Schema</strong>
     *
     * <pre>{@code
     * Flux<ByteBuffer>
     * }</pre>
     *
     * <p><strong>Response Body Schema</strong>
     *
     * <pre>{@code
     * {
     *     objects: [
     *         {
     *             rectangle: {
     *                 x: Integer
     *                 y: Integer
     *                 w: Integer
     *                 h: Integer
     *             }
     *             object: String
     *             confidence: Double
     *             parent: {
     *                 object: String
     *                 confidence: Double
     *                 parent: (recursive schema, see parent above)
     *             }
     *         }
     *     ]
     *     requestId: String
     *     metadata: {
     *         width: Integer
     *         height: Integer
     *         format: String
     *     }
     *     modelVersion: String
     * }
     * }</pre>
     *
     * @param contentType Upload file type.
     * @param image An image stream.
     * @param contentLength The contentLength parameter.
     * @param requestOptions The options to configure the HTTP request before HTTP client sends it.
     * @throws HttpResponseException thrown if the request is rejected by server.
     * @throws ClientAuthenticationException thrown if the request is rejected by server on status code 401.
     * @throws ResourceNotFoundException thrown if the request is rejected by server on status code 404.
     * @throws ResourceModifiedException thrown if the request is rejected by server on status code 409.
     * @return result of a DetectImage call along with {@link Response}.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    public Response<BinaryData> detectObjectsInStreamWithResponse(
            String contentType, BinaryData image, long contentLength, RequestOptions requestOptions) {
        return detectObjectsInStreamWithResponseAsync(contentType, image, contentLength, requestOptions).block();
    }

    /**
     * This operation generates a thumbnail image with the user-specified width and height. By default, the service
     * analyzes the image, identifies the region of interest (ROI), and generates smart cropping coordinates based on
     * the ROI. Smart cropping helps when you specify an aspect ratio that differs from that of the input image. A
     * successful response contains the thumbnail image binary. If the request failed, the response contains an error
     * code and a message to help determine what went wrong. Upon failure, the error code and an error message are
     * returned. The error code could be one of InvalidImageUrl, InvalidImageFormat, InvalidImageSize,
     * InvalidThumbnailSize, NotSupportedImage, FailedToProcess, Timeout, or InternalServerError.
     *
     * <p><strong>Query Parameters</strong>
     *
     * <table border="1">
     *     <caption>Query Parameters</caption>
     *     <tr><th>Name</th><th>Type</th><th>Required</th><th>Description</th></tr>
     *     <tr><td>smartCropping</td><td>Boolean</td><td>No</td><td>Boolean flag for enabling smart cropping.</td></tr>
     *     <tr><td>model-version</td><td>String</td><td>No</td><td>Optional parameter to specify the version of the AI model. Accepted values are: "latest", "2021-04-01", "2021-05-01". Defaults to "latest".</td></tr>
     * </table>
     *
     * <p><strong>Request Body Schema</strong>
     *
     * <pre>{@code
     * Flux<ByteBuffer>
     * }</pre>
     *
     * @param width Width of the thumbnail, in pixels. It must be between 1 and 1024. Recommended minimum of 50.
     * @param height Height of the thumbnail, in pixels. It must be between 1 and 1024. Recommended minimum of 50.
     * @param contentType Upload file type.
     * @param image An image stream.
     * @param contentLength The contentLength parameter.
     * @param requestOptions The options to configure the HTTP request before HTTP client sends it.
     * @throws HttpResponseException thrown if the request is rejected by server.
     * @throws ClientAuthenticationException thrown if the request is rejected by server on status code 401.
     * @throws ResourceNotFoundException thrown if the request is rejected by server on status code 404.
     * @throws ResourceModifiedException thrown if the request is rejected by server on status code 409.
     * @return the {@link Response} on successful completion of {@link Mono}.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    public Mono<Response<Void>> generateThumbnailInStreamWithResponseAsync(
            int width,
            int height,
            String contentType,
            BinaryData image,
            long contentLength,
            RequestOptions requestOptions) {
        final String accept = "application/octet-stream";
        return FluxUtil.withContext(
                context ->
                        service.generateThumbnailInStream(
                                this.getEndpoint(),
                                width,
                                height,
                                contentType,
                                image,
                                contentLength,
                                accept,
                                requestOptions,
                                context));
    }

    /**
     * This operation generates a thumbnail image with the user-specified width and height. By default, the service
     * analyzes the image, identifies the region of interest (ROI), and generates smart cropping coordinates based on
     * the ROI. Smart cropping helps when you specify an aspect ratio that differs from that of the input image. A
     * successful response contains the thumbnail image binary. If the request failed, the response contains an error
     * code and a message to help determine what went wrong. Upon failure, the error code and an error message are
     * returned. The error code could be one of InvalidImageUrl, InvalidImageFormat, InvalidImageSize,
     * InvalidThumbnailSize, NotSupportedImage, FailedToProcess, Timeout, or InternalServerError.
     *
     * <p><strong>Query Parameters</strong>
     *
     * <table border="1">
     *     <caption>Query Parameters</caption>
     *     <tr><th>Name</th><th>Type</th><th>Required</th><th>Description</th></tr>
     *     <tr><td>smartCropping</td><td>Boolean</td><td>No</td><td>Boolean flag for enabling smart cropping.</td></tr>
     *     <tr><td>model-version</td><td>String</td><td>No</td><td>Optional parameter to specify the version of the AI model. Accepted values are: "latest", "2021-04-01", "2021-05-01". Defaults to "latest".</td></tr>
     * </table>
     *
     * <p><strong>Request Body Schema</strong>
     *
     * <pre>{@code
     * Flux<ByteBuffer>
     * }</pre>
     *
     * @param width Width of the thumbnail, in pixels. It must be between 1 and 1024. Recommended minimum of 50.
     * @param height Height of the thumbnail, in pixels. It must be between 1 and 1024. Recommended minimum of 50.
     * @param contentType Upload file type.
     * @param image An image stream.
     * @param contentLength The contentLength parameter.
     * @param requestOptions The options to configure the HTTP request before HTTP client sends it.
     * @param context The context to associate with this operation.
     * @throws HttpResponseException thrown if the request is rejected by server.
     * @throws ClientAuthenticationException thrown if the request is rejected by server on status code 401.
     * @throws ResourceNotFoundException thrown if the request is rejected by server on status code 404.
     * @throws ResourceModifiedException thrown if the request is rejected by server on status code 409.
     * @return the {@link Response} on successful completion of {@link Mono}.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    public Mono<Response<Void>> generateThumbnailInStreamWithResponseAsync(
            int width,
            int height,
            String contentType,
            BinaryData image,
            long contentLength,
            RequestOptions requestOptions,
            Context context) {
        final String accept = "application/octet-stream";
        return service.generateThumbnailInStream(
                this.getEndpoint(), width, height, contentType, image, contentLength, accept, requestOptions, context);
    }

    /**
     * This operation generates a thumbnail image with the user-specified width and height. By default, the service
     * analyzes the image, identifies the region of interest (ROI), and generates smart cropping coordinates based on
     * the ROI. Smart cropping helps when you specify an aspect ratio that differs from that of the input image. A
     * successful response contains the thumbnail image binary. If the request failed, the response contains an error
     * code and a message to help determine what went wrong. Upon failure, the error code and an error message are
     * returned. The error code could be one of InvalidImageUrl, InvalidImageFormat, InvalidImageSize,
     * InvalidThumbnailSize, NotSupportedImage, FailedToProcess, Timeout, or InternalServerError.
     *
     * <p><strong>Query Parameters</strong>
     *
     * <table border="1">
     *     <caption>Query Parameters</caption>
     *     <tr><th>Name</th><th>Type</th><th>Required</th><th>Description</th></tr>
     *     <tr><td>smartCropping</td><td>Boolean</td><td>No</td><td>Boolean flag for enabling smart cropping.</td></tr>
     *     <tr><td>model-version</td><td>String</td><td>No</td><td>Optional parameter to specify the version of the AI model. Accepted values are: "latest", "2021-04-01", "2021-05-01". Defaults to "latest".</td></tr>
     * </table>
     *
     * <p><strong>Request Body Schema</strong>
     *
     * <pre>{@code
     * Flux<ByteBuffer>
     * }</pre>
     *
     * @param width Width of the thumbnail, in pixels. It must be between 1 and 1024. Recommended minimum of 50.
     * @param height Height of the thumbnail, in pixels. It must be between 1 and 1024. Recommended minimum of 50.
     * @param contentType Upload file type.
     * @param image An image stream.
     * @param contentLength The contentLength parameter.
     * @param requestOptions The options to configure the HTTP request before HTTP client sends it.
     * @throws HttpResponseException thrown if the request is rejected by server.
     * @throws ClientAuthenticationException thrown if the request is rejected by server on status code 401.
     * @throws ResourceNotFoundException thrown if the request is rejected by server on status code 404.
     * @throws ResourceModifiedException thrown if the request is rejected by server on status code 409.
     * @return the {@link Response}.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    public Response<Void> generateThumbnailInStreamWithResponse(
            int width,
            int height,
            String contentType,
            BinaryData image,
            long contentLength,
            RequestOptions requestOptions) {
        return generateThumbnailInStreamWithResponseAsync(
                        width, height, contentType, image, contentLength, requestOptions)
                .block();
    }

    /**
     * This operation recognizes content within an image by applying a domain-specific model. The list of
     * domain-specific models that are supported by the Computer Vision API can be retrieved using the /models GET
     * request. Currently, the API provides following domain-specific models: celebrities, landmarks. Two input methods
     * are supported -- (1) Uploading an image or (2) specifying an image URL. A successful response will be returned in
     * JSON. If the request failed, the response will contain an error code and a message to help understand what went
     * wrong.
     *
     * <p><strong>Query Parameters</strong>
     *
     * <table border="1">
     *     <caption>Query Parameters</caption>
     *     <tr><th>Name</th><th>Type</th><th>Required</th><th>Description</th></tr>
     *     <tr><td>language</td><td>String</td><td>No</td><td>The desired language for output generation. If this parameter is not specified, the default value is "en". See https://aka.ms/cv-languages for list of supported languages.</td></tr>
     *     <tr><td>model-version</td><td>String</td><td>No</td><td>Optional parameter to specify the version of the AI model. Accepted values are: "latest", "2021-04-01", "2021-05-01". Defaults to "latest".</td></tr>
     * </table>
     *
     * <p><strong>Request Body Schema</strong>
     *
     * <pre>{@code
     * Flux<ByteBuffer>
     * }</pre>
     *
     * <p><strong>Response Body Schema</strong>
     *
     * <pre>{@code
     * {
     *     result: Object
     *     requestId: String
     *     metadata: {
     *         width: Integer
     *         height: Integer
     *         format: String
     *     }
     *     modelVersion: String
     * }
     * }</pre>
     *
     * @param model The domain-specific content to recognize.
     * @param contentType Upload file type.
     * @param image An image stream.
     * @param contentLength The contentLength parameter.
     * @param requestOptions The options to configure the HTTP request before HTTP client sends it.
     * @throws HttpResponseException thrown if the request is rejected by server.
     * @throws ClientAuthenticationException thrown if the request is rejected by server on status code 401.
     * @throws ResourceNotFoundException thrown if the request is rejected by server on status code 404.
     * @throws ResourceModifiedException thrown if the request is rejected by server on status code 409.
     * @return result of image analysis using a specific domain model including additional metadata along with {@link
     *     Response} on successful completion of {@link Mono}.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    public Mono<Response<BinaryData>> analyzeImageByDomainInStreamWithResponseAsync(
            String model, String contentType, BinaryData image, long contentLength, RequestOptions requestOptions) {
        final String accept = "application/json";
        return FluxUtil.withContext(
                context ->
                        service.analyzeImageByDomainInStream(
                                this.getEndpoint(),
                                model,
                                contentType,
                                image,
                                contentLength,
                                accept,
                                requestOptions,
                                context));
    }

    /**
     * This operation recognizes content within an image by applying a domain-specific model. The list of
     * domain-specific models that are supported by the Computer Vision API can be retrieved using the /models GET
     * request. Currently, the API provides following domain-specific models: celebrities, landmarks. Two input methods
     * are supported -- (1) Uploading an image or (2) specifying an image URL. A successful response will be returned in
     * JSON. If the request failed, the response will contain an error code and a message to help understand what went
     * wrong.
     *
     * <p><strong>Query Parameters</strong>
     *
     * <table border="1">
     *     <caption>Query Parameters</caption>
     *     <tr><th>Name</th><th>Type</th><th>Required</th><th>Description</th></tr>
     *     <tr><td>language</td><td>String</td><td>No</td><td>The desired language for output generation. If this parameter is not specified, the default value is "en". See https://aka.ms/cv-languages for list of supported languages.</td></tr>
     *     <tr><td>model-version</td><td>String</td><td>No</td><td>Optional parameter to specify the version of the AI model. Accepted values are: "latest", "2021-04-01", "2021-05-01". Defaults to "latest".</td></tr>
     * </table>
     *
     * <p><strong>Request Body Schema</strong>
     *
     * <pre>{@code
     * Flux<ByteBuffer>
     * }</pre>
     *
     * <p><strong>Response Body Schema</strong>
     *
     * <pre>{@code
     * {
     *     result: Object
     *     requestId: String
     *     metadata: {
     *         width: Integer
     *         height: Integer
     *         format: String
     *     }
     *     modelVersion: String
     * }
     * }</pre>
     *
     * @param model The domain-specific content to recognize.
     * @param contentType Upload file type.
     * @param image An image stream.
     * @param contentLength The contentLength parameter.
     * @param requestOptions The options to configure the HTTP request before HTTP client sends it.
     * @param context The context to associate with this operation.
     * @throws HttpResponseException thrown if the request is rejected by server.
     * @throws ClientAuthenticationException thrown if the request is rejected by server on status code 401.
     * @throws ResourceNotFoundException thrown if the request is rejected by server on status code 404.
     * @throws ResourceModifiedException thrown if the request is rejected by server on status code 409.
     * @return result of image analysis using a specific domain model including additional metadata along with {@link
     *     Response} on successful completion of {@link Mono}.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    public Mono<Response<BinaryData>> analyzeImageByDomainInStreamWithResponseAsync(
            String model,
            String contentType,
            BinaryData image,
            long contentLength,
            RequestOptions requestOptions,
            Context context) {
        final String accept = "application/json";
        return service.analyzeImageByDomainInStream(
                this.getEndpoint(), model, contentType, image, contentLength, accept, requestOptions, context);
    }

    /**
     * This operation recognizes content within an image by applying a domain-specific model. The list of
     * domain-specific models that are supported by the Computer Vision API can be retrieved using the /models GET
     * request. Currently, the API provides following domain-specific models: celebrities, landmarks. Two input methods
     * are supported -- (1) Uploading an image or (2) specifying an image URL. A successful response will be returned in
     * JSON. If the request failed, the response will contain an error code and a message to help understand what went
     * wrong.
     *
     * <p><strong>Query Parameters</strong>
     *
     * <table border="1">
     *     <caption>Query Parameters</caption>
     *     <tr><th>Name</th><th>Type</th><th>Required</th><th>Description</th></tr>
     *     <tr><td>language</td><td>String</td><td>No</td><td>The desired language for output generation. If this parameter is not specified, the default value is "en". See https://aka.ms/cv-languages for list of supported languages.</td></tr>
     *     <tr><td>model-version</td><td>String</td><td>No</td><td>Optional parameter to specify the version of the AI model. Accepted values are: "latest", "2021-04-01", "2021-05-01". Defaults to "latest".</td></tr>
     * </table>
     *
     * <p><strong>Request Body Schema</strong>
     *
     * <pre>{@code
     * Flux<ByteBuffer>
     * }</pre>
     *
     * <p><strong>Response Body Schema</strong>
     *
     * <pre>{@code
     * {
     *     result: Object
     *     requestId: String
     *     metadata: {
     *         width: Integer
     *         height: Integer
     *         format: String
     *     }
     *     modelVersion: String
     * }
     * }</pre>
     *
     * @param model The domain-specific content to recognize.
     * @param contentType Upload file type.
     * @param image An image stream.
     * @param contentLength The contentLength parameter.
     * @param requestOptions The options to configure the HTTP request before HTTP client sends it.
     * @throws HttpResponseException thrown if the request is rejected by server.
     * @throws ClientAuthenticationException thrown if the request is rejected by server on status code 401.
     * @throws ResourceNotFoundException thrown if the request is rejected by server on status code 404.
     * @throws ResourceModifiedException thrown if the request is rejected by server on status code 409.
     * @return result of image analysis using a specific domain model including additional metadata along with {@link
     *     Response}.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    public Response<BinaryData> analyzeImageByDomainInStreamWithResponse(
            String model, String contentType, BinaryData image, long contentLength, RequestOptions requestOptions) {
        return analyzeImageByDomainInStreamWithResponseAsync(model, contentType, image, contentLength, requestOptions)
                .block();
    }

    /**
     * Optical Character Recognition (OCR) detects text in an image and extracts the recognized characters into a
     * machine-usable character stream. Upon success, the OCR results will be returned. Upon failure, the error code
     * together with an error message will be returned. The error code can be one of InvalidImageUrl,
     * InvalidImageFormat, InvalidImageSize, NotSupportedImage, NotSupportedLanguage, or InternalServerError.
     *
     * <p><strong>Query Parameters</strong>
     *
     * <table border="1">
     *     <caption>Query Parameters</caption>
     *     <tr><th>Name</th><th>Type</th><th>Required</th><th>Description</th></tr>
     *     <tr><td>language</td><td>String</td><td>No</td><td>The BCP-47 language code of the text to be detected in the image. The default value is 'unk'.</td></tr>
     *     <tr><td>model-version</td><td>String</td><td>No</td><td>Optional parameter to specify the version of the AI model. Accepted values are: "latest", "2021-04-01", "2021-05-01". Defaults to "latest".</td></tr>
     * </table>
     *
     * <p><strong>Request Body Schema</strong>
     *
     * <pre>{@code
     * Flux<ByteBuffer>
     * }</pre>
     *
     * <p><strong>Response Body Schema</strong>
     *
     * <pre>{@code
     * {
     *     language: String
     *     textAngle: Double
     *     orientation: String
     *     regions: [
     *         {
     *             boundingBox: String
     *             lines: [
     *                 {
     *                     boundingBox: String
     *                     words: [
     *                         {
     *                             boundingBox: String
     *                             text: String
     *                         }
     *                     ]
     *                 }
     *             ]
     *         }
     *     ]
     *     modelVersion: String
     * }
     * }</pre>
     *
     * @param detectOrientation Whether detect the text orientation in the image. With detectOrientation=true the OCR
     *     service tries to detect the image orientation and correct it before further processing (e.g. if it's
     *     upside-down).
     * @param contentType Upload file type.
     * @param image An image stream.
     * @param contentLength The contentLength parameter.
     * @param requestOptions The options to configure the HTTP request before HTTP client sends it.
     * @throws HttpResponseException thrown if the request is rejected by server.
     * @throws ClientAuthenticationException thrown if the request is rejected by server on status code 401.
     * @throws ResourceNotFoundException thrown if the request is rejected by server on status code 404.
     * @throws ResourceModifiedException thrown if the request is rejected by server on status code 409.
     * @return the response body along with {@link Response} on successful completion of {@link Mono}.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    public Mono<Response<BinaryData>> recognizePrintedTextInStreamWithResponseAsync(
            boolean detectOrientation,
            String contentType,
            BinaryData image,
            long contentLength,
            RequestOptions requestOptions) {
        final String accept = "application/json";
        return FluxUtil.withContext(
                context ->
                        service.recognizePrintedTextInStream(
                                this.getEndpoint(),
                                detectOrientation,
                                contentType,
                                image,
                                contentLength,
                                accept,
                                requestOptions,
                                context));
    }

    /**
     * Optical Character Recognition (OCR) detects text in an image and extracts the recognized characters into a
     * machine-usable character stream. Upon success, the OCR results will be returned. Upon failure, the error code
     * together with an error message will be returned. The error code can be one of InvalidImageUrl,
     * InvalidImageFormat, InvalidImageSize, NotSupportedImage, NotSupportedLanguage, or InternalServerError.
     *
     * <p><strong>Query Parameters</strong>
     *
     * <table border="1">
     *     <caption>Query Parameters</caption>
     *     <tr><th>Name</th><th>Type</th><th>Required</th><th>Description</th></tr>
     *     <tr><td>language</td><td>String</td><td>No</td><td>The BCP-47 language code of the text to be detected in the image. The default value is 'unk'.</td></tr>
     *     <tr><td>model-version</td><td>String</td><td>No</td><td>Optional parameter to specify the version of the AI model. Accepted values are: "latest", "2021-04-01", "2021-05-01". Defaults to "latest".</td></tr>
     * </table>
     *
     * <p><strong>Request Body Schema</strong>
     *
     * <pre>{@code
     * Flux<ByteBuffer>
     * }</pre>
     *
     * <p><strong>Response Body Schema</strong>
     *
     * <pre>{@code
     * {
     *     language: String
     *     textAngle: Double
     *     orientation: String
     *     regions: [
     *         {
     *             boundingBox: String
     *             lines: [
     *                 {
     *                     boundingBox: String
     *                     words: [
     *                         {
     *                             boundingBox: String
     *                             text: String
     *                         }
     *                     ]
     *                 }
     *             ]
     *         }
     *     ]
     *     modelVersion: String
     * }
     * }</pre>
     *
     * @param detectOrientation Whether detect the text orientation in the image. With detectOrientation=true the OCR
     *     service tries to detect the image orientation and correct it before further processing (e.g. if it's
     *     upside-down).
     * @param contentType Upload file type.
     * @param image An image stream.
     * @param contentLength The contentLength parameter.
     * @param requestOptions The options to configure the HTTP request before HTTP client sends it.
     * @param context The context to associate with this operation.
     * @throws HttpResponseException thrown if the request is rejected by server.
     * @throws ClientAuthenticationException thrown if the request is rejected by server on status code 401.
     * @throws ResourceNotFoundException thrown if the request is rejected by server on status code 404.
     * @throws ResourceModifiedException thrown if the request is rejected by server on status code 409.
     * @return the response body along with {@link Response} on successful completion of {@link Mono}.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    public Mono<Response<BinaryData>> recognizePrintedTextInStreamWithResponseAsync(
            boolean detectOrientation,
            String contentType,
            BinaryData image,
            long contentLength,
            RequestOptions requestOptions,
            Context context) {
        final String accept = "application/json";
        return service.recognizePrintedTextInStream(
                this.getEndpoint(),
                detectOrientation,
                contentType,
                image,
                contentLength,
                accept,
                requestOptions,
                context);
    }

    /**
     * Optical Character Recognition (OCR) detects text in an image and extracts the recognized characters into a
     * machine-usable character stream. Upon success, the OCR results will be returned. Upon failure, the error code
     * together with an error message will be returned. The error code can be one of InvalidImageUrl,
     * InvalidImageFormat, InvalidImageSize, NotSupportedImage, NotSupportedLanguage, or InternalServerError.
     *
     * <p><strong>Query Parameters</strong>
     *
     * <table border="1">
     *     <caption>Query Parameters</caption>
     *     <tr><th>Name</th><th>Type</th><th>Required</th><th>Description</th></tr>
     *     <tr><td>language</td><td>String</td><td>No</td><td>The BCP-47 language code of the text to be detected in the image. The default value is 'unk'.</td></tr>
     *     <tr><td>model-version</td><td>String</td><td>No</td><td>Optional parameter to specify the version of the AI model. Accepted values are: "latest", "2021-04-01", "2021-05-01". Defaults to "latest".</td></tr>
     * </table>
     *
     * <p><strong>Request Body Schema</strong>
     *
     * <pre>{@code
     * Flux<ByteBuffer>
     * }</pre>
     *
     * <p><strong>Response Body Schema</strong>
     *
     * <pre>{@code
     * {
     *     language: String
     *     textAngle: Double
     *     orientation: String
     *     regions: [
     *         {
     *             boundingBox: String
     *             lines: [
     *                 {
     *                     boundingBox: String
     *                     words: [
     *                         {
     *                             boundingBox: String
     *                             text: String
     *                         }
     *                     ]
     *                 }
     *             ]
     *         }
     *     ]
     *     modelVersion: String
     * }
     * }</pre>
     *
     * @param detectOrientation Whether detect the text orientation in the image. With detectOrientation=true the OCR
     *     service tries to detect the image orientation and correct it before further processing (e.g. if it's
     *     upside-down).
     * @param contentType Upload file type.
     * @param image An image stream.
     * @param contentLength The contentLength parameter.
     * @param requestOptions The options to configure the HTTP request before HTTP client sends it.
     * @throws HttpResponseException thrown if the request is rejected by server.
     * @throws ClientAuthenticationException thrown if the request is rejected by server on status code 401.
     * @throws ResourceNotFoundException thrown if the request is rejected by server on status code 404.
     * @throws ResourceModifiedException thrown if the request is rejected by server on status code 409.
     * @return the response body along with {@link Response}.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    public Response<BinaryData> recognizePrintedTextInStreamWithResponse(
            boolean detectOrientation,
            String contentType,
            BinaryData image,
            long contentLength,
            RequestOptions requestOptions) {
        return recognizePrintedTextInStreamWithResponseAsync(
                        detectOrientation, contentType, image, contentLength, requestOptions)
                .block();
    }

    /**
     * This operation generates a list of words, or tags, that are relevant to the content of the supplied image. The
     * Computer Vision API can return tags based on objects, living beings, scenery or actions found in images. Unlike
     * categories, tags are not organized according to a hierarchical classification system, but correspond to image
     * content. Tags may contain hints to avoid ambiguity or provide context, for example the tag "ascomycete" may be
     * accompanied by the hint "fungus". Two input methods are supported -- (1) Uploading an image or (2) specifying an
     * image URL. A successful response will be returned in JSON. If the request failed, the response will contain an
     * error code and a message to help understand what went wrong.
     *
     * <p><strong>Query Parameters</strong>
     *
     * <table border="1">
     *     <caption>Query Parameters</caption>
     *     <tr><th>Name</th><th>Type</th><th>Required</th><th>Description</th></tr>
     *     <tr><td>language</td><td>String</td><td>No</td><td>The desired language for output generation. If this parameter is not specified, the default value is "en". See https://aka.ms/cv-languages for list of supported languages.</td></tr>
     *     <tr><td>model-version</td><td>String</td><td>No</td><td>Optional parameter to specify the version of the AI model. Accepted values are: "latest", "2021-04-01", "2021-05-01". Defaults to "latest".</td></tr>
     * </table>
     *
     * <p><strong>Request Body Schema</strong>
     *
     * <pre>{@code
     * Flux<ByteBuffer>
     * }</pre>
     *
     * <p><strong>Response Body Schema</strong>
     *
     * <pre>{@code
     * {
     *     tags: [
     *         {
     *             name: String
     *             confidence: Double
     *             hint: String
     *         }
     *     ]
     *     requestId: String
     *     metadata: {
     *         width: Integer
     *         height: Integer
     *         format: String
     *     }
     *     modelVersion: String
     * }
     * }</pre>
     *
     * @param contentType Upload file type.
     * @param image An image stream.
     * @param contentLength The contentLength parameter.
     * @param requestOptions The options to configure the HTTP request before HTTP client sends it.
     * @throws HttpResponseException thrown if the request is rejected by server.
     * @throws ClientAuthenticationException thrown if the request is rejected by server on status code 401.
     * @throws ResourceNotFoundException thrown if the request is rejected by server on status code 404.
     * @throws ResourceModifiedException thrown if the request is rejected by server on status code 409.
     * @return the results of a image tag operation, including any tags and image metadata along with {@link Response}
     *     on successful completion of {@link Mono}.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    public Mono<Response<BinaryData>> tagImageInStreamWithResponseAsync(
            String contentType, BinaryData image, long contentLength, RequestOptions requestOptions) {
        final String accept = "application/json";
        return FluxUtil.withContext(
                context ->
                        service.tagImageInStream(
                                this.getEndpoint(),
                                contentType,
                                image,
                                contentLength,
                                accept,
                                requestOptions,
                                context));
    }

    /**
     * This operation generates a list of words, or tags, that are relevant to the content of the supplied image. The
     * Computer Vision API can return tags based on objects, living beings, scenery or actions found in images. Unlike
     * categories, tags are not organized according to a hierarchical classification system, but correspond to image
     * content. Tags may contain hints to avoid ambiguity or provide context, for example the tag "ascomycete" may be
     * accompanied by the hint "fungus". Two input methods are supported -- (1) Uploading an image or (2) specifying an
     * image URL. A successful response will be returned in JSON. If the request failed, the response will contain an
     * error code and a message to help understand what went wrong.
     *
     * <p><strong>Query Parameters</strong>
     *
     * <table border="1">
     *     <caption>Query Parameters</caption>
     *     <tr><th>Name</th><th>Type</th><th>Required</th><th>Description</th></tr>
     *     <tr><td>language</td><td>String</td><td>No</td><td>The desired language for output generation. If this parameter is not specified, the default value is "en". See https://aka.ms/cv-languages for list of supported languages.</td></tr>
     *     <tr><td>model-version</td><td>String</td><td>No</td><td>Optional parameter to specify the version of the AI model. Accepted values are: "latest", "2021-04-01", "2021-05-01". Defaults to "latest".</td></tr>
     * </table>
     *
     * <p><strong>Request Body Schema</strong>
     *
     * <pre>{@code
     * Flux<ByteBuffer>
     * }</pre>
     *
     * <p><strong>Response Body Schema</strong>
     *
     * <pre>{@code
     * {
     *     tags: [
     *         {
     *             name: String
     *             confidence: Double
     *             hint: String
     *         }
     *     ]
     *     requestId: String
     *     metadata: {
     *         width: Integer
     *         height: Integer
     *         format: String
     *     }
     *     modelVersion: String
     * }
     * }</pre>
     *
     * @param contentType Upload file type.
     * @param image An image stream.
     * @param contentLength The contentLength parameter.
     * @param requestOptions The options to configure the HTTP request before HTTP client sends it.
     * @param context The context to associate with this operation.
     * @throws HttpResponseException thrown if the request is rejected by server.
     * @throws ClientAuthenticationException thrown if the request is rejected by server on status code 401.
     * @throws ResourceNotFoundException thrown if the request is rejected by server on status code 404.
     * @throws ResourceModifiedException thrown if the request is rejected by server on status code 409.
     * @return the results of a image tag operation, including any tags and image metadata along with {@link Response}
     *     on successful completion of {@link Mono}.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    public Mono<Response<BinaryData>> tagImageInStreamWithResponseAsync(
            String contentType, BinaryData image, long contentLength, RequestOptions requestOptions, Context context) {
        final String accept = "application/json";
        return service.tagImageInStream(
                this.getEndpoint(), contentType, image, contentLength, accept, requestOptions, context);
    }

    /**
     * This operation generates a list of words, or tags, that are relevant to the content of the supplied image. The
     * Computer Vision API can return tags based on objects, living beings, scenery or actions found in images. Unlike
     * categories, tags are not organized according to a hierarchical classification system, but correspond to image
     * content. Tags may contain hints to avoid ambiguity or provide context, for example the tag "ascomycete" may be
     * accompanied by the hint "fungus". Two input methods are supported -- (1) Uploading an image or (2) specifying an
     * image URL. A successful response will be returned in JSON. If the request failed, the response will contain an
     * error code and a message to help understand what went wrong.
     *
     * <p><strong>Query Parameters</strong>
     *
     * <table border="1">
     *     <caption>Query Parameters</caption>
     *     <tr><th>Name</th><th>Type</th><th>Required</th><th>Description</th></tr>
     *     <tr><td>language</td><td>String</td><td>No</td><td>The desired language for output generation. If this parameter is not specified, the default value is "en". See https://aka.ms/cv-languages for list of supported languages.</td></tr>
     *     <tr><td>model-version</td><td>String</td><td>No</td><td>Optional parameter to specify the version of the AI model. Accepted values are: "latest", "2021-04-01", "2021-05-01". Defaults to "latest".</td></tr>
     * </table>
     *
     * <p><strong>Request Body Schema</strong>
     *
     * <pre>{@code
     * Flux<ByteBuffer>
     * }</pre>
     *
     * <p><strong>Response Body Schema</strong>
     *
     * <pre>{@code
     * {
     *     tags: [
     *         {
     *             name: String
     *             confidence: Double
     *             hint: String
     *         }
     *     ]
     *     requestId: String
     *     metadata: {
     *         width: Integer
     *         height: Integer
     *         format: String
     *     }
     *     modelVersion: String
     * }
     * }</pre>
     *
     * @param contentType Upload file type.
     * @param image An image stream.
     * @param contentLength The contentLength parameter.
     * @param requestOptions The options to configure the HTTP request before HTTP client sends it.
     * @throws HttpResponseException thrown if the request is rejected by server.
     * @throws ClientAuthenticationException thrown if the request is rejected by server on status code 401.
     * @throws ResourceNotFoundException thrown if the request is rejected by server on status code 404.
     * @throws ResourceModifiedException thrown if the request is rejected by server on status code 409.
     * @return the results of a image tag operation, including any tags and image metadata along with {@link Response}.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    public Response<BinaryData> tagImageInStreamWithResponse(
            String contentType, BinaryData image, long contentLength, RequestOptions requestOptions) {
        return tagImageInStreamWithResponseAsync(contentType, image, contentLength, requestOptions).block();
    }

    /**
     * Use this interface to get the result of a Read operation, employing the state-of-the-art Optical Character
     * Recognition (OCR) algorithms optimized for text-heavy documents. When you use the Read interface, the response
     * contains a field called 'Operation-Location'. The 'Operation-Location' field contains the URL that you must use
     * for your 'GetReadResult' operation to access OCR results..
     *
     * <p><strong>Query Parameters</strong>
     *
     * <table border="1">
     *     <caption>Query Parameters</caption>
     *     <tr><th>Name</th><th>Type</th><th>Required</th><th>Description</th></tr>
     *     <tr><td>language</td><td>String</td><td>No</td><td>The BCP-47 language code of the text in the document. Read supports auto language identification and multi-language documents, so only provide a language code if you would like to force the document to be processed in that specific language. See https://aka.ms/ocr-languages for list of supported languages.</td></tr>
     *     <tr><td>pages</td><td>List&lt;String&gt;</td><td>No</td><td>Custom page numbers for multi-page documents(PDF/TIFF), input the number of the pages you want to get OCR result. For a range of pages, use a hyphen. Separate each page or range with a comma. In the form of "," separated string.</td></tr>
     *     <tr><td>model-version</td><td>String</td><td>No</td><td>Optional parameter to specify the version of the OCR model used for text extraction. Accepted values are: "latest", "latest-preview", "2021-04-12". Defaults to "latest".</td></tr>
     *     <tr><td>readingOrder</td><td>String</td><td>No</td><td>Optional parameter to specify which reading order algorithm should be applied when ordering the extract text elements. Can be either 'basic' or 'natural'. Will default to 'basic' if not specified</td></tr>
     * </table>
     *
     * <p><strong>Request Body Schema</strong>
     *
     * <pre>{@code
     * {
     *     url: String
     * }
     * }</pre>
     *
     * @param imageUrl A JSON document with a URL pointing to the image that is to be analyzed.
     * @param requestOptions The options to configure the HTTP request before HTTP client sends it.
     * @throws HttpResponseException thrown if the request is rejected by server.
     * @throws ClientAuthenticationException thrown if the request is rejected by server on status code 401.
     * @throws ResourceNotFoundException thrown if the request is rejected by server on status code 404.
     * @throws ResourceModifiedException thrown if the request is rejected by server on status code 409.
     * @return the {@link Response} on successful completion of {@link Mono}.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    public Mono<Response<Void>> readWithResponseAsync(BinaryData imageUrl, RequestOptions requestOptions) {
        final String accept = "application/json";
        return FluxUtil.withContext(
                context -> service.read(this.getEndpoint(), imageUrl, accept, requestOptions, context));
    }

    /**
     * Use this interface to get the result of a Read operation, employing the state-of-the-art Optical Character
     * Recognition (OCR) algorithms optimized for text-heavy documents. When you use the Read interface, the response
     * contains a field called 'Operation-Location'. The 'Operation-Location' field contains the URL that you must use
     * for your 'GetReadResult' operation to access OCR results..
     *
     * <p><strong>Query Parameters</strong>
     *
     * <table border="1">
     *     <caption>Query Parameters</caption>
     *     <tr><th>Name</th><th>Type</th><th>Required</th><th>Description</th></tr>
     *     <tr><td>language</td><td>String</td><td>No</td><td>The BCP-47 language code of the text in the document. Read supports auto language identification and multi-language documents, so only provide a language code if you would like to force the document to be processed in that specific language. See https://aka.ms/ocr-languages for list of supported languages.</td></tr>
     *     <tr><td>pages</td><td>List&lt;String&gt;</td><td>No</td><td>Custom page numbers for multi-page documents(PDF/TIFF), input the number of the pages you want to get OCR result. For a range of pages, use a hyphen. Separate each page or range with a comma. In the form of "," separated string.</td></tr>
     *     <tr><td>model-version</td><td>String</td><td>No</td><td>Optional parameter to specify the version of the OCR model used for text extraction. Accepted values are: "latest", "latest-preview", "2021-04-12". Defaults to "latest".</td></tr>
     *     <tr><td>readingOrder</td><td>String</td><td>No</td><td>Optional parameter to specify which reading order algorithm should be applied when ordering the extract text elements. Can be either 'basic' or 'natural'. Will default to 'basic' if not specified</td></tr>
     * </table>
     *
     * <p><strong>Request Body Schema</strong>
     *
     * <pre>{@code
     * {
     *     url: String
     * }
     * }</pre>
     *
     * @param imageUrl A JSON document with a URL pointing to the image that is to be analyzed.
     * @param requestOptions The options to configure the HTTP request before HTTP client sends it.
     * @param context The context to associate with this operation.
     * @throws HttpResponseException thrown if the request is rejected by server.
     * @throws ClientAuthenticationException thrown if the request is rejected by server on status code 401.
     * @throws ResourceNotFoundException thrown if the request is rejected by server on status code 404.
     * @throws ResourceModifiedException thrown if the request is rejected by server on status code 409.
     * @return the {@link Response} on successful completion of {@link Mono}.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    public Mono<Response<Void>> readWithResponseAsync(
            BinaryData imageUrl, RequestOptions requestOptions, Context context) {
        final String accept = "application/json";
        return service.read(this.getEndpoint(), imageUrl, accept, requestOptions, context);
    }

    /**
     * Use this interface to get the result of a Read operation, employing the state-of-the-art Optical Character
     * Recognition (OCR) algorithms optimized for text-heavy documents. When you use the Read interface, the response
     * contains a field called 'Operation-Location'. The 'Operation-Location' field contains the URL that you must use
     * for your 'GetReadResult' operation to access OCR results..
     *
     * <p><strong>Query Parameters</strong>
     *
     * <table border="1">
     *     <caption>Query Parameters</caption>
     *     <tr><th>Name</th><th>Type</th><th>Required</th><th>Description</th></tr>
     *     <tr><td>language</td><td>String</td><td>No</td><td>The BCP-47 language code of the text in the document. Read supports auto language identification and multi-language documents, so only provide a language code if you would like to force the document to be processed in that specific language. See https://aka.ms/ocr-languages for list of supported languages.</td></tr>
     *     <tr><td>pages</td><td>List&lt;String&gt;</td><td>No</td><td>Custom page numbers for multi-page documents(PDF/TIFF), input the number of the pages you want to get OCR result. For a range of pages, use a hyphen. Separate each page or range with a comma. In the form of "," separated string.</td></tr>
     *     <tr><td>model-version</td><td>String</td><td>No</td><td>Optional parameter to specify the version of the OCR model used for text extraction. Accepted values are: "latest", "latest-preview", "2021-04-12". Defaults to "latest".</td></tr>
     *     <tr><td>readingOrder</td><td>String</td><td>No</td><td>Optional parameter to specify which reading order algorithm should be applied when ordering the extract text elements. Can be either 'basic' or 'natural'. Will default to 'basic' if not specified</td></tr>
     * </table>
     *
     * <p><strong>Request Body Schema</strong>
     *
     * <pre>{@code
     * {
     *     url: String
     * }
     * }</pre>
     *
     * @param imageUrl A JSON document with a URL pointing to the image that is to be analyzed.
     * @param requestOptions The options to configure the HTTP request before HTTP client sends it.
     * @throws HttpResponseException thrown if the request is rejected by server.
     * @throws ClientAuthenticationException thrown if the request is rejected by server on status code 401.
     * @throws ResourceNotFoundException thrown if the request is rejected by server on status code 404.
     * @throws ResourceModifiedException thrown if the request is rejected by server on status code 409.
     * @return the {@link Response}.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    public Response<Void> readWithResponse(BinaryData imageUrl, RequestOptions requestOptions) {
        return readWithResponseAsync(imageUrl, requestOptions).block();
    }

    /**
     * This interface is used for getting OCR results of Read operation. The URL to this interface should be retrieved
     * from 'Operation-Location' field returned from Read interface.
     *
     * <p><strong>Response Body Schema</strong>
     *
     * <pre>{@code
     * {
     *     status: String(notStarted/running/failed/succeeded)
     *     createdDateTime: String
     *     lastUpdatedDateTime: String
     *     analyzeResult: {
     *         version: String
     *         modelVersion: String
     *         readResults: [
     *             {
     *                 page: int
     *                 language: String
     *                 angle: float
     *                 width: float
     *                 height: float
     *                 unit: String(pixel/inch)
     *                 lines: [
     *                     {
     *                         language: String
     *                         boundingBox: [
     *                             float
     *                         ]
     *                         appearance: {
     *                             style: {
     *                                 name: String(other/handwriting)
     *                                 confidence: float
     *                             }
     *                         }
     *                         text: String
     *                         words: [
     *                             {
     *                                 boundingBox: [
     *                                     float
     *                                 ]
     *                                 text: String
     *                                 confidence: float
     *                             }
     *                         ]
     *                     }
     *                 ]
     *             }
     *         ]
     *     }
     * }
     * }</pre>
     *
     * @param operationId Id of read operation returned in the response of the 'Read' interface.
     * @param requestOptions The options to configure the HTTP request before HTTP client sends it.
     * @throws HttpResponseException thrown if the request is rejected by server.
     * @throws ClientAuthenticationException thrown if the request is rejected by server on status code 401.
     * @throws ResourceNotFoundException thrown if the request is rejected by server on status code 404.
     * @throws ResourceModifiedException thrown if the request is rejected by server on status code 409.
     * @return oCR result of the read operation along with {@link Response} on successful completion of {@link Mono}.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    public Mono<Response<BinaryData>> getReadResultWithResponseAsync(
            String operationId, RequestOptions requestOptions) {
        final String accept = "application/json";
        return FluxUtil.withContext(
                context -> service.getReadResult(this.getEndpoint(), operationId, accept, requestOptions, context));
    }

    /**
     * This interface is used for getting OCR results of Read operation. The URL to this interface should be retrieved
     * from 'Operation-Location' field returned from Read interface.
     *
     * <p><strong>Response Body Schema</strong>
     *
     * <pre>{@code
     * {
     *     status: String(notStarted/running/failed/succeeded)
     *     createdDateTime: String
     *     lastUpdatedDateTime: String
     *     analyzeResult: {
     *         version: String
     *         modelVersion: String
     *         readResults: [
     *             {
     *                 page: int
     *                 language: String
     *                 angle: float
     *                 width: float
     *                 height: float
     *                 unit: String(pixel/inch)
     *                 lines: [
     *                     {
     *                         language: String
     *                         boundingBox: [
     *                             float
     *                         ]
     *                         appearance: {
     *                             style: {
     *                                 name: String(other/handwriting)
     *                                 confidence: float
     *                             }
     *                         }
     *                         text: String
     *                         words: [
     *                             {
     *                                 boundingBox: [
     *                                     float
     *                                 ]
     *                                 text: String
     *                                 confidence: float
     *                             }
     *                         ]
     *                     }
     *                 ]
     *             }
     *         ]
     *     }
     * }
     * }</pre>
     *
     * @param operationId Id of read operation returned in the response of the 'Read' interface.
     * @param requestOptions The options to configure the HTTP request before HTTP client sends it.
     * @param context The context to associate with this operation.
     * @throws HttpResponseException thrown if the request is rejected by server.
     * @throws ClientAuthenticationException thrown if the request is rejected by server on status code 401.
     * @throws ResourceNotFoundException thrown if the request is rejected by server on status code 404.
     * @throws ResourceModifiedException thrown if the request is rejected by server on status code 409.
     * @return oCR result of the read operation along with {@link Response} on successful completion of {@link Mono}.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    public Mono<Response<BinaryData>> getReadResultWithResponseAsync(
            String operationId, RequestOptions requestOptions, Context context) {
        final String accept = "application/json";
        return service.getReadResult(this.getEndpoint(), operationId, accept, requestOptions, context);
    }

    /**
     * This interface is used for getting OCR results of Read operation. The URL to this interface should be retrieved
     * from 'Operation-Location' field returned from Read interface.
     *
     * <p><strong>Response Body Schema</strong>
     *
     * <pre>{@code
     * {
     *     status: String(notStarted/running/failed/succeeded)
     *     createdDateTime: String
     *     lastUpdatedDateTime: String
     *     analyzeResult: {
     *         version: String
     *         modelVersion: String
     *         readResults: [
     *             {
     *                 page: int
     *                 language: String
     *                 angle: float
     *                 width: float
     *                 height: float
     *                 unit: String(pixel/inch)
     *                 lines: [
     *                     {
     *                         language: String
     *                         boundingBox: [
     *                             float
     *                         ]
     *                         appearance: {
     *                             style: {
     *                                 name: String(other/handwriting)
     *                                 confidence: float
     *                             }
     *                         }
     *                         text: String
     *                         words: [
     *                             {
     *                                 boundingBox: [
     *                                     float
     *                                 ]
     *                                 text: String
     *                                 confidence: float
     *                             }
     *                         ]
     *                     }
     *                 ]
     *             }
     *         ]
     *     }
     * }
     * }</pre>
     *
     * @param operationId Id of read operation returned in the response of the 'Read' interface.
     * @param requestOptions The options to configure the HTTP request before HTTP client sends it.
     * @throws HttpResponseException thrown if the request is rejected by server.
     * @throws ClientAuthenticationException thrown if the request is rejected by server on status code 401.
     * @throws ResourceNotFoundException thrown if the request is rejected by server on status code 404.
     * @throws ResourceModifiedException thrown if the request is rejected by server on status code 409.
     * @return oCR result of the read operation along with {@link Response}.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    public Response<BinaryData> getReadResultWithResponse(String operationId, RequestOptions requestOptions) {
        return getReadResultWithResponseAsync(operationId, requestOptions).block();
    }

    /**
     * Use this interface to get the result of a Read operation, employing the state-of-the-art Optical Character
     * Recognition (OCR) algorithms optimized for text-heavy documents. When you use the Read interface, the response
     * contains a field called 'Operation-Location'. The 'Operation-Location' field contains the URL that you must use
     * for your 'GetReadResult' operation to access OCR results..
     *
     * <p><strong>Query Parameters</strong>
     *
     * <table border="1">
     *     <caption>Query Parameters</caption>
     *     <tr><th>Name</th><th>Type</th><th>Required</th><th>Description</th></tr>
     *     <tr><td>language</td><td>String</td><td>No</td><td>The BCP-47 language code of the text in the document. Read supports auto language identification and multi-language documents, so only provide a language code if you would like to force the document to be processed in that specific language. See https://aka.ms/ocr-languages for list of supported languages.</td></tr>
     *     <tr><td>pages</td><td>List&lt;String&gt;</td><td>No</td><td>Custom page numbers for multi-page documents(PDF/TIFF), input the number of the pages you want to get OCR result. For a range of pages, use a hyphen. Separate each page or range with a comma. In the form of "," separated string.</td></tr>
     *     <tr><td>model-version</td><td>String</td><td>No</td><td>Optional parameter to specify the version of the OCR model used for text extraction. Accepted values are: "latest", "latest-preview", "2021-04-12". Defaults to "latest".</td></tr>
     *     <tr><td>readingOrder</td><td>String</td><td>No</td><td>Optional parameter to specify which reading order algorithm should be applied when ordering the extract text elements. Can be either 'basic' or 'natural'. Will default to 'basic' if not specified</td></tr>
     * </table>
     *
     * <p><strong>Request Body Schema</strong>
     *
     * <pre>{@code
     * Flux<ByteBuffer>
     * }</pre>
     *
     * @param image An image stream.
     * @param contentLength The contentLength parameter.
     * @param requestOptions The options to configure the HTTP request before HTTP client sends it.
     * @throws HttpResponseException thrown if the request is rejected by server.
     * @throws ClientAuthenticationException thrown if the request is rejected by server on status code 401.
     * @throws ResourceNotFoundException thrown if the request is rejected by server on status code 404.
     * @throws ResourceModifiedException thrown if the request is rejected by server on status code 409.
     * @return the {@link Response} on successful completion of {@link Mono}.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    public Mono<Response<Void>> readInStreamWithResponseAsync(
            BinaryData image, long contentLength, RequestOptions requestOptions) {
        final String accept = "application/json";
        return FluxUtil.withContext(
                context ->
                        service.readInStream(
                                this.getEndpoint(), image, contentLength, accept, requestOptions, context));
    }

    /**
     * Use this interface to get the result of a Read operation, employing the state-of-the-art Optical Character
     * Recognition (OCR) algorithms optimized for text-heavy documents. When you use the Read interface, the response
     * contains a field called 'Operation-Location'. The 'Operation-Location' field contains the URL that you must use
     * for your 'GetReadResult' operation to access OCR results..
     *
     * <p><strong>Query Parameters</strong>
     *
     * <table border="1">
     *     <caption>Query Parameters</caption>
     *     <tr><th>Name</th><th>Type</th><th>Required</th><th>Description</th></tr>
     *     <tr><td>language</td><td>String</td><td>No</td><td>The BCP-47 language code of the text in the document. Read supports auto language identification and multi-language documents, so only provide a language code if you would like to force the document to be processed in that specific language. See https://aka.ms/ocr-languages for list of supported languages.</td></tr>
     *     <tr><td>pages</td><td>List&lt;String&gt;</td><td>No</td><td>Custom page numbers for multi-page documents(PDF/TIFF), input the number of the pages you want to get OCR result. For a range of pages, use a hyphen. Separate each page or range with a comma. In the form of "," separated string.</td></tr>
     *     <tr><td>model-version</td><td>String</td><td>No</td><td>Optional parameter to specify the version of the OCR model used for text extraction. Accepted values are: "latest", "latest-preview", "2021-04-12". Defaults to "latest".</td></tr>
     *     <tr><td>readingOrder</td><td>String</td><td>No</td><td>Optional parameter to specify which reading order algorithm should be applied when ordering the extract text elements. Can be either 'basic' or 'natural'. Will default to 'basic' if not specified</td></tr>
     * </table>
     *
     * <p><strong>Request Body Schema</strong>
     *
     * <pre>{@code
     * Flux<ByteBuffer>
     * }</pre>
     *
     * @param image An image stream.
     * @param contentLength The contentLength parameter.
     * @param requestOptions The options to configure the HTTP request before HTTP client sends it.
     * @param context The context to associate with this operation.
     * @throws HttpResponseException thrown if the request is rejected by server.
     * @throws ClientAuthenticationException thrown if the request is rejected by server on status code 401.
     * @throws ResourceNotFoundException thrown if the request is rejected by server on status code 404.
     * @throws ResourceModifiedException thrown if the request is rejected by server on status code 409.
     * @return the {@link Response} on successful completion of {@link Mono}.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    public Mono<Response<Void>> readInStreamWithResponseAsync(
            BinaryData image, long contentLength, RequestOptions requestOptions, Context context) {
        final String accept = "application/json";
        return service.readInStream(this.getEndpoint(), image, contentLength, accept, requestOptions, context);
    }

    /**
     * Use this interface to get the result of a Read operation, employing the state-of-the-art Optical Character
     * Recognition (OCR) algorithms optimized for text-heavy documents. When you use the Read interface, the response
     * contains a field called 'Operation-Location'. The 'Operation-Location' field contains the URL that you must use
     * for your 'GetReadResult' operation to access OCR results..
     *
     * <p><strong>Query Parameters</strong>
     *
     * <table border="1">
     *     <caption>Query Parameters</caption>
     *     <tr><th>Name</th><th>Type</th><th>Required</th><th>Description</th></tr>
     *     <tr><td>language</td><td>String</td><td>No</td><td>The BCP-47 language code of the text in the document. Read supports auto language identification and multi-language documents, so only provide a language code if you would like to force the document to be processed in that specific language. See https://aka.ms/ocr-languages for list of supported languages.</td></tr>
     *     <tr><td>pages</td><td>List&lt;String&gt;</td><td>No</td><td>Custom page numbers for multi-page documents(PDF/TIFF), input the number of the pages you want to get OCR result. For a range of pages, use a hyphen. Separate each page or range with a comma. In the form of "," separated string.</td></tr>
     *     <tr><td>model-version</td><td>String</td><td>No</td><td>Optional parameter to specify the version of the OCR model used for text extraction. Accepted values are: "latest", "latest-preview", "2021-04-12". Defaults to "latest".</td></tr>
     *     <tr><td>readingOrder</td><td>String</td><td>No</td><td>Optional parameter to specify which reading order algorithm should be applied when ordering the extract text elements. Can be either 'basic' or 'natural'. Will default to 'basic' if not specified</td></tr>
     * </table>
     *
     * <p><strong>Request Body Schema</strong>
     *
     * <pre>{@code
     * Flux<ByteBuffer>
     * }</pre>
     *
     * @param image An image stream.
     * @param contentLength The contentLength parameter.
     * @param requestOptions The options to configure the HTTP request before HTTP client sends it.
     * @throws HttpResponseException thrown if the request is rejected by server.
     * @throws ClientAuthenticationException thrown if the request is rejected by server on status code 401.
     * @throws ResourceNotFoundException thrown if the request is rejected by server on status code 404.
     * @throws ResourceModifiedException thrown if the request is rejected by server on status code 409.
     * @return the {@link Response}.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    public Response<Void> readInStreamWithResponse(
            BinaryData image, long contentLength, RequestOptions requestOptions) {
        return readInStreamWithResponseAsync(image, contentLength, requestOptions).block();
    }
}
